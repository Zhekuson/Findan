{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from macro_agent import MacroAgent, ReplayMemory, QNetwork, Transition\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "#from mpl_finance import candlestick_ohlc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime as datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21867749930>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAPACITY = 500\n",
    "INIT_EPSILON = 1\n",
    "_E = 0.00001\n",
    "GAMMA_DISCOUNT = 0.5\n",
    "EPOCH_COUNT = 500\n",
    "MINI_BATCH_SIZE = 10\n",
    "WINDOW_SIZE = 20\n",
    "ALPHA = 10000\n",
    "ACTIONS={\"HOLD\":torch.tensor([0,1,0], dtype=torch.float32),\n",
    "\"BUY\":torch.tensor([1,0,0], dtype=torch.float32), \n",
    "  \"SELL\":torch.tensor([0,0,1], dtype=torch.float32)}\n",
    "\n",
    "np.random.seed(1000)\n",
    "import random\n",
    "random.seed(1000)\n",
    "torch.manual_seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, all_data):\n",
    "        self._all_data = all_data\n",
    "        self._pointer = WINDOW_SIZE\n",
    "        self.done = False\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def taken_action(self):\n",
    "        self._pointer += 1\n",
    "        if self._pointer >= len(self._all_data) - 1:\n",
    "            self.done = True\n",
    "        pass\n",
    "    \n",
    "    def get_price(self):\n",
    "        return self._all_data.iloc[self._pointer]['Close']\n",
    "\n",
    "    def get_change_zscore(self, column):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        frame = self._all_data.iloc[start_idx:self._pointer + 1]\n",
    "        market_now = self._all_data.iloc[self._pointer]\n",
    "        PC = market_now[column] / np.mean(frame[column]) - 1\n",
    "\n",
    "        PCs = np.empty_like(frame[column])\n",
    "        for i in range(start_idx, self._pointer + 1):\n",
    "            start_frame = np.max([0, i - WINDOW_SIZE])\n",
    "            end_frame = i\n",
    "            PCs[i - start_idx] = self._all_data.iloc[end_frame][column] / np.mean(\n",
    "                self._all_data.iloc[start_frame:end_frame+1][column]) - 1\n",
    "\n",
    "        z_score_price_change = (PC - np.mean(PCs)) / np.std(PCs) \n",
    "        return z_score_price_change\n",
    "\n",
    "    def get_EMA(self, t):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        g = 2 * self._all_data.iloc[t]['Close'] / (WINDOW_SIZE + 1)\n",
    "        ex = (100 - 2/(WINDOW_SIZE + 1))\n",
    "        EMA = g + np.mean(self._all_data.iloc[start_idx:t+1]['Close']) * ex\n",
    "        return EMA\n",
    "        \n",
    "\n",
    "    def get_indicators(self):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        market_now = self._all_data.iloc[self._pointer]\n",
    "        frame = self._all_data.iloc[start_idx:self._pointer + 1]\n",
    "        # price\n",
    "        z_score_price = (market_now['Close'] - \n",
    "            np.mean(frame['Close'])) / np.std(frame['Close']) + _E\n",
    "        # price change\n",
    "        z_score_price_change = self.get_change_zscore('Close') + _E\n",
    "        # volume\n",
    "        z_score_volume = (market_now['Volume'] - \n",
    "            np.mean(frame['Volume'])) / np.std(frame['Volume']) + _E\n",
    "        # volume change\n",
    "        z_score_volume_change = self.get_change_zscore('Volume') + _E\n",
    "        # Volatility\n",
    "        volatility = (self.get_EMA(self._pointer) -\n",
    "         self.get_EMA(self._pointer - WINDOW_SIZE))/ self.get_EMA(self._pointer - WINDOW_SIZE) + _E\n",
    "        return z_score_price,z_score_price_change,z_score_volume,z_score_volume_change,volatility\n",
    "\n",
    "    def get_state(self, agent:MacroAgent):\n",
    "        return torch.tensor(np.hstack((self.get_price(), self.get_indicators(),\n",
    "            agent.estimate_assets(self.get_price()))), dtype=torch.float32)\n",
    "\n",
    "def decay_epsilon(cur_epsilon):\n",
    "    return cur_epsilon * 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    market_data = pd.read_json('RESULT.json')\n",
    "    market_data.rename(columns={1:'Open',2:'High', 3:'Low', 4:'Close', 5:'Volume'}, inplace=True)\n",
    "    market_data[0] = market_data[0].transform(datetime.fromtimestamp)\n",
    "    market_data.set_index([0], inplace=True)\n",
    "    market_data.sort_index(inplace=True)\n",
    "    market_data = market_data[(market_data.index >= '2018-11-15 00:00:00') & (market_data.index <= '2018-11-17 17:06:00')]\n",
    "    return market_data\n",
    "\n",
    "def get_train_data(market_data):\n",
    "    return market_data[market_data.index <= '2018-11-16 00:00:00']\n",
    "\n",
    "def get_test_data(market_data):\n",
    "    return market_data[market_data.index >= '2018-11-16 00:00:00']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(chosen_action, estimated_assets):\n",
    "    if torch.allclose(chosen_action,ACTIONS['SELL']):\n",
    "        if  estimated_assets == 0:\n",
    "            return -1\n",
    "        else: \n",
    "            return 1 if estimated_assets > 0 else -1\n",
    "    elif torch.allclose(chosen_action,ACTIONS['BUY']):\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_best_reward(next_state):\n",
    "    sell_reward = calculate_reward(ACTIONS['SELL'], next_state[6])\n",
    "    buy_reward = calculate_reward(ACTIONS['BUY'], next_state[6])\n",
    "    hold_reward = calculate_reward(ACTIONS['HOLD'], next_state[6])\n",
    "    if sell_reward >= buy_reward and  sell_reward >= hold_reward:\n",
    "        return (ACTIONS['SELL'], sell_reward)\n",
    "    elif buy_reward >= sell_reward and buy_reward >= hold_reward:\n",
    "        return (ACTIONS['BUY'], buy_reward)\n",
    "    else:\n",
    "        return (ACTIONS['HOLD'], hold_reward)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = ReplayMemory(CAPACITY)\n",
    "macro_agent = MacroAgent()\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "optimizer = torch.optim.Adam(macro_agent.q_network.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 149/500 [9:34:02<338:44:58, 3474.35s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "market_data = load_data()\n",
    "train_data = get_train_data(market_data)\n",
    "test_data = get_test_data(market_data)\n",
    "current_max_balance = 0\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(EPOCH_COUNT)):\n",
    "    done = False\n",
    "    cur_epsilon = INIT_EPSILON\n",
    "    environment = Environment(train_data)\n",
    "    macro_agent.sell_assets(0)\n",
    "    optimizer = torch.optim.Adam(macro_agent.q_network.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
    "    while not done:\n",
    "        now_state = environment.get_state(macro_agent)\n",
    "        macro_agent.q_network.eval()\n",
    "        decision = np.random.rand()\n",
    "        if decision < cur_epsilon:\n",
    "            # epsilon\n",
    "            action = ACTIONS[np.random.choice(list(ACTIONS))]\n",
    "            est_assets = macro_agent.estimate_assets(environment.get_price())\n",
    "            cur_reward = calculate_reward(action, est_assets)\n",
    "        else:\n",
    "            # 1-epsilon\n",
    "            action, cur_reward = macro_agent.q_network(now_state)\n",
    "        \n",
    "\n",
    "        # reward algo\n",
    "        environment.taken_action()\n",
    "        next_state = environment.get_state(macro_agent)\n",
    "        done = environment.done\n",
    "        \n",
    "        replay_memory.push(now_state, action, cur_reward, next_state, done)\n",
    "        \n",
    "        # taking batch\n",
    "        batch = replay_memory.sample(MINI_BATCH_SIZE)\n",
    "        q = []\n",
    "        true_actions = []\n",
    "        current_states_batch = []\n",
    "\n",
    "        for i, object in enumerate(batch):\n",
    "            current_states_batch.append(object.state)\n",
    "            if not object.done:\n",
    "                # r_i + gamma * Q()\n",
    "                true_actions.append(object.action + GAMMA_DISCOUNT * get_best_reward(object.next_state)[0])\n",
    "                q.append(object.reward + GAMMA_DISCOUNT * get_best_reward(object.next_state)[1])\n",
    "            else:\n",
    "                # r_i\n",
    "                true_actions.append(object.action)\n",
    "                q.append(object.reward)\n",
    "        # grad d\n",
    "        macro_agent.q_network.train()\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        for batch_state in current_states_batch:\n",
    "            rewards.append(macro_agent.q_network(batch_state)[1])\n",
    "            actions.append(macro_agent.q_network.DQN_SMAX(batch_state))\n",
    "            \n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "        for i in range(len(rewards)):\n",
    "            #print(actions[i])\n",
    "            if rewards[i] != q[i]:\n",
    "                loss = criterion(actions[i], true_actions[i]) \n",
    "                loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        cur_epsilon = decay_epsilon(cur_epsilon)  \n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        # test model\n",
    "        macro_agent.q_network.eval()\n",
    "        test_env = Environment(test_data)\n",
    "        macro_agent.sell_assets(price=0)\n",
    "        current_balance = [0.0]\n",
    "        while not test_env.done:\n",
    "            now_state = test_env.get_state(macro_agent)\n",
    "            action, _ = macro_agent.q_network(now_state)\n",
    "            price = test_env.get_price()\n",
    "            if torch.allclose(action, ACTIONS['BUY']):\n",
    "                #print('time to buy')\n",
    "                prev_assets = macro_agent.estimate_assets(price)\n",
    "                macro_agent.buy_asset(price)\n",
    "                after_assets = macro_agent.estimate_assets(price)\n",
    "                current_balance.append(current_balance[-1] - prev_assets + after_assets)\n",
    "            elif torch.allclose(action,ACTIONS['SELL']):\n",
    "                #print('time to sell')\n",
    "                earning = macro_agent.sell_assets(price)\n",
    "                current_balance.append(current_balance[-1] + earning)\n",
    "            else:\n",
    "                #print('time to hold')\n",
    "                current_balance.append(current_balance[-1])\n",
    "            test_env.taken_action()\n",
    "        plt.plot(current_balance)\n",
    "        pd.DataFrame(current_balance).to_csv('macro_agent_epoch_{}.csv'.format(epoch))\n",
    "        plt.savefig('testing_epoch_{}.jpg'.format(epoch))\n",
    "        if current_balance[-1] > current_max_balance:\n",
    "            torch.save(macro_agent.q_network.state_dict(), 'q_net_epoch_{}'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 9.4715e+01, -1.0813e-02, -1.8710e-02, -2.5174e-03, -1.8232e-03,\n",
      "          1.9214e-06,  0.0000e+00],\n",
      "        [ 7.1231e+01, -8.1507e-03, -1.4112e-02, -1.8872e-03, -1.3655e-03,\n",
      "          1.4436e-06,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.7185e+02,  1.9685e-02,  3.4093e-02,  4.5381e-03,  3.2852e-03,\n",
      "         -3.4757e-06,  0.0000e+00],\n",
      "        [-1.6010e+01,  1.9500e-03,  3.4311e-03,  3.7129e-04,  2.6617e-04,\n",
      "         -3.0391e-07,  0.0000e+00],\n",
      "        [ 1.2504e+02, -1.4153e-02, -2.4434e-02, -3.3787e-03, -2.4492e-03,\n",
      "          2.5587e-06,  0.0000e+00]])\n",
      "tensor([ 0.0000,  0.0171,  0.0128,  0.0000, -0.0310, -0.0029,  0.0226])\n",
      "tensor([[   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [   0.0000,   39.4244,    1.3475,    0.0000,   18.4230,   50.1921,\n",
      "            2.1160],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [   0.0000,  -97.2722,   -3.3318,    0.0000,  -45.4446, -123.8230,\n",
      "           -5.2279],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [   0.0000,  113.4157,    3.8777,    0.0000,   52.9976,  144.3896,\n",
      "            6.0884]])\n",
      "tensor([ 0.0000,  0.0304,  0.0000, -0.0749,  0.0000,  0.0000,  0.0874])\n",
      "tensor([[ 0.0000e+00, -4.2827e+01,  0.0000e+00, -7.7541e+01,  0.0000e+00,\n",
      "          0.0000e+00, -5.3782e+01],\n",
      "        [ 0.0000e+00,  8.2378e-16,  0.0000e+00,  2.5317e-15,  0.0000e+00,\n",
      "          0.0000e+00,  1.1441e-15],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.2276e+01,  0.0000e+00,  2.2242e+01,  0.0000e+00,\n",
      "          0.0000e+00,  1.5414e+01],\n",
      "        [ 0.0000e+00, -1.0948e+00,  0.0000e+00, -1.9702e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.3760e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  2.3904e+01,  0.0000e+00,  4.3299e+01,  0.0000e+00,\n",
      "          0.0000e+00,  3.0017e+01]])\n",
      "tensor([-2.5854e-01,  4.8716e-18,  0.0000e+00,  7.4131e-02, -6.5921e-03,\n",
      "         0.0000e+00,  1.4434e-01])\n",
      "tensor([[-1.0379e+01,  0.0000e+00,  0.0000e+00, -2.0221e+01, -4.5975e+01,\n",
      "          0.0000e+00, -1.3409e+01],\n",
      "        [ 1.0379e+01, -2.1622e-17,  0.0000e+00,  2.0221e+01,  4.5975e+01,\n",
      "          0.0000e+00,  1.3409e+01],\n",
      "        [-3.2663e-14, -0.0000e+00, -0.0000e+00, -5.1512e-14, -1.2035e-13,\n",
      "         -0.0000e+00, -3.1923e-14]])\n",
      "tensor([-6.1246e-01,  6.1245e-01, -1.6087e-15])\n"
     ]
    }
   ],
   "source": [
    "for param in optimizer.param_groups[0]['params']:\n",
    "    if param.requires_grad:\n",
    "        print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIONS[np.random.choice(list(ACTIONS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n",
      "time to hold\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12476/803260318.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcurrent_balance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnow_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmacro_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmacro_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_price\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12476/1616554491.py\u001b[0m in \u001b[0;36mget_state\u001b[1;34m(self, agent)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mMacroAgent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         return torch.tensor(np.hstack((self.get_price(), self.get_indicators(),\n\u001b[0m\u001b[0;32m     64\u001b[0m             agent.estimate_assets(self.get_price()))), dtype=torch.float32)\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "macro_agent.q_network.eval()\n",
    "test_env = Environment(test_data)\n",
    "macro_agent.sell_assets(price=0)\n",
    "current_balance = [0.0]\n",
    "while not test_env.done:\n",
    "    now_state = test_env.get_state(macro_agent)\n",
    "    action, _ = macro_agent.q_network(now_state)\n",
    "    price = test_env.get_price()\n",
    "    if torch.allclose(action, ACTIONS['BUY']):\n",
    "        print('time to buy')\n",
    "        prev_assets = macro_agent.estimate_assets(price)\n",
    "        macro_agent.buy_asset(price)\n",
    "        after_assets = macro_agent.estimate_assets(price)\n",
    "        current_balance.append(current_balance[-1] + price)\n",
    "    elif torch.allclose(action,ACTIONS['SELL']):\n",
    "        print('time to sell')\n",
    "        earning = macro_agent.sell_assets(price)\n",
    "        current_balance.append(current_balance[-1] + earning)\n",
    "    else:\n",
    "        print('time to hold')\n",
    "        current_balance.append(current_balance[-1])\n",
    "    test_env.taken_action()\n",
    "plt.plot(current_balance)\n",
    "pd.DataFrame(current_balance).to_csv('macro_agent_epoch_{}.csv'.format(epoch))\n",
    "plt.savefig('testing_epoch_{}.jpg'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1edc3b666a0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(current_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 0.]), 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_state = test_env.get_state(macro_agent)\n",
    "macro_agent.q_network(now_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b2bd16c4a5b7bdb943c513e9c5dbb440fb1e7bca9cf829d440576f5014c581f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
