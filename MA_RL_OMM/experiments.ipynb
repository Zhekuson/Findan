{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from macro_agent import MacroAgent, ReplayMemory, QNetwork, Transition\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "#from mpl_finance import candlestick_ohlc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime as datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPACITY = 500\n",
    "INIT_EPSILON = 0.9\n",
    "GAMMA_DISCOUNT = 0.8\n",
    "EPOCH_COUNT = 500\n",
    "MINI_BATCH_SIZE = 1\n",
    "WINDOW_SIZE = 20\n",
    "ALPHA = 10000\n",
    "ACTIONS={\"BUY\":torch.tensor([1,0,0], dtype=torch.float32),\n",
    " \"HOLD\":torch.tensor([0,1,0], dtype=torch.float32),\n",
    "  \"SELL\":torch.tensor([0,0,1], dtype=torch.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, all_data):\n",
    "        self._all_data = all_data\n",
    "        self._pointer = WINDOW_SIZE\n",
    "        self.done = False\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def taken_action(self):\n",
    "        self._pointer += 1\n",
    "        if self._pointer >= len(self._all_data) - 1:\n",
    "            self.done = True\n",
    "        pass\n",
    "    \n",
    "    def get_price(self):\n",
    "        return self._all_data.iloc[self._pointer]['Close']\n",
    "\n",
    "    def get_change_zscore(self, column):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        frame = self._all_data.iloc[start_idx:self._pointer + 1]\n",
    "        market_now = self._all_data.iloc[self._pointer]\n",
    "        PC = market_now[column] / np.mean(frame[column]) - 1\n",
    "\n",
    "        PCs = np.empty_like(frame[column])\n",
    "        for i in range(start_idx, self._pointer + 1):\n",
    "            start_frame = np.max([0, i - WINDOW_SIZE])\n",
    "            end_frame = i\n",
    "            PCs[i - start_idx] = self._all_data.iloc[end_frame][column] / np.mean(\n",
    "                self._all_data.iloc[start_frame:end_frame+1][column]) - 1\n",
    "\n",
    "        z_score_price_change = (PC - np.mean(PCs)) / np.std(PCs) \n",
    "        return z_score_price_change\n",
    "\n",
    "    def get_EMA(self, t):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        g = 2 * self._all_data.iloc[t]['Close'] / (WINDOW_SIZE + 1)\n",
    "        ex = (100 - 2/(WINDOW_SIZE + 1))\n",
    "        EMA = g + np.mean(self._all_data.iloc[start_idx:t+1]['Close']) * ex\n",
    "        return EMA\n",
    "        \n",
    "\n",
    "    def get_indicators(self):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        market_now = self._all_data.iloc[self._pointer]\n",
    "        frame = self._all_data.iloc[start_idx:self._pointer + 1]\n",
    "        # price\n",
    "        z_score_price = (market_now['Close'] - \n",
    "            np.mean(frame['Close'])) / np.std(frame['Close'])\n",
    "        # price change\n",
    "        z_score_price_change = self.get_change_zscore('Close')\n",
    "        # volume\n",
    "        z_score_volume = (market_now['Volume'] - \n",
    "            np.mean(frame['Volume'])) / np.std(frame['Volume'])\n",
    "        # volume change\n",
    "        z_score_volume_change = self.get_change_zscore('Volume')\n",
    "        # Volatility\n",
    "        volatility = (self.get_EMA(self._pointer) -\n",
    "         self.get_EMA(self._pointer - WINDOW_SIZE))/ self.get_EMA(self._pointer - WINDOW_SIZE)\n",
    "        return z_score_price,z_score_price_change,z_score_volume,z_score_volume_change,volatility\n",
    "\n",
    "    def get_state(self, agent:MacroAgent):\n",
    "        return torch.tensor(np.hstack((self.get_price(), self.get_indicators(),\n",
    "            agent.estimate_assets(self.get_price()))), dtype=torch.float32)\n",
    "\n",
    "def decay_epsilon(cur_epsilon):\n",
    "    return cur_epsilon * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    market_data = pd.read_json('RESULT.json')\n",
    "    market_data.rename(columns={1:'Open',2:'High', 3:'Low', 4:'Close', 5:'Volume'}, inplace=True)\n",
    "    market_data[0] = market_data[0].transform(datetime.fromtimestamp)\n",
    "    market_data.set_index([0], inplace=True)\n",
    "    market_data.sort_index(inplace=True)\n",
    "    market_data = market_data[(market_data.index >= '2018-11-15 00:00:00') & (market_data.index <= '2018-11-17 17:06:00')]\n",
    "    return market_data\n",
    "\n",
    "def get_train_data(market_data):\n",
    "    return market_data[market_data.index <= '2018-11-16 00:00:00']\n",
    "\n",
    "def get_test_data(market_data):\n",
    "    return market_data[market_data.index >= '2018-11-16 00:00:00']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = ReplayMemory(CAPACITY)\n",
    "macro_agent = MacroAgent()\n",
    "optimizer = torch.optim.Adam(macro_agent.q_network.parameters())\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(chosen_action, estimated_assets):\n",
    "    if torch.allclose(chosen_action,ACTIONS['SELL']):\n",
    "        if  estimated_assets == 0:\n",
    "            return -1\n",
    "        else: \n",
    "            return 1 if estimated_assets > 0 else -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_best_reward(next_state):\n",
    "    sell_reward = calculate_reward(ACTIONS['SELL'], next_state[6])\n",
    "    buy_reward = calculate_reward(ACTIONS['BUY'], next_state[6])\n",
    "    hold_reward = calculate_reward(ACTIONS['HOLD'], next_state[6])\n",
    "    if sell_reward >= buy_reward and  sell_reward >= hold_reward:\n",
    "        return (ACTIONS['SELL'], sell_reward)\n",
    "    elif buy_reward >= sell_reward and buy_reward >= hold_reward:\n",
    "        return (ACTIONS['BUY'], buy_reward)\n",
    "    else:\n",
    "        return (ACTIONS['HOLD'], hold_reward)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0.1298, 0.5299, 0.3404], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1375, 0.5142, 0.3482], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1451, 0.5028, 0.3521], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1519, 0.4944, 0.3537], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1584, 0.4866, 0.3549], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1637, 0.4811, 0.3552], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1701, 0.4732, 0.3568], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1676, 0.4613, 0.3711], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1770, 0.4679, 0.3551], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1772, 0.4722, 0.3507], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1759, 0.4799, 0.3442], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1741, 0.4896, 0.3363], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1720, 0.5005, 0.3275], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1698, 0.5125, 0.3178], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1673, 0.5257, 0.3070], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 0.0000, 1.0000])]\n",
      "[tensor([0.1645, 0.5406, 0.2949], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1628, 0.5528, 0.2843], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1612, 0.5655, 0.2733], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1603, 0.5762, 0.2635], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1593, 0.5877, 0.2531], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1587, 0.5979, 0.2434], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1587, 0.6067, 0.2347], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1717, 0.6572, 0.1711], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1788, 0.7189, 0.1022], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1560, 0.7744, 0.0695], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1509, 0.7868, 0.0624], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1561, 0.7775, 0.0665], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1759, 0.7343, 0.0898], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1999, 0.6648, 0.1352], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1860, 0.6047, 0.2093], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1902, 0.5802, 0.2295], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.1974, 0.5607, 0.2419], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2038, 0.5418, 0.2544], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2100, 0.5215, 0.2685], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.2155, 0.5007, 0.2838], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2201, 0.4798, 0.3000], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2221, 0.4688, 0.3090], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2234, 0.4584, 0.3182], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2238, 0.4494, 0.3268], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2228, 0.4644, 0.3128], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2240, 0.4635, 0.3125], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2252, 0.4626, 0.3121], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2265, 0.4617, 0.3118], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2278, 0.4607, 0.3115], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.2292, 0.4597, 0.3112], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2306, 0.4586, 0.3108], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 0.0000, 1.0000])]\n",
      "[tensor([0.2320, 0.4575, 0.3105], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2335, 0.4564, 0.3102], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2056, 0.4795, 0.3149], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1789, 0.5031, 0.3180], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1505, 0.5663, 0.2832], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1289, 0.6276, 0.2435], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1165, 0.6669, 0.2167], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1023, 0.7115, 0.1862], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.0986, 0.7284, 0.1730], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.0978, 0.7378, 0.1644], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.0998, 0.7402, 0.1600], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1095, 0.7225, 0.1680], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1192, 0.7052, 0.1756], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1349, 0.6726, 0.1925], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1574, 0.6211, 0.2215], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.1812, 0.5639, 0.2550], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2034, 0.5070, 0.2896], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2345, 0.4493, 0.3162], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2607, 0.4344, 0.3049], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2624, 0.4330, 0.3046], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.2641, 0.4317, 0.3043], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.2658, 0.4303, 0.3039], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 0.0000, 1.0000])]\n",
      "[tensor([0.2675, 0.4289, 0.3036], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2693, 0.4275, 0.3032], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2710, 0.4261, 0.3029], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2728, 0.4248, 0.3025], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2745, 0.4234, 0.3021], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2763, 0.4220, 0.3017], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2781, 0.4207, 0.3012], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2799, 0.4193, 0.3008], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2817, 0.4179, 0.3003], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2836, 0.4165, 0.2999], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2854, 0.4152, 0.2994], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2873, 0.4138, 0.2989], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2892, 0.4124, 0.2984], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2911, 0.4111, 0.2979], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2930, 0.4097, 0.2973], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2949, 0.4084, 0.2968], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2968, 0.4070, 0.2962], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.2987, 0.4057, 0.2956], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3007, 0.4043, 0.2950], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3026, 0.4030, 0.2944], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3046, 0.4017, 0.2937], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3066, 0.4003, 0.2931], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3086, 0.3990, 0.2924], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3106, 0.3977, 0.2917], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3126, 0.3964, 0.2910], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([0.3147, 0.3951, 0.2902], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 0.0000, 1.0000])]\n",
      "[tensor([0.3167, 0.3938, 0.2895], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3188, 0.3925, 0.2887], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3208, 0.3912, 0.2879], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3229, 0.3899, 0.2872], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3250, 0.3887, 0.2863], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3271, 0.3874, 0.2855], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3292, 0.3861, 0.2847], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3313, 0.3849, 0.2838], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.3490, 0.3875, 0.2634], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.4690, 0.4084, 0.1225], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.5862, 0.3787, 0.0351], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.6772, 0.3136, 0.0092], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([0.7569, 0.2409, 0.0023], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([8.3192e-01, 1.6764e-01, 4.3956e-04], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([8.9100e-01, 1.0892e-01, 8.2968e-05], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.3629e-01, 6.3701e-02, 1.2846e-05], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.6566e-01, 3.4341e-02, 1.8325e-06], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.8088e-01, 1.9120e-02, 3.6620e-07], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.8772e-01, 1.2285e-02, 1.4253e-07], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.9277e-01, 7.2291e-03, 4.4472e-08], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.9558e-01, 4.4224e-03, 1.7229e-08], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.9758e-01, 2.4220e-03, 5.0192e-09], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.9869e-01, 1.3098e-03, 1.4769e-09], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.9924e-01, 7.5829e-04, 5.6626e-10], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.9963e-01, 3.6713e-04, 1.3658e-10], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.9981e-01, 1.9099e-04, 4.3246e-11], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([9.9992e-01, 8.0765e-05, 8.2351e-12], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.9996e-01, 4.3964e-05, 3.2875e-12], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([9.9998e-01, 1.8526e-05, 7.0315e-13], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([9.9999e-01, 8.5005e-06, 1.9782e-13], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([1.0000e+00, 3.7420e-06, 5.2568e-14], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n",
      "[tensor([1.0000e+00, 1.3884e-06, 9.6986e-15], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([1.0000e+00, 5.2523e-07, 1.9821e-15], grad_fn=<SoftmaxBackward0>)] [tensor([0.8000, 1.0000, 0.0000])]\n",
      "[tensor([1.0000e+00, 2.3251e-07, 6.1032e-16], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1.0000e+00, 7.4245e-08, 9.2944e-17], grad_fn=<SoftmaxBackward0>)] [tensor([1.8000, 0.0000, 0.0000])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19304/2557134061.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# reward algo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0menvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtaken_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmacro_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19304/2337596892.py\u001b[0m in \u001b[0;36mget_state\u001b[1;34m(self, agent)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mMacroAgent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         return torch.tensor(np.hstack((self.get_price(), self.get_indicators(),\n\u001b[0m\u001b[0;32m     64\u001b[0m             agent.estimate_assets(self.get_price()))), dtype=torch.float32)\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "replay_memory = ReplayMemory(CAPACITY)\n",
    "macro_agent = MacroAgent()\n",
    "optimizer = torch.optim.Adam(macro_agent.q_network.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "market_data = load_data()\n",
    "train_data = get_train_data(market_data)\n",
    "test_data = get_test_data(market_data)\n",
    "current_max_balance = 0\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(EPOCH_COUNT)):\n",
    "    done = False\n",
    "    cur_epsilon = INIT_EPSILON\n",
    "    environment = Environment(train_data)\n",
    "    macro_agent.sell_assets(0)\n",
    "    while not done:\n",
    "        now_state = environment.get_state(macro_agent)\n",
    "        macro_agent.q_network.eval()\n",
    "        decision = np.random.rand()\n",
    "        if decision < cur_epsilon:\n",
    "            # epsilon\n",
    "            action = ACTIONS[np.random.choice(list(ACTIONS))]\n",
    "            est_assets = macro_agent.estimate_assets(environment.get_price())\n",
    "            cur_reward = calculate_reward(action, est_assets)\n",
    "        else:\n",
    "            # 1-epsilon\n",
    "            action, cur_reward = macro_agent.q_network(now_state)\n",
    "        \n",
    "\n",
    "        # reward algo\n",
    "        environment.taken_action()\n",
    "        next_state = environment.get_state(macro_agent)\n",
    "        done = environment.done\n",
    "        \n",
    "        replay_memory.push(now_state, action, cur_reward, next_state, done)\n",
    "        \n",
    "        # taking batch\n",
    "        batch = replay_memory.sample(MINI_BATCH_SIZE)\n",
    "        q = []\n",
    "        current_states_batch = []\n",
    "\n",
    "        for i, object in enumerate(batch):\n",
    "            current_states_batch.append(object.state)\n",
    "            if not object.done:\n",
    "                # r_i + gamma * Q()\n",
    "                q.append(object.action + GAMMA_DISCOUNT * get_best_reward(object.next_state)[0])\n",
    "            else:\n",
    "                # r_i\n",
    "                q.append(object.action)\n",
    "        # grad d\n",
    "        macro_agent.q_network.train()\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        for batch_state in current_states_batch:\n",
    "            rewards.append(macro_agent.q_network(batch_state))\n",
    "            actions.append(macro_agent.q_network.DQN.forward(batch_state))\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "        print(actions, q)\n",
    "        for i in range(len(rewards)):\n",
    "            loss = criterion(actions[i], q[i])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        cur_epsilon = decay_epsilon(cur_epsilon)  \n",
    "    \n",
    "\n",
    "    \n",
    "  \n",
    "    torch.save(macro_agent.q_network.state_dict(), 'q_net_epoch_{}'.format(epoch))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.6278e+02, -1.6763e-02,  1.6766e-02, -7.9665e-03, -8.6275e-03,\n",
      "         -2.0191e-04,  0.0000e+00],\n",
      "        [ 4.6390e+02,  8.1858e-03, -1.3437e-02,  3.2233e-02,  4.2579e-02,\n",
      "          1.6054e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "tensor([-0.0473,  0.0836,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "tensor([[-112.9418,   -8.2626,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [  98.0209,   77.8896,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [  57.4117,   13.4140,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [  20.0162,    4.8155,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000]])\n",
      "tensor([-0.1521,  0.2682,  0.1121,  0.0000,  0.0393,  0.0000,  0.0000])\n",
      "tensor([[-5.0538e-03,  3.1921e-01,  0.0000e+00,  0.0000e+00,  9.8109e-01,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.1786e+00,  6.4819e+00,  0.0000e+00,  0.0000e+00,  5.6032e-02,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4419e+00,  8.4943e+00,  2.6679e-01,  0.0000e+00,  2.8212e+01,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-5.2967e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.4610e+00,  5.6324e-02,  2.1998e+00,  0.0000e+00,  5.5837e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.1565e+00, -1.2606e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "tensor([ 0.6657,  1.7108,  5.6048, -3.1716, -0.5452, -2.6454,  0.0000])\n",
      "tensor([[ -2.8490, -10.3619, -12.4105,  -5.2890, -15.9904, -13.2045,   0.0000],\n",
      "        [  1.8182,   9.6202,   9.1034,   4.6145,  12.0952,  12.0023,   0.0000],\n",
      "        [  1.0309,   0.7417,   3.3071,   0.6745,   3.8952,   1.2022,   0.0000]])\n",
      "tensor([-19.8031,  13.0773,   6.7257])\n"
     ]
    }
   ],
   "source": [
    "for param in optimizer.param_groups[0]['params']:\n",
    "    if param.requires_grad:\n",
    "        print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIONS[np.random.choice(list(ACTIONS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  if epoch % 5 == 0:\n",
    "        # test model\n",
    "        macro_agent.q_network.eval()\n",
    "        test_env = Environment(test_data)\n",
    "        macro_agent.sell_assets(price=0)\n",
    "        current_balance = [0.0]\n",
    "        while not test_env.done:\n",
    "            now_state = test_env.get_state(macro_agent)\n",
    "            action = soft_argmax(macro_agent.q_network(now_state.unsqueeze(0)))\n",
    "            price = test_env.get_price()\n",
    "            print(action)\n",
    "            if torch.allclose(action, ACTIONS['BUY']):\n",
    "                prev_assets = macro_agent.estimate_assets(price)\n",
    "                macro_agent.buy_asset(price)\n",
    "                after_assets = macro_agent.estimate_assets(price)\n",
    "                current_balance.append(current_balance[-1] + after_assets - prev_assets)\n",
    "            elif torch.allclose(action,ACTIONS['SELL']):\n",
    "                earning = macro_agent.sell_assets(price)\n",
    "                current_balance.append(current_balance[-1] + earning)\n",
    "            else:\n",
    "                current_balance.append(current_balance[-1])\n",
    "            test_env.taken_action()\n",
    "        plt.plot(current_balance)\n",
    "        pd.DataFrame(current_balance).to_csv('macro_agent_epoch_{}.csv'.format(epoch))\n",
    "        plt.savefig('testing_epoch_{}.jpg'.format(epoch))\n",
    "\n",
    "        if current_balance[-1] > current_max_balance:\n",
    "            torch.save(macro_agent.q_network.state_dict(), 'best_q_net_epoch_{}'.format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b2bd16c4a5b7bdb943c513e9c5dbb440fb1e7bca9cf829d440576f5014c581f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
