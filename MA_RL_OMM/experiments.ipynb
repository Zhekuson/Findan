{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from macro_agent import MacroAgent, ReplayMemory, QNetwork, Transition\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "#from mpl_finance import candlestick_ohlc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime as datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPACITY = 500\n",
    "INIT_EPSILON = 0.4\n",
    "GAMMA_DISCOUNT = 0.8\n",
    "EPOCH_COUNT = 500\n",
    "MINI_BATCH_SIZE = 10\n",
    "WINDOW_SIZE = 20\n",
    "ACTIONS={\"HOLD\":0, \"SELL\":1, \"BUY\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, all_data):\n",
    "        self._all_data = all_data\n",
    "        self._pointer = 0\n",
    "        self.done = False\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def taken_action(self):\n",
    "        self._pointer += 1\n",
    "        if self._pointer >= len(self._all_data):\n",
    "            self.done = True\n",
    "        pass\n",
    "    \n",
    "    def get_price(self):\n",
    "        return self._all_data.iloc[self._pointer]['Close']\n",
    "\n",
    "    def get_change_zscore(self, column):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        frame = self._all_data.iloc[start_idx:self._pointer + 1]\n",
    "        market_now = self._all_data.iloc[self._pointer]\n",
    "        PC = market_now[column] / np.mean(frame[column]) - 1\n",
    "\n",
    "        PCs = np.empty_like(frame[column])\n",
    "        for i in range(start_idx, self._pointer + 1):\n",
    "            start_frame = np.max([0, i - WINDOW_SIZE])\n",
    "            end_frame = i\n",
    "            PCs[i - start_idx] = self._all_data.iloc[end_frame][column] / np.mean(\n",
    "                self._all_data.iloc[start_frame:end_frame+1][column]) - 1\n",
    "\n",
    "        z_score_price_change = (PC - np.mean(PCs)) / np.std(PCs) \n",
    "        return z_score_price_change\n",
    "\n",
    "    def get_EMA(self, t):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        g = 2 * self._all_data.iloc[t]['Close'] / (WINDOW_SIZE + 1)\n",
    "        ex = (100 - 2/(WINDOW_SIZE + 1))\n",
    "        EMA = g + np.mean(self._all_data.iloc[start_idx:t+1]['Close']) * ex\n",
    "        return EMA\n",
    "        \n",
    "\n",
    "    def get_indicators(self):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        market_now = self._all_data.iloc[self._pointer]\n",
    "        frame = self._all_data.iloc[start_idx:self._pointer + 1]\n",
    "        # price\n",
    "        z_score_price = (market_now['Close'] - \n",
    "            np.mean(frame['Close'])) / np.std(frame['Close'])\n",
    "        # price change\n",
    "        z_score_price_change = self.get_change_zscore('Close')\n",
    "        # volume\n",
    "        z_score_volume = (market_now['Volume'] - \n",
    "            np.mean(frame['Volume'])) / np.std(frame['Volume'])\n",
    "        # volume change\n",
    "        z_score_volume_change = self.get_change_zscore('Volume')\n",
    "        # Volatility\n",
    "        volatility = (self.get_EMA(self._pointer) -\n",
    "         self.get_EMA(self._pointer - WINDOW_SIZE))/ self.get_EMA(self._pointer - WINDOW_SIZE)\n",
    "        return z_score_price,z_score_price_change,z_score_volume,z_score_volume_change,volatility\n",
    "\n",
    "def decay_epsilon(cur_epsilon):\n",
    "    return cur_epsilon * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    market_data = pd.read_json('RESULT.json')\n",
    "    market_data.rename(columns={1:'Open',2:'High', 3:'Low', 4:'Close', 5:'Volume'}, inplace=True)\n",
    "    market_data[0] = market_data[0].transform(datetime.fromtimestamp)\n",
    "    market_data.set_index([0], inplace=True)\n",
    "    market_data.sort_index(inplace=True)\n",
    "    market_data = market_data[(market_data.index >= '2018-11-15 00:00:00') & (market_data.index <= '2018-11-17 17:06:00')]\n",
    "    return market_data\n",
    "\n",
    "def get_train_data(market_data):\n",
    "    return market_data[market_data.index <= '2018-11-16 00:00:00']\n",
    "\n",
    "def get_test_data(market_data):\n",
    "    return market_data[market_data.index >= '2018-11-16 00:00:00']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = ReplayMemory(CAPACITY)\n",
    "macro_agent = MacroAgent()\n",
    "optimizer = torch.optim.Adam(macro_agent.q_network.parameters())\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_algo(action):\n",
    "    if action == ACTIONS['SELL']:\n",
    "        if len(macro_agent.assets) == 0:\n",
    "            cur_reward = -1\n",
    "        else:\n",
    "            earning = np.sum(np.ones_like(macro_agent.assets) * environment.get_price() - macro_agent.assets)\n",
    "            cur_reward = 1 if earning > 0 else -1\n",
    "            macro_agent.sell_assets()\n",
    "    elif action == ACTIONS['BUY']:\n",
    "        np.append(macro_agent.assets, environment.get_price())\n",
    "        cur_reward = 0\n",
    "    else:\n",
    "        cur_reward = 0\n",
    "    return cur_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]C:\\Users\\Zhekuson\\AppData\\Local\\Temp/ipykernel_20120/2718687068.py:48: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  z_score_price = (market_now['Close'] -\n",
      "C:\\Users\\Zhekuson\\AppData\\Local\\Temp/ipykernel_20120/2718687068.py:32: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  z_score_price_change = (PC - np.mean(PCs)) / np.std(PCs)\n",
      "C:\\Users\\Zhekuson\\AppData\\Local\\Temp/ipykernel_20120/2718687068.py:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  z_score_volume = (market_now['Volume'] -\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'tuple' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20120/4178011665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mmacro_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmacro_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Zhekuson\\Documents\\Findan\\Findan\\MA_RL_OMM\\macro_agent.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mindicators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0massets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprice\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0massets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDQN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'tuple' and 'tuple'"
     ]
    }
   ],
   "source": [
    "market_data = load_data()\n",
    "train_data = get_train_data(market_data)\n",
    "for epoch in tqdm(range(EPOCH_COUNT)):\n",
    "    done = False\n",
    "    cur_epsilon = INIT_EPSILON\n",
    "    environment = Environment(train_data)\n",
    "    while not done:\n",
    "        now_state = [environment.get_price(), environment.get_indicators(), macro_agent.assets]\n",
    "        macro_agent.q_network.eval()\n",
    "        decision = np.random.rand()\n",
    "        if decision < cur_epsilon:\n",
    "            # epsilon\n",
    "            action = np.random.choice(3)\n",
    "        else:\n",
    "            # 1-epsilon\n",
    "            action = np.argmax(macro_agent.q_network(now_state).detach().numpy())\n",
    "        \n",
    "\n",
    "        # reward algo\n",
    "        cur_reward = reward_algo(action)\n",
    "\n",
    "        environment.taken_action()\n",
    "\n",
    "        next_state = [environment.get_price(), environment.get_indicators(), macro_agent.assets]\n",
    "        done = environment.done\n",
    "        \n",
    "        replay_memory.push(now_state, action, cur_reward, next_state, done)\n",
    "        \n",
    "        batch = replay_memory.sample(np.min([MINI_BATCH_SIZE, len(replay_memory.memory)]))\n",
    "        \n",
    "        q = np.empty(MINI_BATCH_SIZE)\n",
    "        learning_input = np.empty(MINI_BATCH_SIZE, dtype=list)\n",
    "        for i, object in enumerate(batch):\n",
    "            learning_input[i] = [object.state[0], object.state[1], object.state[2]]\n",
    "            if not object.done:\n",
    "                input = [object.next_state[0], object.next_state[1], object.next_state[2]]\n",
    "                act = np.argmax(macro_agent.q_network.forward(input).detach().numpy())\n",
    "                q[i] = object.reward + GAMMA_DISCOUNT * reward_algo(act)\n",
    "            else:\n",
    "                q[i] = object.reward\n",
    "        \n",
    "        macro_agent.q_network.train()\n",
    "        loss = criterion(q, macro_agent.q_network.forward(learning_input))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cur_epsilon = decay_epsilon(cur_epsilon)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b2bd16c4a5b7bdb943c513e9c5dbb440fb1e7bca9cf829d440576f5014c581f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
