{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from macro_agent import MacroAgent, ReplayMemory, QNetwork, Transition\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "#from mpl_finance import candlestick_ohlc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime as datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPACITY = 500\n",
    "INIT_EPSILON = 0.99\n",
    "GAMMA_DISCOUNT = 0.8\n",
    "EPOCH_COUNT = 500\n",
    "MINI_BATCH_SIZE = 1\n",
    "WINDOW_SIZE = 20\n",
    "ALPHA = 10000\n",
    "ACTIONS={\"BUY\":torch.tensor([1,0,0], dtype=torch.float32),\n",
    " \"HOLD\":torch.tensor([0,1,0], dtype=torch.float32),\n",
    "  \"SELL\":torch.tensor([0,0,1], dtype=torch.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, all_data):\n",
    "        self._all_data = all_data\n",
    "        self._pointer = WINDOW_SIZE\n",
    "        self.done = False\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def taken_action(self):\n",
    "        self._pointer += 1\n",
    "        if self._pointer >= len(self._all_data) - 1:\n",
    "            self.done = True\n",
    "        pass\n",
    "    \n",
    "    def get_price(self):\n",
    "        return self._all_data.iloc[self._pointer]['Close']\n",
    "\n",
    "    def get_change_zscore(self, column):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        frame = self._all_data.iloc[start_idx:self._pointer + 1]\n",
    "        market_now = self._all_data.iloc[self._pointer]\n",
    "        PC = market_now[column] / np.mean(frame[column]) - 1\n",
    "\n",
    "        PCs = np.empty_like(frame[column])\n",
    "        for i in range(start_idx, self._pointer + 1):\n",
    "            start_frame = np.max([0, i - WINDOW_SIZE])\n",
    "            end_frame = i\n",
    "            PCs[i - start_idx] = self._all_data.iloc[end_frame][column] / np.mean(\n",
    "                self._all_data.iloc[start_frame:end_frame+1][column]) - 1\n",
    "\n",
    "        z_score_price_change = (PC - np.mean(PCs)) / np.std(PCs) \n",
    "        return z_score_price_change\n",
    "\n",
    "    def get_EMA(self, t):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        g = 2 * self._all_data.iloc[t]['Close'] / (WINDOW_SIZE + 1)\n",
    "        ex = (100 - 2/(WINDOW_SIZE + 1))\n",
    "        EMA = g + np.mean(self._all_data.iloc[start_idx:t+1]['Close']) * ex\n",
    "        return EMA\n",
    "        \n",
    "\n",
    "    def get_indicators(self):\n",
    "        start_idx = np.max([0, self._pointer - WINDOW_SIZE])\n",
    "        market_now = self._all_data.iloc[self._pointer]\n",
    "        frame = self._all_data.iloc[start_idx:self._pointer + 1]\n",
    "        # price\n",
    "        z_score_price = (market_now['Close'] - \n",
    "            np.mean(frame['Close'])) / np.std(frame['Close'])\n",
    "        # price change\n",
    "        z_score_price_change = self.get_change_zscore('Close')\n",
    "        # volume\n",
    "        z_score_volume = (market_now['Volume'] - \n",
    "            np.mean(frame['Volume'])) / np.std(frame['Volume'])\n",
    "        # volume change\n",
    "        z_score_volume_change = self.get_change_zscore('Volume')\n",
    "        # Volatility\n",
    "        volatility = (self.get_EMA(self._pointer) -\n",
    "         self.get_EMA(self._pointer - WINDOW_SIZE))/ self.get_EMA(self._pointer - WINDOW_SIZE)\n",
    "        return z_score_price,z_score_price_change,z_score_volume,z_score_volume_change,volatility\n",
    "\n",
    "    def get_state(self, agent:MacroAgent):\n",
    "        return torch.tensor(np.hstack((self.get_price(), self.get_indicators(),\n",
    "            agent.estimate_assets(self.get_price()))), dtype=torch.float32)\n",
    "\n",
    "def decay_epsilon(cur_epsilon):\n",
    "    return cur_epsilon * 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    market_data = pd.read_json('RESULT.json')\n",
    "    market_data.rename(columns={1:'Open',2:'High', 3:'Low', 4:'Close', 5:'Volume'}, inplace=True)\n",
    "    market_data[0] = market_data[0].transform(datetime.fromtimestamp)\n",
    "    market_data.set_index([0], inplace=True)\n",
    "    market_data.sort_index(inplace=True)\n",
    "    market_data = market_data[(market_data.index >= '2018-11-15 00:00:00') & (market_data.index <= '2018-11-17 17:06:00')]\n",
    "    return market_data\n",
    "\n",
    "def get_train_data(market_data):\n",
    "    return market_data[market_data.index <= '2018-11-16 00:00:00']\n",
    "\n",
    "def get_test_data(market_data):\n",
    "    return market_data[market_data.index >= '2018-11-16 00:00:00']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = ReplayMemory(CAPACITY)\n",
    "macro_agent = MacroAgent()\n",
    "optimizer = torch.optim.Adam(macro_agent.q_network.parameters())\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(chosen_action, estimated_assets):\n",
    "    if torch.allclose(chosen_action,ACTIONS['SELL']):\n",
    "        if  estimated_assets == 0:\n",
    "            return -1\n",
    "        else: \n",
    "            return 1 if estimated_assets > 0 else -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_best_reward(next_state):\n",
    "    sell_reward = calculate_reward(ACTIONS['SELL'], next_state[6])\n",
    "    buy_reward = calculate_reward(ACTIONS['BUY'], next_state[6])\n",
    "    hold_reward = calculate_reward(ACTIONS['HOLD'], next_state[6])\n",
    "    if sell_reward >= buy_reward and  sell_reward >= hold_reward:\n",
    "        return (ACTIONS['SELL'], sell_reward)\n",
    "    elif buy_reward >= sell_reward and buy_reward >= hold_reward:\n",
    "        return (ACTIONS['BUY'], buy_reward)\n",
    "    else:\n",
    "        return (ACTIONS['HOLD'], hold_reward)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]C:\\Users\\Zhekuson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [01:56<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([0., 1., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27908/3091922608.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mcurrent_balance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mnow_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmacro_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmacro_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_price\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27908/1667005082.py\u001b[0m in \u001b[0;36mget_state\u001b[1;34m(self, agent)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mMacroAgent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         return torch.tensor(np.hstack((self.get_price(), self.get_indicators(),\n\u001b[0m\u001b[0;32m     64\u001b[0m             agent.estimate_assets(self.get_price()))), dtype=torch.float32)\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "replay_memory = ReplayMemory(CAPACITY)\n",
    "macro_agent = MacroAgent()\n",
    "optimizer = torch.optim.Adam(macro_agent.q_network.parameters())\n",
    "criterion = nn.L1Loss()\n",
    "market_data = load_data()\n",
    "train_data = get_train_data(market_data)\n",
    "test_data = get_test_data(market_data)\n",
    "current_max_balance = 0\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(EPOCH_COUNT)):\n",
    "    done = False\n",
    "    cur_epsilon = INIT_EPSILON\n",
    "    environment = Environment(train_data)\n",
    "    macro_agent.sell_assets(0)\n",
    "    while not done:\n",
    "        now_state = environment.get_state(macro_agent)\n",
    "        macro_agent.q_network.eval()\n",
    "        decision = np.random.rand()\n",
    "        if decision < cur_epsilon:\n",
    "            # epsilon\n",
    "            action = ACTIONS[np.random.choice(list(ACTIONS))]\n",
    "            est_assets = macro_agent.estimate_assets(environment.get_price())\n",
    "            cur_reward = calculate_reward(action, est_assets)\n",
    "        else:\n",
    "            # 1-epsilon\n",
    "            action, cur_reward = macro_agent.q_network(now_state)\n",
    "        \n",
    "\n",
    "        # reward algo\n",
    "        environment.taken_action()\n",
    "        next_state = environment.get_state(macro_agent)\n",
    "        done = environment.done\n",
    "        \n",
    "        replay_memory.push(now_state, action, cur_reward, next_state, done)\n",
    "        \n",
    "        # taking batch\n",
    "        batch = replay_memory.sample(MINI_BATCH_SIZE)\n",
    "        q = []\n",
    "        current_states_batch = []\n",
    "\n",
    "        for i, object in enumerate(batch):\n",
    "            current_states_batch.append(object.state)\n",
    "            if not object.done:\n",
    "                # r_i + gamma * Q()\n",
    "                q.append(object.action + GAMMA_DISCOUNT * get_best_reward(object.next_state)[0])\n",
    "            else:\n",
    "                # r_i\n",
    "                q.append(object.action)\n",
    "        # grad d\n",
    "        macro_agent.q_network.train()\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        for batch_state in current_states_batch:\n",
    "            rewards.append(macro_agent.q_network(batch_state))\n",
    "            actions.append(macro_agent.q_network.DQN.forward(batch_state))\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "        for i in range(len(rewards)):\n",
    "            loss = criterion(actions[i], q[i])\n",
    "            loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        cur_epsilon = decay_epsilon(cur_epsilon)  \n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        # test model\n",
    "        macro_agent.q_network.eval()\n",
    "        test_env = Environment(test_data)\n",
    "        macro_agent.sell_assets(price=0)\n",
    "        current_balance = [0.0]\n",
    "        while not test_env.done:\n",
    "            now_state = test_env.get_state(macro_agent)\n",
    "            action, _ = macro_agent.q_network(now_state)\n",
    "            price = test_env.get_price()\n",
    "            print(action)\n",
    "            if torch.allclose(action, ACTIONS['BUY']):\n",
    "                print('time to buy')\n",
    "                prev_assets = macro_agent.estimate_assets(price)\n",
    "                macro_agent.buy_asset(price)\n",
    "                after_assets = macro_agent.estimate_assets(price)\n",
    "                print(after_assets)\n",
    "                current_balance.append(current_balance[-1] + after_assets - prev_assets)\n",
    "            elif torch.allclose(action,ACTIONS['SELL']):\n",
    "                earning = macro_agent.sell_assets(price)\n",
    "                current_balance.append(current_balance[-1] + earning)\n",
    "            else:\n",
    "                current_balance.append(current_balance[-1])\n",
    "            test_env.taken_action()\n",
    "        plt.plot(current_balance)\n",
    "        pd.DataFrame(current_balance).to_csv('macro_agent_epoch_{}.csv'.format(epoch))\n",
    "        plt.savefig('testing_epoch_{}.jpg'.format(epoch))\n",
    "\n",
    "        if current_balance[-1] > current_max_balance:\n",
    "            torch.save(macro_agent.q_network.state_dict(), 'best_q_net_epoch_{}'.format(epoch))\n",
    "\n",
    "    \n",
    "  \n",
    "    torch.save(macro_agent.q_network.state_dict(), 'q_net_epoch_{}'.format(epoch))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4187e-26,  3.3881e-29,  2.1245e-29, -1.2799e-28, -1.3656e-28,\n",
      "          3.9978e-31,  0.0000e+00],\n",
      "        [ 2.4573e-26,  5.8683e-29,  3.6797e-29, -2.2168e-28, -2.3652e-28,\n",
      "          6.9243e-31,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.3484e-26, -7.9966e-29, -5.0142e-29,  3.0208e-28,  3.2230e-28,\n",
      "         -9.4356e-31,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "tensor([ 1.8766e-30,  3.2504e-30,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -4.4292e-30,  0.0000e+00])\n",
      "tensor([[ 5.2910e-27,  2.6274e-26,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          2.2747e-26,  0.0000e+00],\n",
      "        [-9.0931e-27, -4.5155e-26,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.9093e-26,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.4235e-27, -1.2035e-26,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0419e-26,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 9.9613e-28,  4.9467e-27,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          4.2825e-27,  0.0000e+00]])\n",
      "tensor([ 1.3178e-29, -2.2648e-29,  0.0000e+00, -6.0363e-30,  0.0000e+00,\n",
      "         0.0000e+00,  2.4811e-30])\n",
      "tensor([[ 7.8554e-27,  2.5742e-27,  0.0000e+00,  1.4212e-26,  0.0000e+00,\n",
      "          0.0000e+00,  1.3894e-26],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.4415e-26, -4.7239e-27,  0.0000e+00, -2.6079e-26,  0.0000e+00,\n",
      "          0.0000e+00, -2.5497e-26],\n",
      "        [-2.7752e-27, -9.0944e-28,  0.0000e+00, -5.0208e-27,  0.0000e+00,\n",
      "          0.0000e+00, -4.9087e-27],\n",
      "        [ 1.7728e-26,  5.8096e-27,  0.0000e+00,  3.2074e-26,  0.0000e+00,\n",
      "          0.0000e+00,  3.1358e-26],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "tensor([ 1.4772e-29,  0.0000e+00,  0.0000e+00, -2.7108e-29, -5.2187e-30,\n",
      "         3.3338e-29,  0.0000e+00])\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2528e-26, 0.0000e+00, 0.0000e+00, 4.2211e-26, 2.5264e-26, 3.1595e-26,\n",
      "         0.0000e+00]])\n",
      "tensor([0.0000e+00, 0.0000e+00, 9.4604e-29])\n"
     ]
    }
   ],
   "source": [
    "for param in optimizer.param_groups[0]['params']:\n",
    "    if param.requires_grad:\n",
    "        print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIONS[np.random.choice(list(ACTIONS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " -0.00021484374974534148,\n",
       " -0.0003906249994543032,\n",
       " -0.0003906249994543032,\n",
       " -0.00037109374989086064,\n",
       " -0.00037109374989086064,\n",
       " -0.0003125000002910383,\n",
       " -0.00023437500021827873,\n",
       " -0.00042968750040017767,\n",
       " -0.0003125000002910383,\n",
       " -0.000546875000509317,\n",
       " -0.0004492187508731149,\n",
       " -0.0004492187508731149,\n",
       " -0.0005664062509822543,\n",
       " -0.0003515625012369128,\n",
       " -0.00037109375080035534,\n",
       " -0.0006054687510186341,\n",
       " -0.000800781251200533,\n",
       " -0.0008593750008003553,\n",
       " -0.0008203125007639755,\n",
       " -0.0008203125007639755,\n",
       " -0.0006054687510186341,\n",
       " -0.0006250000005820766,\n",
       " -0.0008203125007639755,\n",
       " -0.0010156250009458745,\n",
       " -0.0011523437506184564,\n",
       " -0.0009960937504729372,\n",
       " -0.0008398437503274181,\n",
       " -0.0006835937501818989,\n",
       " -0.0007617187502546585,\n",
       " -0.0009570312504365575,\n",
       " -0.0009570312504365575,\n",
       " -0.0009570312504365575,\n",
       " -0.0009765625,\n",
       " -0.001113281249672582,\n",
       " -0.0010937500001091394,\n",
       " -0.0011328125001455192,\n",
       " -0.0011328125001455192,\n",
       " -0.0009179687504001777,\n",
       " -0.0009179687504001777,\n",
       " -0.0009765625,\n",
       " -0.0011328125001455192,\n",
       " -0.0011328125001455192,\n",
       " -0.0011328125001455192,\n",
       " -0.0011328125001455192,\n",
       " -0.0011328125001455192,\n",
       " -0.001035156250509317,\n",
       " -0.0008984375008367351,\n",
       " -0.0009179687504001777,\n",
       " -0.0010156250000363798,\n",
       " -0.0009765625,\n",
       " -0.0009179687504001777,\n",
       " -0.0009570312504365575,\n",
       " -0.0010937500001091394,\n",
       " -0.0012890625002910383,\n",
       " -0.0011914062506548362,\n",
       " -0.0012109375002182787,\n",
       " -0.0014062500004001777,\n",
       " -0.001328125000327418,\n",
       " -0.0014453125004365575,\n",
       " -0.0015625000005456968,\n",
       " -0.0016796875006548362,\n",
       " -0.0018359375008003553,\n",
       " -0.0016796875006548362,\n",
       " -0.0015039062509458745,\n",
       " -0.0015039062509458745,\n",
       " -0.0014062500013096724,\n",
       " -0.0013671875012732926,\n",
       " -0.0013281250012369128,\n",
       " -0.0012109375011277734,\n",
       " -0.001425781250873115,\n",
       " -0.0013476562508003553,\n",
       " -0.0015429687509822543,\n",
       " -0.0016796875006548362,\n",
       " -0.001816406250327418,\n",
       " -0.001816406250327418,\n",
       " -0.0017968750007639755,\n",
       " -0.0015625000005456968,\n",
       " -0.001328125000327418,\n",
       " -0.001328125000327418,\n",
       " -0.001328125000327418,\n",
       " -0.001328125000327418,\n",
       " -0.0010937500001091394,\n",
       " -0.001269531249818101,\n",
       " -0.0012109375002182787,\n",
       " -0.0011328125001455192,\n",
       " -0.0010546875000727596,\n",
       " -0.001035156250509317,\n",
       " -0.0008007812502910383,\n",
       " -0.0008007812502910383,\n",
       " -0.0008007812502910383,\n",
       " -0.0008789062503637979,\n",
       " -0.0011132812505820766,\n",
       " -0.001093750001018634,\n",
       " -0.0010742187514551915,\n",
       " -0.001054687501891749,\n",
       " -0.00085937500170985,\n",
       " -0.0006640625015279511,\n",
       " -0.0006640625015279511,\n",
       " -0.000566406251891749,\n",
       " -0.00046875000225554686,\n",
       " -0.00037109375261934474,\n",
       " -0.0005078125022919266,\n",
       " -0.0006445312519645086,\n",
       " -0.0007031250015643309,\n",
       " -0.0008789062512732926,\n",
       " -0.0008984375008367351,\n",
       " -0.0007812500007275958,\n",
       " -0.0009570312504365575,\n",
       " -0.0011328125001455192,\n",
       " -0.0013085937498544808,\n",
       " -0.0014843749995634425,\n",
       " -0.0013281249994179234,\n",
       " -0.0013671874994543032,\n",
       " -0.0014257812490541255,\n",
       " -0.0012499999993451638,\n",
       " -0.0013085937489449861,\n",
       " -0.0013671874985448085,\n",
       " -0.0014257812481446308,\n",
       " -0.0014453124977080734,\n",
       " -0.0014257812481446308,\n",
       " -0.0012109374983992893,\n",
       " -0.0009765624981810106,\n",
       " -0.00109374999829015,\n",
       " -0.0011328124983265297,\n",
       " -0.0009179687485811883,\n",
       " -0.0009179687485811883,\n",
       " -0.0007226562483992893,\n",
       " -0.0004882812481810106,\n",
       " -0.00029296874799911166,\n",
       " -0.0005273437482173904,\n",
       " -0.0007617187484356691,\n",
       " -0.000957031248617568,\n",
       " -0.001152343748799467,\n",
       " -0.0009960937486539478,\n",
       " -0.0009960937486539478,\n",
       " -0.0009179687485811883,\n",
       " -0.0008398437485084287,\n",
       " -0.0009960937486539478,\n",
       " -0.0010546874982537702,\n",
       " -0.0010546874982537702,\n",
       " -0.0012109374983992893,\n",
       " -0.0013281249994179234,\n",
       " -0.0015234374986903276,\n",
       " -0.0016601562492724042,\n",
       " -0.0016796874988358468,\n",
       " -0.0017187499979627319,\n",
       " -0.0016796874988358468,\n",
       " -0.0017773437466530595,\n",
       " -0.0015820312473806553,\n",
       " -0.0016796874970168574,\n",
       " -0.0014453124967985786,\n",
       " -0.001386718748108251,\n",
       " -0.001386718748108251,\n",
       " -0.001289062498472049,\n",
       " -0.001289062498472049,\n",
       " -0.0014648437481810106,\n",
       " -0.0014648437481810106,\n",
       " -0.0014648437481810106,\n",
       " -0.0016796874988358468,\n",
       " -0.0017187499961437425,\n",
       " -0.0017187499961437425,\n",
       " -0.0016992187465803,\n",
       " -0.0014648437463620212,\n",
       " -0.0014453124967985786,\n",
       " -0.0014062499976716936,\n",
       " -0.0014843749959254637,\n",
       " -0.0015429687464347808,\n",
       " -0.0015429687464347808,\n",
       " -0.0016601562456344254,\n",
       " -0.0016015624969440978,\n",
       " -0.001796874996216502,\n",
       " -0.0015820312473806553,\n",
       " -0.0014843749977444531,\n",
       " -0.0014843749977444531,\n",
       " -0.00146484375,\n",
       " -0.0016210937501455192,\n",
       " -0.0017187499979627319,\n",
       " -0.0018164062494179234,\n",
       " -0.0020117187486903276,\n",
       " -0.001835937498981366,\n",
       " -0.0016992187483992893,\n",
       " -0.0016992187483992893,\n",
       " -0.0017187499979627319,\n",
       " -0.0015820312491996447,\n",
       " -0.0014453125004365575,\n",
       " -0.0016015625005820766,\n",
       " -0.0017578125007275958,\n",
       " -0.0017187499997817213,\n",
       " -0.0014843749995634425,\n",
       " -0.0015234374986903276,\n",
       " -0.001347656248981366,\n",
       " -0.0012890625002910383,\n",
       " -0.001152343751527951,\n",
       " -0.0013867187517462298,\n",
       " -0.0016015625005820766,\n",
       " -0.0018164062512369128,\n",
       " -0.002031250001891749,\n",
       " -0.0022460937507275958,\n",
       " -0.0024609374995634425,\n",
       " -0.0026757812502182787,\n",
       " -0.002890625000873115,\n",
       " -0.0029101562504365575,\n",
       " -0.0029296875,\n",
       " -0.0029492187495634425,\n",
       " -0.002968749999126885,\n",
       " -0.002851562498108251,\n",
       " -0.002617187496070983,\n",
       " -0.0023828124976716936,\n",
       " -0.002148437497453415,\n",
       " -0.0023242187471623765,\n",
       " -0.0022460937489086064,\n",
       " -0.0021679687470168574,\n",
       " -0.0023242187471623765,\n",
       " -0.0024804687473078957,\n",
       " -0.002285156246216502,\n",
       " -0.0022265624975261744,\n",
       " -0.0022265624975261744,\n",
       " -0.0022265624975261744,\n",
       " -0.0021289062478899723,\n",
       " -0.002363281248108251,\n",
       " -0.002363281248108251,\n",
       " -0.0025390624978172127,\n",
       " -0.002734374997089617,\n",
       " -0.002773437496216502,\n",
       " -0.002929687496362021,\n",
       " -0.002734374997089617,\n",
       " -0.002773437496216502,\n",
       " -0.0028124999971623765,\n",
       " -0.0029101562467985786,\n",
       " -0.0027539062466530595,\n",
       " -0.002617187496070983,\n",
       " -0.002812499996252882,\n",
       " -0.0030468749964711606,\n",
       " -0.0032421874966530595,\n",
       " -0.003261718746216502,\n",
       " -0.003261718746216502,\n",
       " -0.00349609374825377,\n",
       " -0.003261718746216502,\n",
       " -0.003261718746216502,\n",
       " -0.0030273437459982233,\n",
       " -0.002812499995343387,\n",
       " -0.002578124996944098,\n",
       " -0.002714843745707185,\n",
       " -0.002617187496070983,\n",
       " -0.0026757812447613105,\n",
       " -0.0029101562467985786,\n",
       " -0.0031445312470168574,\n",
       " -0.003281249997598934,\n",
       " -0.0031445312470168574,\n",
       " -0.0030273437478172127,\n",
       " -0.0030273437478172127,\n",
       " -0.0030273437478172127,\n",
       " -0.0030273437478172127,\n",
       " -0.0031054687478899723,\n",
       " -0.003339843748108251,\n",
       " -0.0035742187492360245,\n",
       " -0.0035742187492360245,\n",
       " -0.0035937499997089617,\n",
       " -0.0034374999995634425,\n",
       " -0.0034374999995634425,\n",
       " -0.0034374999995634425,\n",
       " -0.0036132812492724042,\n",
       " -0.003554687499672582,\n",
       " -0.003652343749308784,\n",
       " -0.003652343749308784,\n",
       " -0.0038867187495270628,\n",
       " -0.00386718749996362,\n",
       " -0.0038867187495270628,\n",
       " -0.0038867187495270628,\n",
       " -0.004101562499272404,\n",
       " -0.004042968749672582,\n",
       " -0.004023437500109139,\n",
       " -0.004003906250545697,\n",
       " -0.0038476562504001777,\n",
       " -0.00394531250003638,\n",
       " -0.0037890624998908606,\n",
       " -0.004023437500109139,\n",
       " -0.004042968749672582,\n",
       " -0.0041210937497453415,\n",
       " -0.004335937499490683,\n",
       " -0.0045507812492360245,\n",
       " -0.004785156249454303,\n",
       " -0.005019531249672582,\n",
       " -0.004863281249527063,\n",
       " -0.004941406249599822,\n",
       " -0.005019531249672582,\n",
       " -0.004863281249527063,\n",
       " -0.0050976562497453415,\n",
       " -0.005253906249890861,\n",
       " -0.005136718749781721,\n",
       " -0.005195312498472049,\n",
       " -0.005097656250654836,\n",
       " -0.005273437500363798,\n",
       " -0.005507812498763087,\n",
       " -0.005507812498763087,\n",
       " -0.005742187500800355,\n",
       " -0.0058789062495634425,\n",
       " -0.0058203124990541255,\n",
       " -0.005761718750363798,\n",
       " -0.005761718750363798,\n",
       " -0.005605468750218279,\n",
       " -0.00544921875007276,\n",
       " -0.005214843749854481,\n",
       " -0.005019531248763087,\n",
       " -0.00503906249832653,\n",
       " -0.005058593747889972,\n",
       " -0.004941406248690328,\n",
       " -0.004746093747598934,\n",
       " -0.004589843747453415,\n",
       " -0.004433593747307896,\n",
       " -0.004199218748908606,\n",
       " -0.004218749998472049,\n",
       " -0.0042382812480354914,\n",
       " -0.004257812497598934,\n",
       " -0.004394531246362021,\n",
       " -0.004296874996725819,\n",
       " -0.004296874996725819,\n",
       " -0.004433593747307896,\n",
       " -0.004472656246434781,\n",
       " -0.004316406246289262,\n",
       " -0.004316406246289262,\n",
       " -0.00455078124650754,\n",
       " -0.0046874999952706276,\n",
       " -0.0046484374961437425,\n",
       " -0.004609374997016857,\n",
       " -0.004570312496070983,\n",
       " -0.004531249995125108,\n",
       " -0.004492187495998223,\n",
       " -0.004726562496216502,\n",
       " -0.004843749995416147,\n",
       " -0.004609374997016857,\n",
       " -0.004374999994979589,\n",
       " -0.0041406249965803,\n",
       " -0.004101562495634425,\n",
       " -0.004062499994688551,\n",
       " -0.004023437495561666,\n",
       " -0.003984374996434781,\n",
       " -0.0041992187452706276,\n",
       " -0.0041992187452706276,\n",
       " -0.004433593745488906,\n",
       " -0.0046289062465803,\n",
       " -0.004824218745852704,\n",
       " -0.005058593746070983,\n",
       " -0.005292968746289262,\n",
       " -0.00552734374650754,\n",
       " -0.005468749995998223,\n",
       " -0.005234374997598934,\n",
       " -0.004999999995561666,\n",
       " -0.005019531245125108,\n",
       " -0.0051171874965803,\n",
       " -0.0051171874965803,\n",
       " -0.00496093750007276,\n",
       " -0.004921874999126885,\n",
       " -0.004882812498181011,\n",
       " -0.0048437499990541255,\n",
       " -0.004609374998835847,\n",
       " -0.0043750000004365575,\n",
       " -0.00439453125,\n",
       " -0.004160156247962732,\n",
       " -0.0039257812495634425,\n",
       " -0.0039257812495634425,\n",
       " -0.0039257812495634425,\n",
       " -0.0037304687502910383,\n",
       " -0.003964843748690328,\n",
       " -0.004140624998399289,\n",
       " -0.004042968750582077,\n",
       " -0.004277343748981366,\n",
       " -0.004511718749199645,\n",
       " -0.004746093749417923,\n",
       " -0.004570312499708962,\n",
       " -0.0043750000004365575,\n",
       " -0.004550781250145519,\n",
       " -0.00439453125,\n",
       " -0.004179687499345164,\n",
       " -0.003945312499126885,\n",
       " -0.003710937497089617,\n",
       " -0.0037304687502910383,\n",
       " -0.00349609374825377,\n",
       " -0.0034179687481810106,\n",
       " -0.0033593749976716936,\n",
       " -0.003300781248981366,\n",
       " -0.0032421875002910383,\n",
       " -0.0031835937497817213,\n",
       " -0.003378906250873115,\n",
       " -0.003320312500363798,\n",
       " -0.0035546875005820766,\n",
       " -0.0035546875005820766,\n",
       " -0.0035546875005820766,\n",
       " -0.0035546875005820766,\n",
       " -0.0035546875005820766,\n",
       " -0.0033203124985448085,\n",
       " -0.0033203124985448085,\n",
       " -0.003085937500145519,\n",
       " -0.003085937500145519,\n",
       " -0.003085937500145519,\n",
       " -0.003085937500145519,\n",
       " -0.003085937500145519,\n",
       " -0.003085937500145519,\n",
       " -0.003085937500145519,\n",
       " -0.003085937500145519,\n",
       " -0.003085937500145519,\n",
       " -0.0033203125021827873,\n",
       " -0.0035546875005820766,\n",
       " -0.003535156251018634,\n",
       " -0.003769531253055902,\n",
       " -0.0040039062514551915,\n",
       " -0.003945312502764864,\n",
       " -0.0038867187540745363,\n",
       " -0.0038281250035652192,\n",
       " -0.0036718750034197,\n",
       " -0.0036718750034197,\n",
       " -0.003906250003637979,\n",
       " -0.0041406250038562575,\n",
       " -0.004375000004074536,\n",
       " -0.004316406255384209,\n",
       " -0.004121093754292815,\n",
       " -0.003925781253201421,\n",
       " -0.003730468753929017,\n",
       " -0.0037890625026193447,\n",
       " -0.003613281252910383,\n",
       " -0.0033789062545110937,\n",
       " -0.003359375004947651,\n",
       " -0.0031835937552386895,\n",
       " -0.003144531254292815,\n",
       " -0.003300781254438334,\n",
       " -0.003535156254656613,\n",
       " -0.0037695312548748916,\n",
       " -0.0037109375043655746,\n",
       " -0.003750000005311449,\n",
       " -0.003535156254656613,\n",
       " -0.0034765625059662852,\n",
       " -0.0036718750052386895,\n",
       " -0.003613281256548362,\n",
       " -0.0034765625059662852,\n",
       " -0.0035546875078580342,\n",
       " -0.003652343755675247,\n",
       " -0.0035742187574214768,\n",
       " -0.003730468757566996,\n",
       " -0.0037109375080035534,\n",
       " -0.0036328125061118044,\n",
       " -0.0037890625062573235,\n",
       " -0.003769531256693881,\n",
       " -0.0037500000071304385,\n",
       " -0.003730468757566996,\n",
       " -0.0035742187574214768,\n",
       " -0.0036718750088766683,\n",
       " -0.003789062508076313,\n",
       " -0.003906250007275958,\n",
       " -0.003906250007275958,\n",
       " -0.0036718750052386895,\n",
       " -0.0036718750052386895,\n",
       " -0.003691406254802132,\n",
       " -0.0036718750052386895,\n",
       " -0.0038281250053842086,\n",
       " -0.0037304687557480065,\n",
       " -0.003925781255020411,\n",
       " -0.00408203125516593,\n",
       " -0.00408203125516593,\n",
       " -0.00408203125516593,\n",
       " -0.004316406255384209,\n",
       " -0.004199218756184564,\n",
       " -0.004023437506475602,\n",
       " -0.0038867187568030204,\n",
       " -0.0039843750064392225,\n",
       " -0.004082031256075425,\n",
       " -0.003906250007275958,\n",
       " -0.003730468757566996,\n",
       " -0.003730468757566996,\n",
       " -0.003730468757566996,\n",
       " -0.0035546875078580342,\n",
       " -0.0036718750079671736,\n",
       " -0.003652343758403731,\n",
       " -0.003652343758403731,\n",
       " -0.003652343758403731,\n",
       " -0.003652343758403731,\n",
       " -0.003652343758403731,\n",
       " -0.0038867187586220098,\n",
       " -0.0041210937588402885,\n",
       " -0.0041210937588402885,\n",
       " -0.0043554687581490725,\n",
       " -0.004589843758367351,\n",
       " -0.0043554687581490725,\n",
       " -0.004589843758367351,\n",
       " -0.004589843758367351,\n",
       " -0.004394531257275958,\n",
       " -0.004433593758221832,\n",
       " -0.004199218756184564,\n",
       " -0.003984375007348717,\n",
       " -0.004023437506475602,\n",
       " -0.0038085937576397555,\n",
       " -0.0035937500088039087,\n",
       " -0.003632812507930794,\n",
       " -0.003417968759094947,\n",
       " -0.003203125008440111,\n",
       " -0.003203125008440111,\n",
       " -0.003203125008440111,\n",
       " -0.0031054687588039087,\n",
       " -0.0032421875093859853,\n",
       " -0.003085937509240466,\n",
       " -0.003085937509240466,\n",
       " -0.003085937509240466,\n",
       " -0.003085937509240466,\n",
       " -0.003085937509240466,\n",
       " -0.0028906250081490725,\n",
       " -0.0028906250081490725,\n",
       " -0.0028906250081490725,\n",
       " -0.0028906250081490725,\n",
       " -0.0029882812577852746,\n",
       " -0.0028906250081490725,\n",
       " -0.0027929687585128704,\n",
       " -0.0026953125088766683,\n",
       " -0.0028515625090221874,\n",
       " -0.0030078125091677066,\n",
       " -0.0031640625093132257,\n",
       " -0.0031640625093132257,\n",
       " -0.0033984375095315045,\n",
       " -0.003183593759786163,\n",
       " -0.002988281259604264,\n",
       " -0.0031054687597134034,\n",
       " -0.0032617187598589226,\n",
       " -0.003378906259968062,\n",
       " -0.0034960937600772013,\n",
       " -0.0036132812601863407,\n",
       " -0.0037109375098225428,\n",
       " -0.003808593759458745,\n",
       " -0.003808593759458745,\n",
       " -0.003769531259422365,\n",
       " -0.003964843759604264,\n",
       " -0.003925781259567884,\n",
       " -0.004121093759749783,\n",
       " -0.004316406259931682,\n",
       " -0.004511718760113581,\n",
       " -0.004472656260077201,\n",
       " -0.00425781251033186,\n",
       " -0.00429687501036824,\n",
       " -0.004082031260622898,\n",
       " -0.0038671875108775566,\n",
       " -0.003652343761132215,\n",
       " -0.0034375000113868737,\n",
       " -0.0036328125115687726,\n",
       " -0.0035742187619689503,\n",
       " -0.003750000011677912,\n",
       " -0.003925781261386874,\n",
       " -0.0039648437614232535,\n",
       " -0.004023437511023076,\n",
       " -0.004218750011204975,\n",
       " -0.0044531250114232535,\n",
       " -0.004687500011641532,\n",
       " -0.004707031261204975,\n",
       " -0.0047460937612413545,\n",
       " -0.004531250011496013,\n",
       " -0.0043164062617506715,\n",
       " -0.0043164062617506715,\n",
       " -0.004531250011496013,\n",
       " -0.0047460937612413545,\n",
       " -0.0047460937612413545,\n",
       " -0.004980468761459633,\n",
       " -0.005214843761677912,\n",
       " -0.005214843761677912,\n",
       " -0.005214843760768417,\n",
       " -0.005449218760986696,\n",
       " -0.005683593761204975,\n",
       " -0.0059179687614232535,\n",
       " -0.005761718761277734,\n",
       " -0.005898437510950316,\n",
       " -0.005781250010841177,\n",
       " -0.005605468761132215,\n",
       " -0.005605468761132215,\n",
       " -0.005839843761350494,\n",
       " -0.005976562511023076,\n",
       " -0.005878906261386874,\n",
       " -0.005839843761350494,\n",
       " -0.005800781261314114,\n",
       " -0.005761718761277734,\n",
       " -0.0057226562612413545,\n",
       " -0.005683593763933459,\n",
       " -0.005683593763023964,\n",
       " -0.005683593763023964,\n",
       " -0.0058984375136788,\n",
       " -0.006113281262514647,\n",
       " -0.005976562512842065,\n",
       " -0.005761718763096724,\n",
       " -0.005820312512696546,\n",
       " -0.006054687512914825,\n",
       " -0.006269531262660166,\n",
       " -0.006289062512223609,\n",
       " -0.006503906261059456,\n",
       " -0.006503906261059456,\n",
       " -0.006503906261059456,\n",
       " -0.006503906261059456,\n",
       " -0.006503906261059456,\n",
       " -0.006269531262660166,\n",
       " -0.0060937500129512046,\n",
       " -0.006171875011204975,\n",
       " -0.005996093761496013,\n",
       " -0.006074218763387762,\n",
       " -0.006230468763533281,\n",
       " -0.0063867187636788,\n",
       " -0.0065429687638243195,\n",
       " -0.006699218763969839,\n",
       " -0.006855468764115358,\n",
       " -0.007011718764260877,\n",
       " -0.007167968764406396,\n",
       " -0.007089843762514647,\n",
       " -0.007246093762660166,\n",
       " -0.007402343762805685,\n",
       " -0.0075585937629512046,\n",
       " -0.007480468761059456,\n",
       " -0.007402343762805685,\n",
       " -0.007324218760913936,\n",
       " -0.007480468761059456,\n",
       " -0.007363281260950316,\n",
       " -0.007246093760841177,\n",
       " -0.0071289062607320375,\n",
       " -0.007011718760622898,\n",
       " -0.006953125011023076,\n",
       " -0.006914062512805685,\n",
       " -0.006875000011859811,\n",
       " -0.006660156262114469,\n",
       " -0.00658203126204171,\n",
       " -0.006562500012478267,\n",
       " -0.006406250012332748,\n",
       " -0.006425781261896191,\n",
       " -0.006367187511386874,\n",
       " -0.006367187511386874,\n",
       " -0.006308593763606041,\n",
       " -0.006113281262514647,\n",
       " -0.00597656251375156,\n",
       " -0.006132812513897079,\n",
       " -0.006250000013096724,\n",
       " -0.0064843750133150024,\n",
       " -0.00646484376375156,\n",
       " -0.006699218763969839,\n",
       " -0.0065429687638243195,\n",
       " -0.0063867187636788,\n",
       " -0.006503906262878445,\n",
       " -0.006621093763897079,\n",
       " -0.006738281264915713,\n",
       " -0.006738281264915713,\n",
       " -0.0069531250119325705,\n",
       " -0.0069531250119325705,\n",
       " -0.0069531250119325705,\n",
       " -0.006796875011787051,\n",
       " -0.006679687510768417,\n",
       " -0.006679687510768417,\n",
       " -0.006914062512805685,\n",
       " -0.007148437511204975,\n",
       " -0.00718750001033186,\n",
       " -0.007207031259895302,\n",
       " -0.00714843751029548,\n",
       " -0.007343750010477379,\n",
       " -0.007285156260877557,\n",
       " -0.007500000010622898,\n",
       " -0.007480468761059456,\n",
       " -0.007714843761277734,\n",
       " -0.007714843761277734,\n",
       " -0.007949218761496013,\n",
       " -0.007949218761496013,\n",
       " -0.008183593761714292,\n",
       " -0.008339843761859811,\n",
       " -0.008242187512223609,\n",
       " -0.00812500001211447,\n",
       " -0.00812500001211447,\n",
       " -0.008164062513969839,\n",
       " -0.008183593763533281,\n",
       " -0.008203125013096724,\n",
       " -0.008222656262660166,\n",
       " -0.00808593751207809,\n",
       " -0.007949218761496013,\n",
       " -0.008046875012951205,\n",
       " -0.008261718761787051,\n",
       " -0.008222656262660166,\n",
       " -0.008144531260768417,\n",
       " -0.008066406262514647,\n",
       " -0.00812500001211447,\n",
       " -0.008320312512296368,\n",
       " -0.008320312512296368,\n",
       " -0.008320312512296368,\n",
       " -0.008320312512296368,\n",
       " -0.008320312512296368,\n",
       " -0.008554687512514647,\n",
       " -0.008789062512732926,\n",
       " -0.008613281263023964,\n",
       " -0.008378906262805685,\n",
       " -0.008144531262587407,\n",
       " -0.008085937512987584,\n",
       " -0.008027343763387762,\n",
       " -0.007871093763242243,\n",
       " -0.007832031263205863,\n",
       " -0.008066406266152626,\n",
       " -0.007910156266007107,\n",
       " -0.00769531251717126,\n",
       " -0.007910156266007107,\n",
       " -0.008125000014842954,\n",
       " -0.008105468765279511,\n",
       " -0.008085937515716068,\n",
       " -0.008066406266152626,\n",
       " -0.007910156266007107,\n",
       " -0.008125000015752448,\n",
       " -0.008085937515716068,\n",
       " -0.008320312515934347,\n",
       " -0.008320312515934347,\n",
       " -0.008320312515934347,\n",
       " -0.008320312515934347,\n",
       " -0.008320312515934347,\n",
       " -0.008320312515934347,\n",
       " -0.008320312515934347,\n",
       " -0.008320312515934347,\n",
       " -0.008457031265606929,\n",
       " -0.00833984376549779,\n",
       " -0.00822265626538865,\n",
       " -0.008105468765279511,\n",
       " -0.00792968751557055,\n",
       " -0.00785156251549779,\n",
       " -0.007734375014479156,\n",
       " -0.007519531265643309,\n",
       " -0.007304687516807462,\n",
       " -0.0072070312653522706,\n",
       " -0.007089843766152626,\n",
       " -0.007128906265279511,\n",
       " -0.007011718767898856,\n",
       " -0.006894531266880222,\n",
       " -0.006777343765861588,\n",
       " -0.006894531266880222,\n",
       " -0.006972656265133992,\n",
       " -0.007031250014733814,\n",
       " -0.007265625014952093,\n",
       " -0.007500000015170372,\n",
       " -0.007539062515206751,\n",
       " -0.00736328126549779,\n",
       " -0.007187500015788828,\n",
       " -0.007011718766079866,\n",
       " -0.006835937516370905,\n",
       " -0.006660156266661943,\n",
       " -0.006484375016952981,\n",
       " -0.0063085937672440195,\n",
       " -0.006386718767316779,\n",
       " -0.006210937517607817,\n",
       " -0.006035156267898856,\n",
       " -0.006113281267971615,\n",
       " -0.006191406268044375,\n",
       " -0.0062695312681171345,\n",
       " -0.006093750018408173,\n",
       " -0.006230468768080755,\n",
       " -0.006445312517826096,\n",
       " -0.006406250018699211,\n",
       " -0.0063867187636788,\n",
       " -0.006210937513969839,\n",
       " -0.006445312516007107,\n",
       " -0.006679687518044375,\n",
       " -0.006914062516443664,\n",
       " -0.0071484375148429535,\n",
       " -0.00720703126717126,\n",
       " -0.007050781263387762,\n",
       " -0.006894531266880222,\n",
       " -0.0071093750157160684,\n",
       " -0.007324218764551915,\n",
       " -0.007539062513387762,\n",
       " -0.007578125012514647,\n",
       " -0.007558593759313226,\n",
       " -0.007539062513387762,\n",
       " -0.0073632812636788,\n",
       " -0.00720703126717126,\n",
       " -0.007089843766152626,\n",
       " -0.006972656265133992,\n",
       " -0.0071093750157160684,\n",
       " -0.007246093766298145,\n",
       " -0.007011718764260877,\n",
       " -0.007089843769790605,\n",
       " -0.00720703126717126,\n",
       " -0.00728515626542503,\n",
       " -0.007070312516589183,\n",
       " -0.007050781267025741,\n",
       " -0.007265625015861588,\n",
       " -0.007480468765606929,\n",
       " -0.0077148437667347025,\n",
       " -0.007675781266698323,\n",
       " -0.007519531265643309,\n",
       " -0.007382812516880222,\n",
       " -0.007324218767280399,\n",
       " -0.007109375017535058,\n",
       " -0.006933593767826096,\n",
       " -0.0069921875174259185,\n",
       " -0.007031250017462298,\n",
       " -0.006933593767826096,\n",
       " -0.006699218769426807,\n",
       " -0.006914062518262654,\n",
       " -0.0071289062670985,\n",
       " -0.007343750017753337,\n",
       " -0.007148437516661943,\n",
       " -0.006953125017389539,\n",
       " -0.0067578125181171345,\n",
       " -0.006582031268408173,\n",
       " -0.006601562517971615,\n",
       " -0.0066796875162253855,\n",
       " -0.006523437516079866,\n",
       " -0.006582031265679689,\n",
       " -0.006660156265752448,\n",
       " -0.006542968765643309,\n",
       " -0.006503906265606929,\n",
       " -0.006464843765570549,\n",
       " -0.0064257812655341695,\n",
       " -0.0066210937657160684,\n",
       " -0.006816406265897967,\n",
       " -0.007011718766079866,\n",
       " -0.007207031266261765,\n",
       " -0.007402343766443664,\n",
       " -0.007597656266625563,\n",
       " -0.007812500016370905,\n",
       " -0.008027343766116246,\n",
       " -0.008242187515861588,\n",
       " -0.008222656266298145,\n",
       " -0.008437500016043487,\n",
       " -0.008652343765788828,\n",
       " -0.008769531265897967,\n",
       " -0.008886718766007107,\n",
       " -0.008750000016334525,\n",
       " -0.008613281266661943,\n",
       " -0.008476562516989361,\n",
       " -0.008339843767316779,\n",
       " -0.008203125017644197,\n",
       " -0.0083007812672804,\n",
       " -0.008300781268189894,\n",
       " -0.00843750001877197,\n",
       " -0.008203125016734703,\n",
       " -0.008164062517607817,\n",
       " -0.008125000018480932,\n",
       " -0.008085937515716068,\n",
       " -0.008046875016589183,\n",
       " -0.008007812517462298,\n",
       " -0.007968750018335413,\n",
       " -0.007929687519208528,\n",
       " -0.007929687519208528,\n",
       " -0.00769531251717126,\n",
       " -0.00769531251717126,\n",
       " -0.007480468768335413,\n",
       " -0.007500000014260877,\n",
       " -0.007441406269208528,\n",
       " -0.007675781263969839,\n",
       " -0.0077929687686264515,\n",
       " -0.007558593766589183,\n",
       " -0.007753906269499566,\n",
       " -0.007832031267753337,\n",
       " -0.00777343751542503,\n",
       " -0.007929687519208528,\n",
       " -0.007871093766880222,\n",
       " -0.007851562520954758,\n",
       " -0.007753906269499566,\n",
       " -0.007910156266007107,\n",
       " -0.00769531251717126,\n",
       " -0.007734375016298145,\n",
       " -0.007773437519063009,\n",
       " -0.007558593766589183,\n",
       " -0.007343750017753337,\n",
       " -0.00712890626891749,\n",
       " -0.006914062520081643,\n",
       " -0.007070312520227162,\n",
       " -0.007148437522118911,\n",
       " -0.007226562520372681,\n",
       " -0.0073046875186264515,\n",
       " -0.007519531269281288,\n",
       " -0.0077343750181171345,\n",
       " -0.007910156267826096,\n",
       " -0.008085937517535058,\n",
       " -0.00826171876724402,\n",
       " -0.008437500016952981,\n",
       " -0.008652343765788828,\n",
       " -0.008496093765643309,\n",
       " -0.008691406266734703,\n",
       " -0.008789062516370905,\n",
       " -0.008867187516443664,\n",
       " -0.008710937516298145,\n",
       " -0.008476562516079866,\n",
       " -0.008359375015970727,\n",
       " -0.008242187515861588,\n",
       " -0.008125000015752448,\n",
       " -0.00830078126546141,\n",
       " -0.008242187515861588,\n",
       " -0.00841796876557055,\n",
       " -0.008593750015279511,\n",
       " -0.008769531264988473,\n",
       " -0.008945312514697434,\n",
       " -0.009121093764406396,\n",
       " -0.009296875014115358,\n",
       " -0.00947265626382432,\n",
       " -0.009550781263897079,\n",
       " -0.009628906263969839,\n",
       " -0.009863281264188117,\n",
       " -0.009863281264188117,\n",
       " -0.009902343764224497,\n",
       " -0.010117187513969839,\n",
       " -0.009980468764297257,\n",
       " -0.009843750014624675,\n",
       " -0.009707031264952093,\n",
       " -0.009570312515279511,\n",
       " -0.00935546876553417,\n",
       " -0.00931640626549779,\n",
       " -0.00919921876538865,\n",
       " -0.009062500015716068,\n",
       " -0.008925781266043487,\n",
       " -0.008828125016407284,\n",
       " -0.008593750016189006,\n",
       " -0.008378906266443664,\n",
       " -0.008164062516698323,\n",
       " -0.007988281267898856,\n",
       " -0.007812500018189894,\n",
       " -0.008007812518371793,\n",
       " -0.00798828126880835,\n",
       " -0.007832031268662831,\n",
       " -0.00791015626873559,\n",
       " -0.007871093768699211,\n",
       " -0.00798828126880835,\n",
       " -0.00810546876891749,\n",
       " -0.00822265626902663,\n",
       " -0.008378906269172148,\n",
       " -0.008378906269172148,\n",
       " -0.008378906269172148,\n",
       " -0.00839843751873559,\n",
       " -0.008417968768299033,\n",
       " -0.008437500017862476,\n",
       " -0.008203125017644197,\n",
       " -0.007968750017425918,\n",
       " -0.007968750017425918,\n",
       " -0.007968750017425918,\n",
       " -0.007968750017425918,\n",
       " -0.007968750017425918,\n",
       " -0.007968750017425918,\n",
       " -0.008203125017644197,\n",
       " -0.008066406267971615,\n",
       " -0.008046875018408173,\n",
       " -0.00802734376884473,\n",
       " -0.008007812519281288,\n",
       " -0.007988281269717845,\n",
       " -0.007968750020154403,\n",
       " -0.007792968770445441,\n",
       " -0.007851562520045263,\n",
       " -0.007910156269645086,\n",
       " -0.007968750019244908,\n",
       " -0.007792968769535946,\n",
       " -0.007851562519135769,\n",
       " -0.00791015626873559,\n",
       " -0.007968750018335413,\n",
       " -0.008027343767935236,\n",
       " -0.008144531268044375,\n",
       " -0.008261718768153514,\n",
       " -0.008339843768226274,\n",
       " -0.008417968768299033,\n",
       " -0.008457031268335413,\n",
       " -0.00843750001877197,\n",
       " -0.008652343768517312,\n",
       " -0.008867187518262654,\n",
       " -0.008847656268699211,\n",
       " -0.008867187518262654,\n",
       " -0.009082031268007995,\n",
       " -0.009101562518480932,\n",
       " -0.009296875017753337,\n",
       " -0.009453125017898856,\n",
       " -0.009687500018117134,\n",
       " -0.009921875018335413,\n",
       " -0.009863281267826096,\n",
       " -0.009921875018335413,\n",
       " -0.009746093768626451,\n",
       " -0.009628906267607817,\n",
       " -0.009628906267607817,\n",
       " -0.009453125017898856,\n",
       " -0.009453125017898856,\n",
       " -0.00964843751717126,\n",
       " -0.00964843751717126,\n",
       " -0.009804687517316779,\n",
       " -0.009960937517462298,\n",
       " -0.009882812519208528,\n",
       " -0.010039062519354047,\n",
       " -0.010097656268044375,\n",
       " -0.010156250016734703,\n",
       " -0.00998046876702574,\n",
       " -0.009843750018262654,\n",
       " -0.009609375018044375,\n",
       " -0.009804687517316779,\n",
       " -0.010000000016589183,\n",
       " -0.010000000016589183,\n",
       " -0.010000000016589183,\n",
       " -0.010000000016589183,\n",
       " -0.00998046877066372,\n",
       " -0.009960937517462298,\n",
       " -0.01005859376891749,\n",
       " -0.010078125018480932,\n",
       " -0.010097656268044375,\n",
       " -0.010175781266298145,\n",
       " -0.00998046876702574,\n",
       " -0.010214843769063009,\n",
       " -0.010449218767462298,\n",
       " -0.010683593769499566,\n",
       " -0.010664062516298145,\n",
       " -0.010585937518044375,\n",
       " -0.010585937518044375,\n",
       " -0.010351562516007107,\n",
       " -0.010527343765716068,\n",
       " -0.010410156268335413,\n",
       " -0.010410156268335413,\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b2bd16c4a5b7bdb943c513e9c5dbb440fb1e7bca9cf829d440576f5014c581f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
