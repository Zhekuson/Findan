{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhekuson/Findan/blob/main/Sb_1/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j06z23TnuylB"
      },
      "source": [
        "# Первоначальная настройка"
      ],
      "id": "j06z23TnuylB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T0SlbaXu3wI"
      },
      "source": [
        "Здесь маунт, импорты и прочее  \n",
        "Не забудь очистить выходы ячеек перед коммитом"
      ],
      "id": "7T0SlbaXu3wI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-Q4el0uxlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19723484-4082-42ec-dd67-bf077db7e287"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "er-Q4el0uxlC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7jhh5avw8v-"
      },
      "source": [
        "**Нужно добавить ссылку на мой диск для нашей общей папки по финдану**\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "id": "E7jhh5avw8v-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugHCXDKvvD0R",
        "outputId": "beba57b2-d91c-4562-93de-9c0600f63084"
      },
      "source": [
        "!ls drive/MyDrive/Findan/Sb_1\n",
        "# не очищайте эту ячейку"
      ],
      "id": "ugHCXDKvvD0R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " data   plots  'Если ты это видишь все ок'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id5v5LhRxU8P"
      },
      "source": [
        "Ссылка на папку Findan должна лежать в корне (в MyDrive)  \n",
        "Если все сделано правильно, то появится доступ к общим файлам в этой папке"
      ],
      "id": "id5v5LhRxU8P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kDjanGQxk0j"
      },
      "source": [
        "Сохраняться должны: **веса моделей/отчеты** - на диске,  \n",
        "**выходы ячеек** - на гитхабе "
      ],
      "id": "4kDjanGQxk0j"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjHG7Fm33tZN"
      },
      "source": [
        "Правила по работе с *общими* ноутбуками  \n",
        "1) **Строго** в отдельных ветках, иначе будет очень плохо  \n",
        "2) PR в main очень аккуратно, мердж конфликты резолвим тщательно     \n",
        "3) Коммиты тоже аккуратные и без лишних выводов ячеек  "
      ],
      "id": "GjHG7Fm33tZN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt1cRT4a53wa"
      },
      "source": [
        "Либо в отдельных ноутбуках, тогда свобода действий"
      ],
      "id": "nt1cRT4a53wa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2HPbspFu-1Q"
      },
      "source": [
        "# Начало"
      ],
      "id": "x2HPbspFu-1Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMPKuKAt1T7X"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import sys\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras.layers import LSTM, GRU, Conv1D, MaxPooling1D\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from operator import add\n",
        "import json"
      ],
      "id": "oMPKuKAt1T7X",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0bPUBFb4pDi"
      },
      "source": [
        "def make_ann_model(window_size):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, activation='relu', input_shape=(window_size, 1)))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "def make_lstm_model(window_size):\n",
        "    model_lstm = Sequential()\n",
        "    model_lstm.add(LSTM(256, input_shape=(window_size, 1), activation='relu', kernel_initializer='lecun_uniform',\n",
        "                        return_sequences=True))\n",
        "    model_lstm.add(Dropout(0.2))\n",
        "    model_lstm.add(LSTM(128, input_shape=(window_size, 1), activation='relu', kernel_initializer='lecun_uniform',\n",
        "                        return_sequences=False))\n",
        "    model_lstm.add(Dropout(0.2))\n",
        "    model_lstm.add(Dense(1, activation='linear'))\n",
        "    model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    return model_lstm\n",
        "\n",
        "\n",
        "def make_cnn_model(window_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(window_size, 1)))\n",
        "    model.add(Conv1D(filters=32, kernel_size=1, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    # model.add(Dense(32,activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_gru_model(window_size):\n",
        "    model = Sequential()\n",
        "    model.add(GRU(256, input_shape=(window_size, 1), activation='relu', kernel_initializer='lecun_uniform',\n",
        "                  return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(128, input_shape=(window_size, 1), activation='relu', kernel_initializer='lecun_uniform',\n",
        "                  return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    return model\n",
        "\n",
        "def test_model(model, X_train, X_test, y_train, y_test):\n",
        "    y_pred_test_ann = model.predict(X_test)\n",
        "    y_train_pred_ann = model.predict(X_train)\n",
        "    r2_train = mse(y_train, y_train_pred_ann)\n",
        "    r2_test = mse(y_test, y_pred_test_ann)\n",
        "\n",
        "    return r2_train, r2_test"
      ],
      "id": "E0bPUBFb4pDi",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZWk_AgrRqy04"
      },
      "source": [
        "symbols = ['INFY', 'BHARTIARTL', 'AXISBANK', 'CIPLA', 'HCLTECH', 'HDFC', 'ULTRACEMCO', 'ACC']\n",
        "window_sizes = [3, 5, 7, 9, 11, 13, 15]"
      ],
      "id": "ZWk_AgrRqy04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rb9P2aP5qy04"
      },
      "source": [
        "def window_transform(time_series, window_size):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(time_series) - window_size):\n",
        "        X.append(time_series[i:i + window_size])\n",
        "        y.append(time_series[i + window_size])\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "id": "rb9P2aP5qy04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "13UhoYWvqy04",
        "outputId": "5fddb262-fccd-49e6-d5d3-9e31dff100f9"
      },
      "source": [
        "for sym in symbols:\n",
        "    json_descriptor = {'stock': sym, 'ann': [], 'gru': [], 'lstm': [], 'cnn': []}\n",
        "    data = pd.read_csv('drive/MyDrive/Findan/Sb_1/data/{}.csv'.format(sym), index_col=0)\n",
        "    print('data loaded for {}!!'.format(sym))\n",
        "    data.index = pd.to_datetime(data.index)\n",
        "    data_frame = data.copy()\n",
        "    df = data_frame[[\"Close\"]]\n",
        "\n",
        "    print(df)\n",
        "    split_date = pd.Timestamp('01-01-2017')\n",
        "\n",
        "    train = df.loc[:split_date]\n",
        "    test = df.loc[split_date:]\n",
        "\n",
        "    sc = MinMaxScaler()\n",
        "    train_sc = sc.fit_transform(train)\n",
        "    test_sc = sc.transform(test)\n",
        "\n",
        "    ann = []\n",
        "    gru = []\n",
        "    lstm = []\n",
        "    cnn = []\n",
        "\n",
        "    for win_sz in window_sizes:\n",
        "        ann_result = []\n",
        "        gru_result = []\n",
        "        lstm_result = []\n",
        "        cnn_result = []\n",
        "        pred_ANN = []\n",
        "        pred_LSTM = []\n",
        "        pred_GRU = []\n",
        "        pred_CNN = []\n",
        "        for i in range(5):\n",
        "            # ''''''''ANN'''''''''''''''''''\n",
        "            X_train, y_train = window_transform(train_sc, win_sz)\n",
        "            X_test, y_test = window_transform(test_sc, win_sz)\n",
        "\n",
        "            model = make_ann_model(win_sz)\n",
        "            early_stop = EarlyStopping(monitor='loss', patience=2, verbose=1)\n",
        "            history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, callbacks=[early_stop],\n",
        "                                shuffle=False)\n",
        "\n",
        "            train_acc, test_acc = test_model(model, X_train, X_test, y_train, y_test)\n",
        "            y_pred_test_ANN = model.predict(X_test)\n",
        "\n",
        "            ann_result.append(test_acc)\n",
        "            # ''''''''ANN''''''''''''''''''''\n",
        "\n",
        "            # ''''''''CNN''''''''''''''''''''\n",
        "            model = make_cnn_model(win_sz)\n",
        "            early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
        "            history_model_cnn = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, shuffle=False,\n",
        "                                          callbacks=[early_stop])\n",
        "\n",
        "            train_acc, test_acc = test_model(model, X_train, X_test, y_train, y_test)\n",
        "            y_pred_test_CNN = model.predict(X_test)\n",
        "            cnn_result.append(test_acc)\n",
        "            # ''''''''CNN''''''''''''''''''''\n",
        "\n",
        "            X_tr_t = X_train.reshape(X_train.shape[0], win_sz, 1)\n",
        "            X_tst_t = X_test.reshape(X_test.shape[0], win_sz, 1)\n",
        "\n",
        "            # ''''''''''LSTM''''''''''''''''''\n",
        "            model = make_lstm_model(win_sz)\n",
        "            early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
        "            history_model_lstm = model.fit(X_tr_t, y_train, epochs=200, batch_size=32, verbose=1, shuffle=False,\n",
        "                                           callbacks=[early_stop])\n",
        "\n",
        "            train_acc, test_acc = test_model(model, X_tr_t, X_tst_t, y_train, y_test)\n",
        "            y_pred_test_LSTM = model.predict(X_tst_t)\n",
        "            lstm_result.append(test_acc)\n",
        "            # \"''''''''LSTM'''''''''''''''''''\n",
        "\n",
        "            # ''''''''GRU'''''''''''''''''''''\n",
        "            model = make_gru_model(win_sz)\n",
        "            early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
        "            history_model_gru = model.fit(X_tr_t, y_train, epochs=200, batch_size=32, verbose=1, shuffle=False,\n",
        "                                          callbacks=[early_stop])\n",
        "\n",
        "            train_acc, test_acc = test_model(model, X_tr_t, X_tst_t, y_train, y_test)\n",
        "            y_pred_test_GRU = model.predict(X_tst_t)\n",
        "            gru_result.append(test_acc)\n",
        "            # ''''''''GRU'''''''''''''''''''''\n",
        "\n",
        "            pred_ANN.append(y_pred_test_ANN)\n",
        "            pred_CNN.append(y_pred_test_CNN)\n",
        "            pred_LSTM.append(y_pred_test_LSTM)\n",
        "            pred_GRU.append(y_pred_test_GRU)\n",
        "        # update optimal window size param\n",
        "        ann.append([win_sz, min(ann_result), np.mean(ann_result), np.std(ann_result)])\n",
        "        gru.append([win_sz, min(gru_result), np.mean(gru_result), np.std(gru_result)])\n",
        "        lstm.append([win_sz, min(lstm_result), np.mean(lstm_result), np.std(lstm_result)])\n",
        "        cnn.append([win_sz, min(cnn_result), np.mean(cnn_result), np.std(cnn_result)])\n",
        "\n",
        "        plot_ann = [0] * len(pred_ANN[0])\n",
        "        for pred in pred_ANN:\n",
        "            plot_ann = list(map(add, plot_ann, pred))\n",
        "\n",
        "        for i in range(len(plot_ann)):\n",
        "            plot_ann[i] = plot_ann[i] / 5\n",
        "\n",
        "        plot_lstm = [0] * len(pred_LSTM[0])\n",
        "        for pred in pred_LSTM:\n",
        "            plot_lstm = list(map(add, plot_lstm, pred))\n",
        "\n",
        "        for i in range(len(plot_lstm)):\n",
        "            plot_lstm[i] = plot_lstm[i] / 5\n",
        "\n",
        "        plot_gru = [0] * len(pred_GRU[0])\n",
        "        for pred in pred_GRU:\n",
        "            plot_gru = list(map(add, plot_gru, pred))\n",
        "\n",
        "        for i in range(len(plot_gru)):\n",
        "            plot_gru[i] = plot_gru[i] / 5\n",
        "\n",
        "        plot_cnn = [0] * len(pred_CNN[0])\n",
        "        for pred in pred_CNN:\n",
        "            plot_cnn = list(map(add, plot_cnn, pred))\n",
        "\n",
        "        for i in range(len(plot_cnn)):\n",
        "            plot_cnn[i] = plot_cnn[i] / 5\n",
        "\n",
        "        # save prediction plots\n",
        "        plt.plot(y_test, '-', label='True Values', color='#1b9e77')\n",
        "        plt.plot(plot_ann, label='ANN Prediction', color='#d95f02')\n",
        "        plt.plot(plot_cnn, ':', label='CNN Prediction', color='#7570b3')\n",
        "        plt.plot(plot_lstm, label='LSTM Prediction', color='#e7298a')\n",
        "        plt.plot(plot_gru, label='GRU Prediction', color='#66a61e')\n",
        "        plt.title(\"Prediction\")\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Normalized Stock Prices')\n",
        "        plt.legend()\n",
        "        plt.savefig('drive/MyDrive/Findan/Sb_1/plots/single_step/' + sym + ' ' + 'window_sz ' + str(win_sz))\n",
        "        plt.clf()"
      ],
      "id": "13UhoYWvqy04",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 0.0014\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 9.9120e-04\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 9.8484e-04\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 9.1712e-04\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 9.4476e-04\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 8.2608e-04\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 9.1566e-04\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 7.2166e-04\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 9.0304e-04\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 6.4038e-04\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 8.7219e-04\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 6.4636e-04\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 7.1193e-04\n",
            "Epoch 26/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 6.8469e-04\n",
            "Epoch 27/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 6.2833e-04\n",
            "Epoch 28/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 7.0552e-04\n",
            "Epoch 29/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 6.6107e-04\n",
            "Epoch 30/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 6.6766e-04\n",
            "Epoch 31/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 7.0415e-04\n",
            "Epoch 32/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 6.5020e-04\n",
            "Epoch 00032: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 16s 113ms/step - loss: 0.0222\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 13s 112ms/step - loss: 0.0084\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 13s 115ms/step - loss: 0.0047\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 13s 115ms/step - loss: 0.0032\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0024\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0026\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0028\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0020\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 13s 112ms/step - loss: 0.0020\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0025\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 13s 112ms/step - loss: 0.0018\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0015\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0021\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0016\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0019\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 13s 112ms/step - loss: 0.0015\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0018\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0015\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 13s 112ms/step - loss: 0.0017\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0014\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0014\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0016\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0015\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0013\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0014\n",
            "Epoch 26/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0020\n",
            "Epoch 27/200\n",
            "117/117 [==============================] - 13s 111ms/step - loss: 0.0014\n",
            "Epoch 28/200\n",
            "117/117 [==============================] - 13s 112ms/step - loss: 0.0014\n",
            "Epoch 29/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0017\n",
            "Epoch 00029: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 14s 97ms/step - loss: 0.0253\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 11s 95ms/step - loss: 0.0047\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0032\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0036\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0031\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0035\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0030\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0018\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0019\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0018\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0022\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 11s 95ms/step - loss: 0.0024\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0023\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0020\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0016\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0014\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0014\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0016\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0018\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0018\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0018\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 11s 95ms/step - loss: 0.0020\n",
            "Epoch 00022: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 1s 3ms/step - loss: 0.0094\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0035\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0031\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0027\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0026\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 9.9853e-04\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 9.0246e-04\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 8.8875e-04\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 0s 2ms/step - loss: 8.5099e-04\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 8.7279e-04\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 8.0769e-04\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 9.6431e-04\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 7.8353e-04\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 9.3134e-04\n",
            "Epoch 00025: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0186\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0033\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 0.0024\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0023\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 0.0022\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0022\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0019\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0015\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 9.3274e-04\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0013\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 8.1914e-04\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 8.6656e-04\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 7.6616e-04\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0011\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 6.6119e-04\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 8.7707e-04\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 5.7738e-04\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 9.3941e-04\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 6.0574e-04\n",
            "Epoch 26/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 6.8261e-04\n",
            "Epoch 27/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 7.0267e-04\n",
            "Epoch 28/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 7.6621e-04\n",
            "Epoch 00028: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 17s 119ms/step - loss: 0.0309\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 14s 120ms/step - loss: 0.0104\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 14s 119ms/step - loss: 0.0045\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 14s 121ms/step - loss: 0.0037\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 14s 118ms/step - loss: 0.0027\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 14s 119ms/step - loss: 0.0024\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 14s 121ms/step - loss: 0.0019\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 14s 118ms/step - loss: 0.0023\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0020\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 14s 117ms/step - loss: 0.0036\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 13s 115ms/step - loss: 0.0018\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0023\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0018\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 14s 115ms/step - loss: 0.0016\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 13s 115ms/step - loss: 0.0021\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0014\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 13s 115ms/step - loss: 0.0017\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0017\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0015\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 14s 117ms/step - loss: 0.0015\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 14s 115ms/step - loss: 0.0017\n",
            "Epoch 00021: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 14s 95ms/step - loss: 0.0271\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0034\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0054\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0058\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0023\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0020\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0024\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 11s 92ms/step - loss: 0.0026\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0018\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0018\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0024\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0025\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0022\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 11s 92ms/step - loss: 0.0017\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0016\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0016\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0016\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 11s 93ms/step - loss: 0.0023\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 11s 94ms/step - loss: 0.0024\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 11s 95ms/step - loss: 0.0014\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0013\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0013\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 11s 98ms/step - loss: 0.0016\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 11s 95ms/step - loss: 0.0014\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 11s 95ms/step - loss: 0.0015\n",
            "Epoch 26/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0015\n",
            "Epoch 00026: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 1s 3ms/step - loss: 0.0445\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 9.7873e-04\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 9.3719e-04\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 9.4136e-04\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 8.6792e-04\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 8.7419e-04\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0413\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0031\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0021\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0019\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 9.6068e-04\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0011\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 8.9908e-04\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 1s 4ms/step - loss: 0.0014\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 0.0010\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 0.0011\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 7.9980e-04\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 9.9447e-04\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 9.9351e-04\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 00022: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 16s 119ms/step - loss: 0.0276\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 14s 118ms/step - loss: 0.0099\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0055\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 14s 118ms/step - loss: 0.0034\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 14s 117ms/step - loss: 0.0034\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 14s 117ms/step - loss: 0.0027\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 14s 117ms/step - loss: 0.0028\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 14s 118ms/step - loss: 0.0021\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0027\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 14s 117ms/step - loss: 0.0026\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0022\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0021\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 14s 117ms/step - loss: 0.0025\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0017\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0017\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 14s 115ms/step - loss: 0.0020\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0015\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0016\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 14s 117ms/step - loss: 0.0018\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 14s 118ms/step - loss: 0.0015\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 14s 115ms/step - loss: 0.0019\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 14s 115ms/step - loss: 0.0015\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 13s 115ms/step - loss: 0.0018\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0013\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 13s 115ms/step - loss: 0.0012\n",
            "Epoch 26/200\n",
            "117/117 [==============================] - 13s 113ms/step - loss: 0.0016\n",
            "Epoch 27/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0013\n",
            "Epoch 28/200\n",
            "117/117 [==============================] - 13s 115ms/step - loss: 0.0013\n",
            "Epoch 29/200\n",
            "117/117 [==============================] - 13s 112ms/step - loss: 0.0012\n",
            "Epoch 30/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0014\n",
            "Epoch 31/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0013\n",
            "Epoch 32/200\n",
            "117/117 [==============================] - 14s 116ms/step - loss: 0.0013\n",
            "Epoch 33/200\n",
            "117/117 [==============================] - 14s 115ms/step - loss: 0.0019\n",
            "Epoch 34/200\n",
            "117/117 [==============================] - 13s 114ms/step - loss: 0.0022\n",
            "Epoch 00034: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 14s 96ms/step - loss: 0.0280\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 11s 95ms/step - loss: 0.0038\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0049\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0037\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0043\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0022\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0021\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 11s 97ms/step - loss: 0.0026\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0023\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 11s 97ms/step - loss: 0.0028\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 11s 98ms/step - loss: 0.0026\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0018\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0020\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 11s 97ms/step - loss: 0.0021\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0026\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0019\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 11s 97ms/step - loss: 0.0016\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 11s 97ms/step - loss: 0.0020\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0016\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 11s 97ms/step - loss: 0.0016\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 11s 97ms/step - loss: 0.0014\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0018\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0018\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 11s 97ms/step - loss: 0.0014\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 11s 96ms/step - loss: 0.0014\n",
            "Epoch 26/200\n",
            "117/117 [==============================] - 11s 95ms/step - loss: 0.0016\n",
            "Epoch 00026: early stopping\n",
            "data loaded for BHARTIARTL!!\n",
            "             Close\n",
            "Date              \n",
            "2002-02-18   44.35\n",
            "2002-02-19   41.70\n",
            "2002-02-20   41.25\n",
            "2002-02-21   42.40\n",
            "2002-02-22   43.30\n",
            "...            ...\n",
            "2019-01-09  334.50\n",
            "2019-01-10  337.30\n",
            "2019-01-11  335.10\n",
            "2019-01-14  331.60\n",
            "2019-01-15  337.75\n",
            "\n",
            "[4211 rows x 1 columns]\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0307\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0160\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0091\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0044\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.1523e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.5040e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 3.7066e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.4001e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.2829e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.2648e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.3105e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.4179e-04\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0011\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.0818e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.7913e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0515e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2186e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.8836e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.8475e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.9695e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.1599e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.3285e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.5932e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.8240e-04\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 7s 37ms/step - loss: 0.0020\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0013\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0010\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0010\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 7s 32ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0021\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0014\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0010\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0014\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0013\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0301\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0145\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0076\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0034\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.7820e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.3373e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.3855e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9668e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7856e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7350e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 2.7488e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.8283e-04\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0021\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0038\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0037\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 7s 36ms/step - loss: 0.0020\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 4s 35ms/step - loss: 0.0015\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 4s 35ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0010\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 9.6743e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0011\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 8.8301e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 8.6140e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 8.8940e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 9.0071e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 8.9327e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 8.6665e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0010\n",
            "Epoch 00022: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 7s 32ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0016\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0015\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0118\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0080\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0035\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.8491e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.3621e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.4790e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.1842e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.0159e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.9564e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.9849e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.0795e-04\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0013\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.4580e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.1881e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.3614e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.3487e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.3045e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2286e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.0910e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.6911e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.1186e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2824e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2712e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2077e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 4.1615e-04\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 8s 40ms/step - loss: 0.0021\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 5s 40ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 5s 41ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 5s 41ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 5s 41ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 5s 42ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 5s 41ms/step - loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 4s 39ms/step - loss: 0.0015\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0013\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 5s 41ms/step - loss: 0.0014\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 5s 40ms/step - loss: 0.0012\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 8.9963e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0010\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 5s 40ms/step - loss: 8.7470e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 9.6374e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 9.9085e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 8.8248e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 9.7108e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 9.1942e-04\n",
            "Epoch 00022: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 7s 33ms/step - loss: 0.0030\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0024\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0012\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0010\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0011\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0011\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 8.6028e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0010\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0013\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0012\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0011\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.2719e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.2050e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.2164e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.7408e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.4897e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.4621e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.5620e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.7098e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.8691e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.0049e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0979e-04\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 7s 38ms/step - loss: 0.0019\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0020\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0020\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0017\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 5s 41ms/step - loss: 0.0017\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0014\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0014\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0016\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0018\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0017\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0019\n",
            "Epoch 00015: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 7s 32ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0021\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0010\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0011\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0010\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 9.1551e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 9.4598e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 9.9992e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 8.7764e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 9.0414e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0012\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0010\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0012\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0010\n",
            "Epoch 00021: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0022\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0039\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0026\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0011\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.2407e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.4186e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.9984e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.1443e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.7205e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.5481e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.5614e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.6907e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.8812e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0951e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2990e-04\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 7s 38ms/step - loss: 0.0020\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0016\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 5s 39ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 4s 38ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0016\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 4s 37ms/step - loss: 0.0016\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 4s 36ms/step - loss: 0.0016\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 7s 31ms/step - loss: 0.0024\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 4s 30ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 9.9272e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0010\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 9.6492e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 9.8589e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 9.6274e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 9.1834e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 9.5520e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 4s 31ms/step - loss: 8.6384e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 0.0010\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 4s 30ms/step - loss: 0.0012\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 9.3644e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 4s 33ms/step - loss: 8.8714e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 4s 32ms/step - loss: 9.8915e-04\n",
            "Epoch 00024: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0431\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0082\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0052\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.1908e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.6586e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.3831e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.5095e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.9568e-04\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.3580e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.8211e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.5051e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0601e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0002e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.2004e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2034e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.1179e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.9996e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.4178e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 4.9082e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2155e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.3109e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2438e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0767e-04\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 62ms/step - loss: 0.0023\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0016\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0024\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0020\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0021\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 0.0018\n",
            "Epoch 00007: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 8s 47ms/step - loss: 0.0027\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 6s 49ms/step - loss: 0.0013\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 5s 44ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0011\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 9.7985e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 6s 52ms/step - loss: 9.8973e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 6s 49ms/step - loss: 9.2094e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0010\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 9.7567e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0010\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 6s 55ms/step - loss: 8.6441e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 6s 51ms/step - loss: 0.0010\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 6s 49ms/step - loss: 0.0010\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.0012\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0013\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.0013\n",
            "Epoch 00022: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0028\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0050\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0033\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0013\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.5388e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.6699e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.5834e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0283e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0344e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2303e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.4161e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.7577e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.1737e-04\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 60ms/step - loss: 0.0030\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0016\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0017\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0019\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 0.0016\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0019\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 8s 45ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 6s 52ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.0016\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 6s 52ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 6s 51ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 6s 53ms/step - loss: 0.0011\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 6s 51ms/step - loss: 0.0011\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0013\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 6s 52ms/step - loss: 0.0014\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 6s 54ms/step - loss: 0.0014\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 6s 51ms/step - loss: 0.0013\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0015\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0035\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0029\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0021\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0038\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0036\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0026\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 62ms/step - loss: 0.0031\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0022\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0021\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0019\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0016\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0014\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0014\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0015\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0014\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0010\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0011\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0010\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0010\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0011\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 0.0011\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0010\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 8.1192e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 9.1457e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 8.1969e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 7.7533e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 9.8531e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 9.3937e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 9.7038e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 8.6052e-04\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 7.6563e-04\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 7.3623e-04\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 7s 58ms/step - loss: 8.2396e-04\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 7.2614e-04\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 7.0601e-04\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 8.5227e-04\n",
            "Epoch 36/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 7.7585e-04\n",
            "Epoch 37/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 8.0863e-04\n",
            "Epoch 38/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 7.3895e-04\n",
            "Epoch 39/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 6.5063e-04\n",
            "Epoch 40/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 6.9083e-04\n",
            "Epoch 41/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 6.8136e-04\n",
            "Epoch 42/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 6.7568e-04\n",
            "Epoch 43/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 7.0763e-04\n",
            "Epoch 44/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 7.0936e-04\n",
            "Epoch 00044: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 9s 49ms/step - loss: 0.0030\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 6s 53ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 6s 52ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 6s 49ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 5s 45ms/step - loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 6s 51ms/step - loss: 0.0014\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 6s 51ms/step - loss: 0.0014\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.0013\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 6s 51ms/step - loss: 0.0012\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0012\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0014\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0337\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0081\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.2325e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.0083e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.6857e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.9961e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.7156e-04\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0012\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.6614e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.8765e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.7993e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2835e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0540e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0134e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0738e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2179e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2866e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.3136e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2935e-04\n",
            "Epoch 00015: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 60ms/step - loss: 0.0024\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0016\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0018\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0016\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0017\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 8s 46ms/step - loss: 0.0022\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 5s 45ms/step - loss: 0.0016\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 5s 42ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 5s 44ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 5s 43ms/step - loss: 0.0012\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 5s 45ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 5s 45ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 5s 45ms/step - loss: 0.0014\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0014\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0121\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0115\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0055\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.3226e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 4.7264e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.0692e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.7800e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.6710e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.6521e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.6974e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.7908e-04\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0013\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.3979e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.0875e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2579e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2645e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.4815e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.4740e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.6172e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.7607e-04\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 58ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 58ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 0.0022\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0022\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 58ms/step - loss: 0.0018\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0018\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0020\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0021\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0022\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 7s 59ms/step - loss: 0.0026\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 7s 60ms/step - loss: 0.0033\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 8s 46ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 5s 45ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 5s 47ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 6s 49ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 6s 50ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 6s 51ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 6s 48ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 6s 49ms/step - loss: 0.0013\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 5s 46ms/step - loss: 0.0012\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0013\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0016\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.3801e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.5259e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.6088e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.1802e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.5032e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.8719e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.0805e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.1823e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.3407e-04\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 11s 75ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0023\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0015\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0016\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0018\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 9s 77ms/step - loss: 0.0016\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0018\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0019\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 62ms/step - loss: 0.0027\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0014\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 65ms/step - loss: 0.0019\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0011\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 7s 65ms/step - loss: 0.0016\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0015\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0083\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0088\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0048\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.8192e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.5931e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.2695e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.0446e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.1974e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.6407e-04\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0020\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0037\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0019\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 11s 72ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0017\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0017\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 62ms/step - loss: 0.0031\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0012\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0016\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0012\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0010\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 9.4909e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0010\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0013\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0013\n",
            "Epoch 00020: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0048\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0083\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0043\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.5893e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.6491e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.4949e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.5515e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.0433e-04\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0017\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0031\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.8772e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.3818e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.9613e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.1916e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.2768e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.2033e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.1478e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.0785e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.9801e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.9842e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.9878e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.0208e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0795e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0860e-04\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 11s 73ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0032\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0022\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 9s 74ms/step - loss: 0.0022\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0022\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0022\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0023\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0025\n",
            "Epoch 00008: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 64ms/step - loss: 0.0035\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0022\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0010\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0013\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0013\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0012\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0012\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.0971e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.2989e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.3878e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.2083e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.3165e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.4103e-04\n",
            "Epoch 00008: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0027\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0047\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0036\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0030\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0033\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0038\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 11s 72ms/step - loss: 0.0038\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0025\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0019\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 9s 77ms/step - loss: 0.0021\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0022\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0019\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0018\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0016\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0015\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0019\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0020\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0022\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0028\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0028\n",
            "Epoch 00015: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 63ms/step - loss: 0.0030\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 65ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 65ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0011\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0015\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0013\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0015\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0014\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0012\n",
            "Epoch 00015: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0215\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0120\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0049\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.6173e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.5216e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.8394e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0015\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.8808e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.6433e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.0168e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.8810e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.9416e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.2475e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.4020e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.4482e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.4321e-04\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 11s 73ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0025\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0016\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0016\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0018\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0018\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 10s 62ms/step - loss: 0.0028\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 7s 64ms/step - loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 9.2658e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 7s 61ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0011\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 7s 62ms/step - loss: 0.0012\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 7s 63ms/step - loss: 0.0011\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0109\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0060\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0049\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0028\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0014\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0011\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.4705e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.2723e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.3843e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.0926e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.6819e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.5922e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.5428e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.6506e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.7173e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.7798e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.7746e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.7192e-04\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 12s 82ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0022\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0016\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 9s 82ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 9s 82ms/step - loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0015\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0017\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0015\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0016\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0016\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 11s 71ms/step - loss: 0.0036\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0010\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0010\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 9s 75ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0012\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0012\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 9.5842e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0011\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0011\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0013\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0013\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0016\n",
            "Epoch 00022: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0146\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0104\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0029\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.8759e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.6097e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.4509e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.3423e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.2582e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.1811e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.1143e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.0596e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.0093e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.9528e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.8710e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.7663e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.6395e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.4937e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.3314e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.1575e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.9750e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.7899e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.5997e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.4079e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.2179e-04\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.0242e-04\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.8047e-04\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.6044e-04\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.4284e-04\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.2814e-04\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.1432e-04\n",
            "Epoch 36/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.0371e-04\n",
            "Epoch 37/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.9467e-04\n",
            "Epoch 38/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.8696e-04\n",
            "Epoch 39/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.7841e-04\n",
            "Epoch 40/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.7176e-04\n",
            "Epoch 41/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.6498e-04\n",
            "Epoch 42/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.5804e-04\n",
            "Epoch 43/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.5099e-04\n",
            "Epoch 44/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.4388e-04\n",
            "Epoch 45/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.3695e-04\n",
            "Epoch 46/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2749e-04\n",
            "Epoch 47/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.2056e-04\n",
            "Epoch 48/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.1292e-04\n",
            "Epoch 49/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0340e-04\n",
            "Epoch 50/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.9456e-04\n",
            "Epoch 51/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.8506e-04\n",
            "Epoch 52/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.7605e-04\n",
            "Epoch 53/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.6760e-04\n",
            "Epoch 54/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.5663e-04\n",
            "Epoch 55/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.4854e-04\n",
            "Epoch 56/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.4054e-04\n",
            "Epoch 57/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.3215e-04\n",
            "Epoch 58/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2353e-04\n",
            "Epoch 59/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.1509e-04\n",
            "Epoch 60/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.0693e-04\n",
            "Epoch 61/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.9993e-04\n",
            "Epoch 62/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.9132e-04\n",
            "Epoch 63/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.8347e-04\n",
            "Epoch 64/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.7499e-04\n",
            "Epoch 65/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.6730e-04\n",
            "Epoch 66/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.6050e-04\n",
            "Epoch 67/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.5239e-04\n",
            "Epoch 68/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.4531e-04\n",
            "Epoch 69/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.3843e-04\n",
            "Epoch 70/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.3128e-04\n",
            "Epoch 71/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.2370e-04\n",
            "Epoch 72/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.1573e-04\n",
            "Epoch 73/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.0963e-04\n",
            "Epoch 74/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.0238e-04\n",
            "Epoch 75/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9581e-04\n",
            "Epoch 76/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.8853e-04\n",
            "Epoch 77/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.8123e-04\n",
            "Epoch 78/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7426e-04\n",
            "Epoch 79/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.6749e-04\n",
            "Epoch 80/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.6069e-04\n",
            "Epoch 81/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.5407e-04\n",
            "Epoch 82/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.4781e-04\n",
            "Epoch 83/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.4217e-04\n",
            "Epoch 84/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.3711e-04\n",
            "Epoch 85/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.3282e-04\n",
            "Epoch 86/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.2969e-04\n",
            "Epoch 87/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.2737e-04\n",
            "Epoch 88/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.2607e-04\n",
            "Epoch 89/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.2577e-04\n",
            "Epoch 90/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.2643e-04\n",
            "Epoch 91/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.2751e-04\n",
            "Epoch 00091: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0031\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0041\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0035\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.8845e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.8959e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.7068e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.1143e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 6.6070e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 6.2757e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.9673e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.6193e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.3465e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.0202e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.7527e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.4500e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.1113e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.8677e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.5493e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.3606e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.2111e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.1083e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.0493e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9835e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 2.9595e-04\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9092e-04\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 2.9350e-04\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.0605e-04\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.1611e-04\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.2875e-04\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.3998e-04\n",
            "Epoch 00035: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 12s 83ms/step - loss: 0.0028\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 10s 86ms/step - loss: 0.0016\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 10s 85ms/step - loss: 0.0016\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0018\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0015\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 10s 85ms/step - loss: 0.0017\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0015\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0015\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0015\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 11s 71ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0021\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0011\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0010\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 9.0782e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0011\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 9.8819e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 9.5123e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 9s 75ms/step - loss: 0.0011\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 9s 73ms/step - loss: 0.0011\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0031\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0071\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0069\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0018\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.4305e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.8201e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.5560e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.8790e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.8621e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.0778e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 9.4092e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.5749e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.9198e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 12s 82ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0030\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0029\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0024\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0024\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0020\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0022\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0026\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0025\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 86ms/step - loss: 0.0028\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0028\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 12s 71ms/step - loss: 0.0028\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 9s 73ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0012\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 9s 74ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 9s 73ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0013\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0013\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0014\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0018\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0020\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0019\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0028\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0013\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.0906e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.4267e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.0524e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.4930e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.6626e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.1351e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.8904e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 6.3216e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.9030e-04\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 12s 85ms/step - loss: 0.0028\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0032\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 0.0027\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 10s 85ms/step - loss: 0.0030\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0021\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0022\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0022\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 9s 82ms/step - loss: 0.0023\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0023\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0024\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 11s 70ms/step - loss: 0.0030\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0026\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 69ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0016\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0015\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0014\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0014\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0014\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0150\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0061\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0064\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0040\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0027\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0019\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 12s 82ms/step - loss: 0.0027\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0026\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0022\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0024\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0025\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0022\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 9s 82ms/step - loss: 0.0020\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0023\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0021\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0025\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0027\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0026\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 11s 69ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 8s 70ms/step - loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 8s 71ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 9s 73ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 9s 74ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 8s 73ms/step - loss: 0.0013\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 8s 72ms/step - loss: 0.0014\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0021\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0042\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0036\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0016\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.8885e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 8.7999e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.2685e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.0043e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.7157e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.3403e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.5299e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.3429e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 7.6044e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.7603e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.2378e-04\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 14s 95ms/step - loss: 0.0032\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0019\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0022\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 91ms/step - loss: 0.0021\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 92ms/step - loss: 0.0019\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 92ms/step - loss: 0.0019\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0020\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 11s 92ms/step - loss: 0.0022\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0023\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0027\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 12s 78ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0022\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0012\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0011\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 9s 78ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 9s 77ms/step - loss: 0.0011\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0013\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0016\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0016\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.3945e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.0730e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.5077e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 7.2379e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.3198e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.3676e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 7.7290e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.1641e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.7924e-04\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 14s 92ms/step - loss: 0.0031\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0032\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0024\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 11s 92ms/step - loss: 0.0020\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 92ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 91ms/step - loss: 0.0019\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0021\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0020\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0019\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 12s 80ms/step - loss: 0.0027\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0025\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0016\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0010\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0013\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 9.1766e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0010\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 9.6223e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0012\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0015\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0016\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0048\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0059\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0013\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0017\n",
            "Epoch 00006: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 14s 95ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0014\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0016\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0016\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0015\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0017\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 12s 79ms/step - loss: 0.0033\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 9s 78ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 9s 78ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 10s 85ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0011\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 9.2308e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 9.3423e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0010\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 9.2275e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 7.9826e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 8.3675e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 10s 85ms/step - loss: 8.8404e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 10s 84ms/step - loss: 7.5650e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0011\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 10s 85ms/step - loss: 8.4327e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 7.0643e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 7.5926e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 7.5712e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 8.4862e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 8.8203e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0010\n",
            "Epoch 00029: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0020\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0022\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0036\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0040\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0028\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 14s 96ms/step - loss: 0.0037\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0018\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0022\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0021\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 13s 80ms/step - loss: 0.0036\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0021\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0025\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 9s 78ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0014\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 9s 78ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0013\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0013\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0013\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0014\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 9s 78ms/step - loss: 0.0016\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0016\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0015\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0028\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0055\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0050\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0017\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0023\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.2063e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 9.2559e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 8.9743e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0017\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0014\n",
            "Epoch 00015: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 14s 95ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0032\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0032\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0025\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0026\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0029\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0030\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0033\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0038\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 13s 80ms/step - loss: 0.0032\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0011\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 10s 82ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 10s 83ms/step - loss: 0.0010\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 9.7720e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 9s 80ms/step - loss: 9.9307e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0013\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0013\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 9s 79ms/step - loss: 0.0012\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 9s 81ms/step - loss: 0.0012\n",
            "Epoch 00021: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0017\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.6846e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.3312e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.0505e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.7161e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.3851e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.0243e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.6985e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.3866e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.0987e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.7918e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.4888e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.1621e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.8327e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.4736e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0916e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.6768e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2573e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 3.8382e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.4530e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.1368e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9067e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7736e-04\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7181e-04\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7197e-04\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7638e-04\n",
            "Epoch 00032: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0034\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0073\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0065\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0041\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0032\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0022\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0027\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0026\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0028\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0031\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0030\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 15s 105ms/step - loss: 0.0039\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 12s 107ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 12s 107ms/step - loss: 0.0022\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0019\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0020\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 12s 106ms/step - loss: 0.0020\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 12s 104ms/step - loss: 0.0021\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 13s 87ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 10s 86ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0012\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 10s 85ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 10s 85ms/step - loss: 0.0010\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 85ms/step - loss: 0.0011\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0014\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 10s 86ms/step - loss: 0.0012\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0012\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0014\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.3984e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.6051e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.2801e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.1576e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.9434e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.4266e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.2828e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.8595e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.9685e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.5591e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2388e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.9894e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.8758e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.9216e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.1521e-04\n",
            "Epoch 00020: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0016\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0011\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.1595e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.8323e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.4437e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 8.4567e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 8.4245e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.5251e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 9.1806e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 9.0951e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.7729e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.8725e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.6535e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.3635e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 3.1190e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.0122e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 2.9626e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 2.9184e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 2.9048e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 2.8981e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.1457e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.0210e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.1568e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.3527e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.6708e-04\n",
            "Epoch 00029: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 15s 105ms/step - loss: 0.0030\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 12s 103ms/step - loss: 0.0021\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 12s 101ms/step - loss: 0.0022\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 12s 104ms/step - loss: 0.0019\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 12s 102ms/step - loss: 0.0019\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 12s 104ms/step - loss: 0.0018\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 12s 101ms/step - loss: 0.0020\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 12s 103ms/step - loss: 0.0018\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 12s 103ms/step - loss: 0.0017\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 12s 102ms/step - loss: 0.0017\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 12s 102ms/step - loss: 0.0015\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 12s 102ms/step - loss: 0.0015\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 12s 102ms/step - loss: 0.0017\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 12s 103ms/step - loss: 0.0013\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 12s 103ms/step - loss: 0.0015\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 13s 108ms/step - loss: 0.0016\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 12s 106ms/step - loss: 0.0016\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 12s 103ms/step - loss: 0.0018\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 12s 103ms/step - loss: 0.0019\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 13s 86ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0015\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 10s 90ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 10s 90ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 91ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 10s 90ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 11s 93ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 11s 91ms/step - loss: 0.0014\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 11s 90ms/step - loss: 0.0014\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0020\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.0571e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 8.1274e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.6946e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.4424e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.9950e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.5574e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.1794e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.8707e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.5932e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.3439e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0277e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.6220e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2714e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.9141e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.6762e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.5616e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.4731e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.4404e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.4573e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.5105e-04\n",
            "Epoch 00026: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0018\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0026\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 9.6686e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.6486e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.6071e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.8571e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 9.3299e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 9.7270e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 9.5259e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.9508e-04\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 15s 109ms/step - loss: 0.0034\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 13s 108ms/step - loss: 0.0025\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 13s 108ms/step - loss: 0.0022\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 13s 113ms/step - loss: 0.0021\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 13s 108ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 12s 107ms/step - loss: 0.0020\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0020\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 12s 106ms/step - loss: 0.0021\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 12s 106ms/step - loss: 0.0021\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 12s 108ms/step - loss: 0.0019\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 23s 175ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0018\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 10s 90ms/step - loss: 0.0018\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 10s 90ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 90ms/step - loss: 0.0011\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 91ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 10s 86ms/step - loss: 0.0013\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0011\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0022\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0041\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0036\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0018\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.8019e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.4440e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.7535e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 15s 105ms/step - loss: 0.0038\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0023\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 12s 103ms/step - loss: 0.0021\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 13s 108ms/step - loss: 0.0016\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 13s 108ms/step - loss: 0.0020\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0017\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 12s 107ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 12s 106ms/step - loss: 0.0020\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 13s 86ms/step - loss: 0.0027\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0018\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0020\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 9.6548e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0011\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0010\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 10s 86ms/step - loss: 0.0010\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0010\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0011\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 9.0182e-04\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.9304e-04\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 7.3610e-04\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.8043e-04\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.4943e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.3569e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.3143e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.2697e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.1639e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.1021e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 6.0353e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.9618e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.8566e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.7460e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.6370e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.4987e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.3518e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.1906e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 5.0187e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.8268e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.6400e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.4290e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.2227e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 4.0049e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.8019e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.6102e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.4394e-04\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.3269e-04\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.2166e-04\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.1528e-04\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.0835e-04\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.0507e-04\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.0226e-04\n",
            "Epoch 36/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 3.0097e-04\n",
            "Epoch 37/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9816e-04\n",
            "Epoch 38/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9666e-04\n",
            "Epoch 39/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9569e-04\n",
            "Epoch 40/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9361e-04\n",
            "Epoch 41/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9239e-04\n",
            "Epoch 42/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.9065e-04\n",
            "Epoch 43/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.8748e-04\n",
            "Epoch 44/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.8716e-04\n",
            "Epoch 45/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.8398e-04\n",
            "Epoch 46/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7996e-04\n",
            "Epoch 47/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7740e-04\n",
            "Epoch 48/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7611e-04\n",
            "Epoch 49/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7507e-04\n",
            "Epoch 50/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.7832e-04\n",
            "Epoch 51/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 2.8292e-04\n",
            "Epoch 00051: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0015\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.3748e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.0874e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.9422e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.4028e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0010\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 15s 106ms/step - loss: 0.0037\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 12s 106ms/step - loss: 0.0029\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 12s 106ms/step - loss: 0.0027\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0024\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0025\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 12s 107ms/step - loss: 0.0023\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 12s 107ms/step - loss: 0.0022\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 12s 106ms/step - loss: 0.0023\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0025\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 12s 106ms/step - loss: 0.0030\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0039\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 12s 105ms/step - loss: 0.0036\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 13s 88ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 10s 86ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0026\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 10s 90ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 10s 90ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 10s 88ms/step - loss: 0.0012\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 10s 89ms/step - loss: 0.0013\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0013\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 10s 90ms/step - loss: 0.0013\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 10s 87ms/step - loss: 0.0013\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0012\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 00008: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0020\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0027\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0021\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.3850e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.7634e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.2377e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 7.8181e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.1765e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 6.3932e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 5.5213e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.8296e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.5462e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.4612e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.4255e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 4.4647e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 4.4301e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 4.4705e-04\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 4.4374e-04\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 4.4362e-04\n",
            "Epoch 00031: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 16s 116ms/step - loss: 0.0031\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 14s 118ms/step - loss: 0.0025\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 14s 118ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 13s 115ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 13s 115ms/step - loss: 0.0019\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 14s 116ms/step - loss: 0.0017\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 13s 116ms/step - loss: 0.0018\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 13s 116ms/step - loss: 0.0019\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 13s 114ms/step - loss: 0.0020\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 14s 94ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0023\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0013\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0013\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 9.8934e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0010\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0010\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 11s 94ms/step - loss: 0.0010\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0020\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0025\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0013\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 00006: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 16s 115ms/step - loss: 0.0027\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 13s 116ms/step - loss: 0.0023\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 13s 115ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 13s 116ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 14s 118ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 13s 115ms/step - loss: 0.0015\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 14s 118ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 14s 119ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0019\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 14s 123ms/step - loss: 0.0016\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 14s 121ms/step - loss: 0.0017\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 14s 98ms/step - loss: 0.0029\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0022\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 12s 100ms/step - loss: 0.0014\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 12s 101ms/step - loss: 0.0014\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 12s 99ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0012\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0017\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0010\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0010\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0011\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0016\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0018\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0023\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 6ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0011\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 9.4845e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.6622e-04\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.7596e-04\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 8.8839e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.0296e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 9.2785e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 9.3890e-04\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 16s 119ms/step - loss: 0.0021\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 14s 120ms/step - loss: 0.0017\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 14s 120ms/step - loss: 0.0025\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 14s 118ms/step - loss: 0.0015\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 14s 120ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 14s 119ms/step - loss: 0.0011\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0019\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 13s 116ms/step - loss: 0.0019\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 14s 119ms/step - loss: 0.0021\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 15s 99ms/step - loss: 0.0024\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0016\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0018\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0014\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 99ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0014\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0016\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 12s 99ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 11s 99ms/step - loss: 0.0011\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 9.6507e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 11s 99ms/step - loss: 0.0011\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0011\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0012\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0012\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0011\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0046\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0036\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0023\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0027\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0012\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0011\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0010\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 6ms/step - loss: 9.7853e-04\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 9.4820e-04\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 9.1821e-04\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.7002e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.3072e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 7.7571e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 7.3447e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 7.2098e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 7.1438e-04\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 7.1997e-04\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 7.2427e-04\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 7.2141e-04\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 7.0991e-04\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.9212e-04\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 6.6858e-04\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 6.4462e-04\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 6.2134e-04\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.9957e-04\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.8464e-04\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 5.7211e-04\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 5.6026e-04\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 5.4351e-04\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 5.2613e-04\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 4.8973e-04\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.7529e-04\n",
            "Epoch 36/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 4.5818e-04\n",
            "Epoch 37/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 4.4816e-04\n",
            "Epoch 38/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 4.3367e-04\n",
            "Epoch 39/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 4.1605e-04\n",
            "Epoch 40/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 3.9704e-04\n",
            "Epoch 41/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 3.8502e-04\n",
            "Epoch 42/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 3.6680e-04\n",
            "Epoch 43/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 3.4996e-04\n",
            "Epoch 44/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 3.4127e-04\n",
            "Epoch 45/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 3.3004e-04\n",
            "Epoch 46/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 3.2598e-04\n",
            "Epoch 47/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 3.4634e-04\n",
            "Epoch 48/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 3.4290e-04\n",
            "Epoch 49/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 3.2167e-04\n",
            "Epoch 50/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 3.1862e-04\n",
            "Epoch 51/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 3.0704e-04\n",
            "Epoch 52/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 3.2047e-04\n",
            "Epoch 53/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 2.9989e-04\n",
            "Epoch 54/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.3326e-04\n",
            "Epoch 55/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 2.9006e-04\n",
            "Epoch 56/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.3585e-04\n",
            "Epoch 57/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 2.7563e-04\n",
            "Epoch 58/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 3.1958e-04\n",
            "Epoch 59/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 2.7626e-04\n",
            "Epoch 60/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.3522e-04\n",
            "Epoch 61/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 2.8145e-04\n",
            "Epoch 62/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 3.6010e-04\n",
            "Epoch 00062: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 16s 117ms/step - loss: 0.0041\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 14s 116ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0021\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 14s 118ms/step - loss: 0.0020\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 13s 116ms/step - loss: 0.0023\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 13s 114ms/step - loss: 0.0020\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 14s 120ms/step - loss: 0.0019\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 14s 118ms/step - loss: 0.0018\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 14s 118ms/step - loss: 0.0020\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 14s 116ms/step - loss: 0.0020\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0021\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 14s 121ms/step - loss: 0.0023\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0030\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 14s 97ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0020\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0020\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0016\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0015\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 0.0012\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 8.7553e-04\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0010\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 9.9930e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 9.8093e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 9.4528e-04\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 11s 95ms/step - loss: 9.1729e-04\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0042\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0046\n",
            "Epoch 00003: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0019\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0028\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 8.7632e-04\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 9.4561e-04\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0010\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 8.9735e-04\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 17s 120ms/step - loss: 0.0034\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 13s 116ms/step - loss: 0.0026\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 14s 119ms/step - loss: 0.0024\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 14s 116ms/step - loss: 0.0021\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0020\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0023\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 14s 117ms/step - loss: 0.0022\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 14s 116ms/step - loss: 0.0019\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 13s 116ms/step - loss: 0.0019\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 13s 114ms/step - loss: 0.0023\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 13s 114ms/step - loss: 0.0023\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 13s 114ms/step - loss: 0.0021\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 13s 114ms/step - loss: 0.0027\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 13s 113ms/step - loss: 0.0025\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 14s 97ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0018\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0019\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0013\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0012\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0012\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0011\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0011\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0011\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0010\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 9.9872e-04\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 9.6013e-04\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 12s 100ms/step - loss: 9.4831e-04\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 11s 96ms/step - loss: 0.0011\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0011\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 11s 98ms/step - loss: 0.0015\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0013\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 11s 97ms/step - loss: 0.0013\n",
            "Epoch 00022: early stopping\n",
            "data loaded for AXISBANK!!\n",
            "             Close\n",
            "Date              \n",
            "2002-01-01   26.30\n",
            "2002-01-02   26.05\n",
            "2002-01-03   27.20\n",
            "2002-01-04   27.20\n",
            "2002-01-07   27.80\n",
            "...            ...\n",
            "2019-01-09  670.10\n",
            "2019-01-10  663.25\n",
            "2019-01-11  666.50\n",
            "2019-01-14  659.20\n",
            "2019-01-15  660.60\n",
            "\n",
            "[4245 rows x 1 columns]\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 1s 3ms/step - loss: 0.0045\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0035\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 7.9906e-04\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.7162e-04\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.2467e-04\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.0953e-04\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.0533e-04\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.0385e-04\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.0290e-04\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.9943e-04\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.9332e-04\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.8347e-04\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.6787e-04\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.5029e-04\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.3121e-04\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.1288e-04\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.9626e-04\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.8126e-04\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.6751e-04\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.5536e-04\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.4415e-04\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.3409e-04\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.2674e-04\n",
            "Epoch 26/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.2116e-04\n",
            "Epoch 27/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.1489e-04\n",
            "Epoch 28/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.0833e-04\n",
            "Epoch 29/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.0209e-04\n",
            "Epoch 30/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.9689e-04\n",
            "Epoch 31/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.9106e-04\n",
            "Epoch 32/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.8561e-04\n",
            "Epoch 33/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.8025e-04\n",
            "Epoch 34/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.7481e-04\n",
            "Epoch 35/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.7219e-04\n",
            "Epoch 36/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.6652e-04\n",
            "Epoch 37/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.6214e-04\n",
            "Epoch 38/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.6007e-04\n",
            "Epoch 39/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.5510e-04\n",
            "Epoch 40/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.5383e-04\n",
            "Epoch 41/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.4890e-04\n",
            "Epoch 42/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.4960e-04\n",
            "Epoch 43/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 3.4325e-04\n",
            "Epoch 44/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.4603e-04\n",
            "Epoch 45/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.3891e-04\n",
            "Epoch 46/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.4551e-04\n",
            "Epoch 47/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.3375e-04\n",
            "Epoch 48/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.3911e-04\n",
            "Epoch 49/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.3416e-04\n",
            "Epoch 00049: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 1s 3ms/step - loss: 0.0032\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 8.6311e-04\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.7941e-04\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 6.3888e-04\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 6.0902e-04\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.7757e-04\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 5.5585e-04\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.3740e-04\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.2006e-04\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.2922e-04\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.0926e-04\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.1197e-04\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.9448e-04\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.9281e-04\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.8185e-04\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.0537e-04\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.5180e-04\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.6608e-04\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.5142e-04\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.3861e-04\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.4029e-04\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.8461e-04\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.4073e-04\n",
            "Epoch 26/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.5881e-04\n",
            "Epoch 27/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.1110e-04\n",
            "Epoch 28/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.6337e-04\n",
            "Epoch 29/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.6097e-04\n",
            "Epoch 30/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.0694e-04\n",
            "Epoch 31/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.3639e-04\n",
            "Epoch 32/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.0309e-04\n",
            "Epoch 33/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.1219e-04\n",
            "Epoch 34/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.9601e-04\n",
            "Epoch 35/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.8489e-04\n",
            "Epoch 36/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.9625e-04\n",
            "Epoch 37/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.0366e-04\n",
            "Epoch 38/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.7556e-04\n",
            "Epoch 39/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 5.9153e-04\n",
            "Epoch 40/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 4.1844e-04\n",
            "Epoch 41/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.9617e-04\n",
            "Epoch 42/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.9938e-04\n",
            "Epoch 43/200\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 3.8884e-04\n",
            "Epoch 00043: early stopping\n",
            "Epoch 1/200\n",
            "117/117 [==============================] - 7s 41ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 5s 39ms/step - loss: 0.0056\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 5s 40ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 4s 38ms/step - loss: 0.0017\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 4s 38ms/step - loss: 0.0030\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 4s 38ms/step - loss: 0.0017\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 5s 39ms/step - loss: 0.0021\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 4s 38ms/step - loss: 0.0016\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 5s 40ms/step - loss: 0.0017\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 5s 39ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 4s 37ms/step - loss: 0.0013\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 4s 37ms/step - loss: 0.0013\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 4s 38ms/step - loss: 0.0017\n",
            "Epoch 14/200\n",
            " 85/117 [====================>.........] - ETA: 1s - loss: 8.9018e-04"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-675f64290fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             history_model_lstm = model.fit(X_tr_t, y_train, epochs=200, batch_size=32, verbose=1, shuffle=False,\n\u001b[0;32m---> 67\u001b[0;31m                                            callbacks=[early_stop])\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tst_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zof0S6bfyT4e",
        "outputId": "86c4c01d-0cda-469c-b42a-778765f9fb43"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import LSTM, GRU, Conv1D, MaxPooling1D\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from operator import add\n",
        "import json\n",
        "import itertools\n",
        "\n",
        "symbols = ['ACC', 'HCLTECH', 'JSWSTEEL', 'AXISBANK', 'INFY', 'HDFC', 'INFY', 'BHARTIARTL', 'ULTRACEMCO', 'CIPLA', 'MARUTI']\n",
        "\n",
        "# (x, y) here x indicates the input size and y indicates the prediction size\n",
        "# (30, 7) means we predict next 7 days stocks using previous 30 days prices\n",
        "window_size = [(30, 7), (30, 14), (60, 7), (60, 14)]\n",
        "\n",
        "\n",
        "def adj_r2_score(r2, n, k):\n",
        "    return 1 - ((1 - r2) * ((n - 1) / (n - k - 1)))\n",
        "\n",
        "\n",
        "def window_transform(series, input_size, output_size):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    slen = len(series)\n",
        "    n_windows = slen - (input_size + output_size) + 1\n",
        "\n",
        "    for i in range(n_windows):\n",
        "        X.append(series[i:i + input_size])\n",
        "        y.append(series[i+input_size: i+input_size+output_size])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    X = X.reshape(X.shape[0], X.shape[1])\n",
        "    y = y.reshape(y.shape[0], y.shape[1])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def test_window_transform(series, input_size, output_size):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    slen = len(series)\n",
        "\n",
        "    j = input_size\n",
        "    while (j+output_size) < slen:\n",
        "        X.append(series[j - input_size:j])\n",
        "        y.append(series[j:j+output_size])\n",
        "        j = j + output_size\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    X = X.reshape(X.shape[0], X.shape[1])\n",
        "    y = y.reshape(y.shape[0], y.shape[1])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def make_ann_model(input_size, output_size):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, activation='relu', input_shape=(input_size,)))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(output_size, activation='linear'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_cnn_model(input_size, output_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=5, strides=1, activation='relu', input_shape=(input_size, 1)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(output_size, activation='linear'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_lstm_model(input_size, output_size):\n",
        "    model_lstm = Sequential()\n",
        "    model_lstm.add(LSTM(256, input_shape=(input_size, 1), activation='relu', kernel_initializer='lecun_uniform',\n",
        "                        return_sequences=True))\n",
        "    model_lstm.add(Dropout(0.2))\n",
        "    model_lstm.add(LSTM(128, input_shape=(input_size, 1), activation='relu', kernel_initializer='lecun_uniform',\n",
        "                        return_sequences=False))\n",
        "    model_lstm.add(Dropout(0.2))\n",
        "    model_lstm.add(Dense(output_size, activation='linear'))\n",
        "    opt = Adam(clipnorm=1.0)\n",
        "    model_lstm.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "    return model_lstm\n",
        "\n",
        "\n",
        "def make_gru_model(input_size, output_size):\n",
        "    model = Sequential()\n",
        "    model.add(GRU(256, input_shape=(input_size, 1), activation='relu', kernel_initializer='lecun_uniform',\n",
        "                  return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(128, input_shape=(input_size, 1), activation='relu', kernel_initializer='lecun_uniform',\n",
        "                  return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(output_size, activation='linear'))\n",
        "    opt = Adam(clipnorm=1.0)\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def test_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    true_ = [item for sublist in y_test for item in sublist]\n",
        "    pred_ = [item for sublist in y_pred for item in sublist]\n",
        "\n",
        "    error = mse(true_, pred_)\n",
        "\n",
        "    return error, pred_\n",
        "\n",
        "\n",
        "def plot_all_model():\n",
        "    print('plotting_model')\n",
        "    ann_model = make_ann_model(3)\n",
        "    cnn_model = make_cnn_model(3)\n",
        "    lstm_model = make_lstm_model(3)\n",
        "    gru_model = make_gru_model(3)\n",
        "\n",
        "    plot_model(ann_model, to_file='ann_plot.png', show_shapes=True, show_layer_names=True)\n",
        "    plot_model(cnn_model, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)\n",
        "    plot_model(lstm_model, to_file='lstm_plot.png', show_shapes=True, show_layer_names=True)\n",
        "    plot_model(gru_model, to_file='gru_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "result = []\n",
        "\n",
        "for sym in symbols:\n",
        "\n",
        "  json_descriptor = {'stock': sym, 'ann': [], 'gru': [], 'lstm': [], 'cnn': []}\n",
        "\n",
        "  data = pd.read_csv('drive/MyDrive/Findan/Sb_1/data/{}.csv'.format(sym), index_col=0)\n",
        "  print('data loaded for {}!!'.format(sym))\n",
        "  \n",
        "  data.index = pd.to_datetime(data.index)\n",
        "  data_frame = data.copy()\n",
        "  df = data_frame[[\"Close\"]]\n",
        "\n",
        "  split_date = pd.Timestamp('01-01-2017')\n",
        "\n",
        "  train = df.loc[:split_date]\n",
        "  test = df.loc[split_date:]\n",
        "\n",
        "  sc = MinMaxScaler()\n",
        "  train_sc = sc.fit_transform(train)\n",
        "  test_sc = sc.transform(test)\n",
        "\n",
        "  ann = []\n",
        "  gru = []\n",
        "  lstm = []\n",
        "  cnn = []\n",
        "\n",
        "  for in_size, out_size in window_size:\n",
        "      ann_result = []\n",
        "      gru_result = []\n",
        "      lstm_result = []\n",
        "      cnn_result = []\n",
        "      pred_ANN = []\n",
        "      pred_LSTM = []\n",
        "      pred_GRU = []\n",
        "      pred_CNN = []\n",
        "      for i in range(5):\n",
        "          # ''''''''ANN'''''''''''''''''''\n",
        "          X_train, y_train = window_transform(train_sc, in_size, out_size)\n",
        "          print('X train: ', X_train.shape)\n",
        "          print('y train: ', y_train.shape)\n",
        "          X_test, y_test = test_window_transform(test_sc, in_size, out_size)\n",
        "          flat_y_test = [item for sublist in y_test for item in sublist]\n",
        "          print('X test: ', X_test.shape)\n",
        "          print('y test: ', y_test.shape)\n",
        "          model = make_ann_model(in_size, out_size)\n",
        "          early_stop = EarlyStopping(monitor='loss', patience=2, verbose=1)\n",
        "          history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, callbacks=[early_stop],\n",
        "                              shuffle=False)\n",
        "\n",
        "          error, pred_ann = test_model(model, X_test, y_test)\n",
        "\n",
        "          ann_result.append(error)\n",
        "          # ''''''''ANN''''''''''''''''''''\n",
        "\n",
        "          # ''''''''CNN''''''''''''''''''''\n",
        "          X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "          y_train = y_train.reshape(y_train.shape[0], y_train.shape[1])\n",
        "          print('X train: ', X_train.shape)\n",
        "          print('y train: ', y_train.shape)\n",
        "          X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "          y_test = y_test.reshape(y_test.shape[0], y_test.shape[1])\n",
        "          print('X train: ', X_train.shape)\n",
        "          print('y train: ', y_train.shape)\n",
        "          model = make_cnn_model(in_size, out_size)\n",
        "          print(model.summary())\n",
        "          early_stop = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
        "          history_model_cnn = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, shuffle=False,\n",
        "                                        callbacks=[early_stop])\n",
        "\n",
        "          error, pred_cnn = test_model(model, X_test, y_test)\n",
        "          cnn_result.append(error)\n",
        "          # ''''''''CNN''''''''''''''''''''\n",
        "\n",
        "          # ''''''''''LSTM''''''''''''''''''\n",
        "          model = make_lstm_model(in_size, out_size)\n",
        "          print(model.summary())\n",
        "          early_stop = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
        "          history_model_lstm = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1,\n",
        "                                          shuffle=False, callbacks=[early_stop])\n",
        "\n",
        "          error, pred_lstm = test_model(model, X_test, y_test)\n",
        "          lstm_result.append(error)\n",
        "          # \"''''''''LSTM'''''''''''''''''''\n",
        "\n",
        "          # ''''''''GRU'''''''''''''''''''''\n",
        "          model = make_gru_model(in_size, out_size)\n",
        "          early_stop = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
        "          history_model_gru = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, shuffle=False,\n",
        "                                        callbacks=[early_stop])\n",
        "\n",
        "          error, pred_gru = test_model(model, X_test, y_test)\n",
        "          gru_result.append(error)\n",
        "          # ''''''''GRU'''''''''''''''''''''\n",
        "\n",
        "          pred_ANN.append(pred_ann)\n",
        "          pred_CNN.append(pred_cnn)\n",
        "          pred_LSTM.append(pred_lstm)\n",
        "          pred_GRU.append(pred_gru)\n",
        "      # update optimal window size param\n",
        "      ann.append([in_size, out_size, min(ann_result), np.mean(ann_result), np.std(ann_result)])\n",
        "      gru.append([in_size, out_size, min(gru_result), np.mean(gru_result), np.std(gru_result)])\n",
        "      lstm.append([in_size, out_size, min(lstm_result), np.mean(lstm_result), np.std(lstm_result)])\n",
        "      cnn.append([in_size, out_size, min(cnn_result), np.mean(cnn_result), np.std(cnn_result)])\n",
        "\n",
        "      plot_ann = [0] * len(pred_ANN[0])\n",
        "      for pred in pred_ANN:\n",
        "          plot_ann = list(map(add, plot_ann, pred))\n",
        "\n",
        "      for i in range(len(plot_ann)):\n",
        "          plot_ann[i] = plot_ann[i] / 5\n",
        "\n",
        "      plot_lstm = [0] * len(pred_LSTM[0])\n",
        "      for pred in pred_LSTM:\n",
        "          plot_lstm = list(map(add, plot_lstm, pred))\n",
        "\n",
        "      for i in range(len(plot_lstm)):\n",
        "          plot_lstm[i] = plot_lstm[i] / 5\n",
        "\n",
        "      plot_gru = [0] * len(pred_GRU[0])\n",
        "      for pred in pred_GRU:\n",
        "          plot_gru = list(map(add, plot_gru, pred))\n",
        "\n",
        "      for i in range(len(plot_gru)):\n",
        "          plot_gru[i] = plot_gru[i] / 5\n",
        "\n",
        "      plot_cnn = [0] * len(pred_CNN[0])\n",
        "      for pred in pred_CNN:\n",
        "          plot_cnn = list(map(add, plot_cnn, pred))\n",
        "\n",
        "      for i in range(len(plot_cnn)):\n",
        "          plot_cnn[i] = plot_cnn[i] / 5\n",
        "\n",
        "      # save prediction plots\n",
        "      plt.plot(flat_y_test, '-', label='True Values', color='#1b9e77')\n",
        "      plt.plot(plot_ann, label='MLP Prediction', color='#d95f02')\n",
        "      plt.plot(plot_cnn, ':', label='CNN Prediction', color='#7570b3')\n",
        "      plt.plot(plot_lstm, label='LSTM Prediction', color='#e7298a')\n",
        "      plt.plot(plot_gru, label='GRU Prediction', color='#66a61e')\n",
        "      plt.title(\"Prediction\")\n",
        "      plt.xlabel('Time')\n",
        "      plt.ylabel('Normalized Stock Prices')\n",
        "      plt.legend()\n",
        "      plt.savefig('drive/MyDrive/Findan/Sb_1/plots/multi_step/' + sym + ' ' + ' in_sz ' + str(in_size) + ' out_sz ' + str(out_size))\n",
        "      plt.clf()\n",
        "      \n",
        "      print(y_test)\n",
        "      print(plot_ann)\n",
        "      # save prediction plots\n",
        "      df = pd.DataFrame(zip(flat_y_test, plot_ann, plot_cnn, plot_lstm, plot_gru), columns = ['actual', 'ann', 'cnn', 'lstm', 'gru'])\n",
        "      df.to_csv(path_or_buf='drive/MyDrive/Findan/Sb_1/predictions/multi_step/predictions_{}_{}_{}.csv'.format(sym, in_size, out_size))\n",
        "\n",
        "  json_descriptor['ann'] = ann\n",
        "  json_descriptor['lstm'] = lstm\n",
        "  json_descriptor['cnn'] = cnn\n",
        "  json_descriptor['gru'] = gru\n",
        "  result.append(json_descriptor)\n",
        "\n",
        "  with open('data.json', 'w') as f:\n",
        "      json.dump(result, f)"
      ],
      "id": "zof0S6bfyT4e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data loaded for ACC!!\n",
            "X train:  (3704, 30)\n",
            "y train:  (3704, 7)\n",
            "X test:  (67, 30)\n",
            "y test:  (67, 7)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 2ms/step - loss: 0.0217\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 1ms/step - loss: 0.0037\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 1ms/step - loss: 0.0028\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 1ms/step - loss: 0.0013\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 00030: early stopping\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "Model: \"sequential_313\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_150 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_79 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_150 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_473 (Dense)            (None, 7)                 5831      \n",
            "=================================================================\n",
            "Total params: 6,215\n",
            "Trainable params: 6,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0056\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0049\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0028\n",
            "Epoch 00004: early stopping\n",
            "Model: \"sequential_314\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_158 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_308 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_159 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_309 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_474 (Dense)            (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 462,215\n",
            "Trainable params: 462,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 24s 181ms/step - loss: 0.0095\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 21s 181ms/step - loss: 0.0095\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 21s 183ms/step - loss: 0.0054\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 21s 183ms/step - loss: 0.0047\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 21s 181ms/step - loss: 0.0053\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 21s 182ms/step - loss: 0.0046\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 21s 181ms/step - loss: 0.0041\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0042\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 21s 182ms/step - loss: 0.0038\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 21s 183ms/step - loss: 0.0036\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 21s 183ms/step - loss: 0.0032\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 21s 184ms/step - loss: 0.0035\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 21s 185ms/step - loss: 0.0029\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 21s 182ms/step - loss: 0.0029\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 21s 181ms/step - loss: 0.0023\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 21s 184ms/step - loss: 0.0023\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 21s 182ms/step - loss: 0.0026\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 21s 183ms/step - loss: 0.0026\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 21s 182ms/step - loss: 0.0024\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 19s 138ms/step - loss: 0.0091\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 16s 136ms/step - loss: 0.0074\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 16s 137ms/step - loss: 0.0074\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 16s 138ms/step - loss: 0.0057\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 16s 138ms/step - loss: 0.0046\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0043\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 16s 137ms/step - loss: 0.0042\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0047\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 16s 137ms/step - loss: 0.0046\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 16s 138ms/step - loss: 0.0030\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 16s 137ms/step - loss: 0.0030\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 16s 137ms/step - loss: 0.0033\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 16s 137ms/step - loss: 0.0031\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 16s 135ms/step - loss: 0.0024\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 16s 137ms/step - loss: 0.0024\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 16s 137ms/step - loss: 0.0026\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 16s 136ms/step - loss: 0.0023\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0027\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0027\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0023\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 16s 138ms/step - loss: 0.0027\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 16s 138ms/step - loss: 0.0024\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 16s 138ms/step - loss: 0.0023\n",
            "Epoch 00023: early stopping\n",
            "X train:  (3704, 30)\n",
            "y train:  (3704, 7)\n",
            "X test:  (67, 30)\n",
            "y test:  (67, 7)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 2ms/step - loss: 0.0146\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0036\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0025\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 1ms/step - loss: 0.0019\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 00026: early stopping\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "Model: \"sequential_317\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_151 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_80 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_151 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_479 (Dense)            (None, 7)                 5831      \n",
            "=================================================================\n",
            "Total params: 6,215\n",
            "Trainable params: 6,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0026\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0047\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0035\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 00033: early stopping\n",
            "Model: \"sequential_318\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_160 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_312 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_161 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_313 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_480 (Dense)            (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 462,215\n",
            "Trainable params: 462,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 24s 185ms/step - loss: 0.0092\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 22s 188ms/step - loss: 0.0096\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 21s 183ms/step - loss: 0.0079\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 22s 187ms/step - loss: 0.0062\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0051\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0051\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0043\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0036\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0044\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0039\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0032\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0030\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 22s 188ms/step - loss: 0.0028\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0029\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 22s 187ms/step - loss: 0.0028\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0025\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0025\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0033\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0025\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0024\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0027\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0027\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0025\n",
            "Epoch 00023: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 20s 141ms/step - loss: 0.0100\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 16s 142ms/step - loss: 0.0107\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 16s 138ms/step - loss: 0.0065\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 16s 141ms/step - loss: 0.0048\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0047\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0046\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0044\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0040\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0044\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 16s 141ms/step - loss: 0.0041\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0030\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 16s 142ms/step - loss: 0.0027\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0032\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0025\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0029\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0024\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0025\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 16s 141ms/step - loss: 0.0030\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0026\n",
            "Epoch 00019: early stopping\n",
            "X train:  (3704, 30)\n",
            "y train:  (3704, 7)\n",
            "X test:  (67, 30)\n",
            "y test:  (67, 7)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 2ms/step - loss: 0.0030\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 00015: early stopping\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "Model: \"sequential_321\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_152 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_81 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_152 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_485 (Dense)            (None, 7)                 5831      \n",
            "=================================================================\n",
            "Total params: 6,215\n",
            "Trainable params: 6,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0050\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0047\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 00004: early stopping\n",
            "Model: \"sequential_322\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_162 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_316 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_163 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_317 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_486 (Dense)            (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 462,215\n",
            "Trainable params: 462,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 24s 186ms/step - loss: 0.0100\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0084\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 21s 184ms/step - loss: 0.0077\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0055\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0044\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 22s 185ms/step - loss: 0.0046\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 22s 185ms/step - loss: 0.0046\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0041\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 21s 184ms/step - loss: 0.0038\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 22s 188ms/step - loss: 0.0032\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0035\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0036\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0032\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0029\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 22s 188ms/step - loss: 0.0028\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 23s 200ms/step - loss: 0.0026\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0029\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 22s 188ms/step - loss: 0.0022\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0022\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0026\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0024\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0021\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0023\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0023\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0023\n",
            "Epoch 00025: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 20s 143ms/step - loss: 0.0081\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0087\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0062\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0048\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 17s 143ms/step - loss: 0.0045\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 17s 143ms/step - loss: 0.0042\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0040\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0032\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0039\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 16s 141ms/step - loss: 0.0032\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 17s 143ms/step - loss: 0.0035\n",
            "Epoch 00011: early stopping\n",
            "X train:  (3704, 30)\n",
            "y train:  (3704, 7)\n",
            "X test:  (67, 30)\n",
            "y test:  (67, 7)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 2ms/step - loss: 0.0372\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0045\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0033\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0026\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 00013: early stopping\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "Model: \"sequential_325\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_153 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_82 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_153 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_491 (Dense)            (None, 7)                 5831      \n",
            "=================================================================\n",
            "Total params: 6,215\n",
            "Trainable params: 6,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0049\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0028\n",
            "Epoch 00004: early stopping\n",
            "Model: \"sequential_326\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_164 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_320 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_165 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_321 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_492 (Dense)            (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 462,215\n",
            "Trainable params: 462,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 25s 193ms/step - loss: 0.0094\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0111\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0068\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 22s 187ms/step - loss: 0.0052\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 22s 186ms/step - loss: 0.0044\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0044\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0053\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0047\n",
            "Epoch 00008: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 20s 143ms/step - loss: 0.0090\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0074\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 17s 143ms/step - loss: 0.0054\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0052\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 17s 142ms/step - loss: 0.0050\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0047\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0041\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 17s 143ms/step - loss: 0.0042\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0041\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0032\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0032\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0030\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 17s 143ms/step - loss: 0.0027\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 16s 141ms/step - loss: 0.0030\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 17s 142ms/step - loss: 0.0026\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 17s 143ms/step - loss: 0.0031\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 16s 141ms/step - loss: 0.0025\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0028\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 16s 140ms/step - loss: 0.0031\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 16s 139ms/step - loss: 0.0026\n",
            "Epoch 00020: early stopping\n",
            "X train:  (3704, 30)\n",
            "y train:  (3704, 7)\n",
            "X test:  (67, 30)\n",
            "y test:  (67, 7)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 2ms/step - loss: 0.0076\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0033\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 00019: early stopping\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "X train:  (3704, 30, 1)\n",
            "y train:  (3704, 7)\n",
            "Model: \"sequential_329\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_154 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_83 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_154 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_497 (Dense)            (None, 7)                 5831      \n",
            "=================================================================\n",
            "Total params: 6,215\n",
            "Trainable params: 6,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0025\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0049\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0033\n",
            "Epoch 00004: early stopping\n",
            "Model: \"sequential_330\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_166 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_324 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_167 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_325 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_498 (Dense)            (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 462,215\n",
            "Trainable params: 462,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 25s 192ms/step - loss: 0.0112\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 22s 188ms/step - loss: 0.0082\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0066\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0058\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0054\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0046\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0045\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0037\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0041\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0034\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0034\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0033\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0028\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0031\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0029\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0027\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0030\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0027\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0024\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0025\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0025\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0024\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0025\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0023\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0024\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0022\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0021\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0021\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0025\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0024\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0021\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0019\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0019\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0022\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0021\n",
            "Epoch 36/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0018\n",
            "Epoch 37/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0023\n",
            "Epoch 38/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0023\n",
            "Epoch 39/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0020\n",
            "Epoch 00039: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 20s 144ms/step - loss: 0.0095\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 17s 143ms/step - loss: 0.0114\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 16s 142ms/step - loss: 0.0060\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0054\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0047\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0047\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0046\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0039\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0038\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0033\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0030\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0032\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0036\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0035\n",
            "Epoch 00014: early stopping\n",
            "[[0.81817348 0.80431857 0.81224003 0.81826523 0.81517617 0.8193357\n",
            "  0.80719354]\n",
            " [0.80138243 0.7887815  0.78511133 0.7835515  0.78287864 0.77422315\n",
            "  0.77407022]\n",
            " [0.77033888 0.77682285 0.77926964 0.77807683 0.78749694 0.79055542\n",
            "  0.79153413]\n",
            " [0.78511133 0.78339858 0.78605946 0.76975777 0.7785356  0.77590531\n",
            "  0.7761194 ]\n",
            " [0.78859799 0.79235992 0.78966846 0.80624541 0.81597137 0.82101786\n",
            "  0.83297651]\n",
            " [0.8197333  0.82321997 0.83306827 0.83591265 0.83566797 0.84120382\n",
            "  0.83487277]\n",
            " [0.84618914 0.84600563 0.83646318 0.90469782 0.90488133 0.90139467\n",
            "  0.922437  ]\n",
            " [0.91665647 0.89616467 0.90564595 0.91512723 0.93720944 0.96846709\n",
            "  0.96231955]\n",
            " [0.95568265 0.95504037 0.94925985 0.95051382 0.97972229 0.95794593\n",
            "  0.94347932]\n",
            " [0.9465378  0.91683998 0.91723758 0.88998654 0.91246636 0.92020431\n",
            "  0.91534133]\n",
            " [0.92191705 0.92307928 0.93595547 0.92671886 0.92837044 0.90469782\n",
            "  0.90784805]\n",
            " [0.91206875 0.91188525 0.90561537 0.91008074 0.89913139 0.90781747\n",
            "  0.9240274 ]\n",
            " [0.92586249 0.93262173 0.93571079 0.93161243 0.92286518 0.88729508\n",
            "  0.88821263]\n",
            " [0.88815146 0.88087228 0.89283093 0.88857964 0.89702104 0.90754221\n",
            "  0.90613531]\n",
            " [0.9176046  0.93149009 0.9652251  0.96375703 0.99528994 0.99057989\n",
            "  0.9979814 ]\n",
            " [0.98275018 0.96892586 0.9668461  0.97678615 0.97755077 0.96546978\n",
            "  0.98115977]\n",
            " [0.98067042 0.98189381 0.98467702 1.00568877 1.02923905 1.03092121\n",
            "  1.033368  ]\n",
            " [1.03018718 1.03468314 1.00850257 0.99862368 1.0134573  1.02960607\n",
            "  1.01058233]\n",
            " [1.01926841 1.01822853 1.01620993 1.0239173  1.01143871 1.0323587\n",
            "  1.02367262]\n",
            " [1.02960607 1.022908   1.03379618 1.00507707 1.02578297 1.02709812\n",
            "  1.01465011]\n",
            " [1.01740274 1.02125642 1.05410448 1.04951676 1.05018963 1.03541718\n",
            "  1.03856741]\n",
            " [1.03327624 1.01422192 0.99204796 0.95442868 0.92038782 0.92005138\n",
            "  0.89414607]\n",
            " [0.9284622  0.93522143 0.9292574  0.93164301 0.96167727 0.98580866\n",
            "  0.97880475]\n",
            " [0.98241375 0.97103621 0.98669562 1.00443479 1.01645461 1.01816736\n",
            "  1.01281502]\n",
            " [1.00143748 1.01113286 1.00911426 1.02348911 1.01201982 1.01244801\n",
            "  1.03471373]\n",
            " [1.02856619 1.03703817 1.02238806 1.02593589 1.02501835 1.01663812\n",
            "  1.01529239]\n",
            " [0.99865427 0.99480059 0.99629924 0.98791901 1.00492415 1.0200942\n",
            "  1.00015292]\n",
            " [0.96589797 0.9648275  0.97519574 0.96907879 0.96017862 0.95748715\n",
            "  0.95011622]\n",
            " [0.95088084 0.94195009 0.94730242 0.95794593 0.96048446 0.95552973\n",
            "  0.96369586]\n",
            " [0.99030462 0.98164913 0.9678554  0.96525569 0.95436751 0.95944458\n",
            "  0.95965867]\n",
            " [0.98011989 0.97822364 0.98534989 0.97482873 0.9873379  0.98348422\n",
            "  0.99134451]\n",
            " [0.99730854 0.98076217 0.98801077 1.00721801 1.02358087 1.02884145\n",
            "  1.03804747]\n",
            " [1.03012601 1.03287864 1.02403964 1.02578297 1.04110595 1.05349278\n",
            "  1.04752875]\n",
            " [1.04661121 1.0408001  1.0393932  1.01672988 0.9845241  0.97773428\n",
            "  0.98525814]\n",
            " [0.97877416 0.97091387 0.98421825 0.94922926 0.92558723 0.91200759\n",
            "  0.89270859]\n",
            " [0.95745657 0.9376988  0.93194886 0.91858331 0.91344507 0.93136775\n",
            "  0.9210301 ]\n",
            " [0.92509787 0.92809518 0.92020431 0.93188769 0.93775997 0.92047957\n",
            "  0.91451554]\n",
            " [0.92109126 0.90417788 0.89754098 0.8852459  0.86674211 0.8587289\n",
            "  0.87588696]\n",
            " [0.88533766 0.9077563  0.90234279 0.88081111 0.87772205 0.87276731\n",
            "  0.87496942]\n",
            " [0.86946415 0.8567103  0.8595241  0.85392709 0.84383411 0.86184854\n",
            "  0.87276731]\n",
            " [0.85759726 0.87126866 0.87181918 0.86450942 0.86319427 0.85976878\n",
            "  0.8545082 ]\n",
            " [0.8615427  0.88604111 0.89243333 0.88420602 0.88289087 0.87695743\n",
            "  0.87919011]\n",
            " [0.87717152 0.8806276  0.86701737 0.87570345 0.89255566 0.8742048\n",
            "  0.86236849]\n",
            " [0.85622094 0.85362124 0.85065451 0.84514925 0.83548446 0.81878517\n",
            "  0.80939564]\n",
            " [0.78520308 0.78468314 0.77838268 0.76238684 0.74388304 0.73238317\n",
            "  0.72531808]\n",
            " [0.73697088 0.73088451 0.73067042 0.72302422 0.72265721 0.75030585\n",
            "  0.73323954]\n",
            " [0.72183142 0.70776242 0.72666381 0.72696966 0.72614387 0.72926352\n",
            "  0.72651089]\n",
            " [0.73583925 0.72131148 0.71819183 0.71715195 0.70745657 0.70173722\n",
            "  0.69858698]\n",
            " [0.7136347  0.72641913 0.75214093 0.72229019 0.7116161  0.74131392\n",
            "  0.72923293]\n",
            " [0.73700147 0.74801199 0.77177636 0.76198923 0.76327379 0.76033766\n",
            "  0.75394544]\n",
            " [0.74749205 0.73993761 0.69662956 0.70978101 0.71183019 0.70130903\n",
            "  0.7126254 ]\n",
            " [0.72351358 0.82425985 0.82068143 0.85313188 0.86065574 0.84157083\n",
            "  0.85744434]\n",
            " [0.85842305 0.86438708 0.85065451 0.85392709 0.86288843 0.86145094\n",
            "  0.88252386]\n",
            " [0.8669562  0.85316247 0.87811965 0.87536702 0.89671519 0.89998777\n",
            "  0.92476144]\n",
            " [0.92197822 0.92540372 0.93228529 0.91488255 0.90867384 0.91512723\n",
            "  0.92411916]\n",
            " [0.93840225 0.8932897  0.86873012 0.87448006 0.88325789 0.85667972\n",
            "  0.85111329]\n",
            " [0.87252263 0.90179227 0.89231099 0.88221801 0.8782114  0.86346954\n",
            "  0.85603744]\n",
            " [0.87827257 0.88949719 0.87671275 0.87126866 0.88426719 0.84517984\n",
            "  0.8563127 ]\n",
            " [0.8261561  0.82373991 0.81835699 0.81701126 0.79936384 0.84120382\n",
            "  0.85340714]\n",
            " [0.87191094 0.86353071 0.7930022  0.79162589 0.76645461 0.76724982\n",
            "  0.75825789]\n",
            " [0.74727795 0.74773673 0.7443724  0.7626621  0.78156349 0.80957915\n",
            "  0.8235564 ]\n",
            " [0.80710179 0.81618547 0.81725593 0.80174945 0.81306582 0.82328114\n",
            "  0.84753487]\n",
            " [0.84010276 0.84025569 0.82086494 0.83747247 0.81263763 0.80199413\n",
            "  0.80569489]\n",
            " [0.80067898 0.81710301 0.8303768  0.84952288 0.84472107 0.82159897\n",
            "  0.79263518]\n",
            " [0.80441033 0.78529484 0.79817103 0.8301933  0.83976633 0.83780891\n",
            "  0.84046978]\n",
            " [0.84001101 0.86609983 0.86203205 0.83316002 0.80722413 0.82664546\n",
            "  0.81428921]\n",
            " [0.82682897 0.84420113 0.8323954  0.82942868 0.81003793 0.820345\n",
            "  0.8257585 ]]\n",
            "[0.8480683326721191, 0.850538682937622, 0.8492719888687134, 0.8581799387931823, 0.8610064387321472, 0.854245948791504, 0.8510567784309387, 0.8439387321472168, 0.8389225244522095, 0.8438974499702454, 0.8514918088912964, 0.8531902432441711, 0.8424894094467164, 0.8500806331634522, 0.815438175201416, 0.8102973699569702, 0.8177322626113892, 0.8153187990188598, 0.8284974932670593, 0.8137802481651306, 0.823286521434784, 0.8099705219268799, 0.8074485063552856, 0.8060568332672119, 0.8062362551689148, 0.8217658877372742, 0.8050075054168702, 0.8145372986793518, 0.8071045041084289, 0.8091336369514466, 0.8021953701972961, 0.8102127909660339, 0.8170239329338074, 0.8131433248519897, 0.8142378807067872, 0.8313841342926025, 0.8280822396278381, 0.8264254808425904, 0.8326793551445008, 0.8401307940483094, 0.829665732383728, 0.833782148361206, 0.854940676689148, 0.8550206542015075, 0.8559586524963378, 0.8602606773376464, 0.8686485648155212, 0.8547907829284668, 0.8600520014762878, 0.8979937791824341, 0.8951850652694702, 0.8973924517631531, 0.9048300862312317, 0.9103084325790405, 0.8974030137062072, 0.899963092803955, 0.9356517553329468, 0.9357904195785522, 0.9380984902381897, 0.9478422999382019, 0.9536690592765809, 0.9377921342849731, 0.9413087010383606, 0.972692346572876, 0.9678925752639771, 0.974916398525238, 0.978377890586853, 0.9814693927764893, 0.9696002960205078, 0.9706831574440002, 0.9403499484062194, 0.9341784358024597, 0.9411306023597718, 0.9435536861419678, 0.9518672823905945, 0.9401531338691711, 0.9456471681594849, 0.9303518295288086, 0.9373918414115906, 0.937318742275238, 0.9327990770339966, 0.9493474006652832, 0.9318832874298095, 0.9429216861724854, 0.923835563659668, 0.9288470983505249, 0.9194793224334716, 0.9288116097450256, 0.9394413113594056, 0.9329362750053406, 0.9364142894744873, 0.9286739587783813, 0.9350815892219544, 0.9286591529846191, 0.9343695640563965, 0.9436042070388794, 0.9338035345077514, 0.941959547996521, 0.9118296146392822, 0.9117326617240906, 0.9080479264259338, 0.9154218912124634, 0.9283009529113769, 0.9171961307525635, 0.926036536693573, 0.965799081325531, 0.9731272220611572, 0.9723302841186523, 0.971862506866455, 0.9891140341758728, 0.9631467342376709, 0.9798739910125732, 0.9911198258399964, 0.9893062829971313, 0.9885947704315186, 0.9997070789337158, 1.0019267678260804, 0.9941472053527832, 0.9973628282546997, 1.0115335702896118, 1.0078731060028077, 1.0157236576080322, 1.0179832100868225, 1.0277255296707153, 1.0056198835372925, 1.0172402620315553, 1.0191306829452516, 1.0247001647949219, 1.027899146080017, 1.0276305198669433, 1.043410873413086, 1.025410771369934, 1.0331424713134765, 1.027940535545349, 1.0278267860412598, 1.0279545068740845, 1.0320480585098266, 1.0406572818756104, 1.0281558156013488, 1.0352622270584106, 1.023740530014038, 1.0332845449447632, 1.0305268526077271, 1.031333899497986, 1.0462367534637451, 1.0285655021667481, 1.0396087169647217, 1.0431851625442505, 1.0468777179718018, 1.0412535429000855, 1.0452348947525025, 1.0577361106872558, 1.0428089857101441, 1.0542725563049316, 0.9800734877586365, 0.98141850233078, 0.9789896965026855, 0.9844955921173095, 0.9902303695678711, 0.9901066541671752, 0.9935317277908325, 0.9538894534111023, 0.9574699163436889, 0.9530006289482117, 0.9521931767463684, 0.9741084337234497, 0.9549545288085938, 0.9694504380226135, 0.9942737698554993, 1.0104655861854552, 0.9987339615821839, 0.998311448097229, 1.023731279373169, 1.0015501737594605, 1.0178605556488036, 1.0286977291107178, 1.0234752893447876, 1.0179063558578492, 1.0351895809173584, 1.030504536628723, 1.0326195001602172, 1.0311357736587525, 1.0275225162506103, 1.031528115272522, 1.035082793235779, 1.0346456527709962, 1.0490751266479492, 1.0290618896484376, 1.0375661373138427, 1.007787036895752, 1.0104753971099854, 1.00637788772583, 1.012590193748474, 1.0263981342315673, 1.0130940914154052, 1.0231865406036378, 0.9766514778137207, 0.9797123908996582, 0.9766197681427002, 0.978597891330719, 0.9902375698089599, 0.979330313205719, 0.9925273299217224, 0.9655453324317932, 0.969116497039795, 0.9597420454025268, 0.966270923614502, 0.9791133999824524, 0.96617351770401, 0.9764567971229553, 0.9739437341690064, 0.9783492088317871, 0.9682816743850708, 0.9753499984741211, 0.9877874374389648, 0.9778064370155335, 0.984214448928833, 0.9905385375022888, 0.9912012934684753, 0.9852263808250428, 0.9927379012107849, 1.0021804094314575, 0.9915309429168702, 0.9973234176635742, 1.0107018113136292, 1.0163597822189332, 1.0157804489135742, 1.0178238153457642, 1.030656099319458, 1.0144670724868774, 1.0248444557189942, 1.0405806303024292, 1.0410246133804322, 1.043458914756775, 1.0477732419967651, 1.0553695678710937, 1.0414799451828003, 1.04901180267334, 1.0239764213562013, 1.024240207672119, 1.0278542041778564, 1.029250478744507, 1.039323353767395, 1.0283552289009095, 1.034852433204651, 0.9589451909065246, 0.9645064830780029, 0.9624834299087525, 0.9622240662574768, 0.9756602764129638, 0.9649070382118226, 0.9741567850112915, 0.9347684860229493, 0.9426629304885864, 0.9352185487747192, 0.9336938261985779, 0.9533241987228394, 0.9409479141235352, 0.9537450551986695, 0.9380530834197998, 0.9441950917243958, 0.9312535405158997, 0.9368690609931946, 0.9529713749885559, 0.9426050782203674, 0.9539524674415588, 0.9072453141212463, 0.907798683643341, 0.903289520740509, 0.9111424803733825, 0.9167253375053406, 0.9171793103218079, 0.9229992508888245, 0.897627079486847, 0.903237271308899, 0.9015261650085449, 0.8978813767433167, 0.9190730094909668, 0.9013165354728698, 0.9119397163391113, 0.8803462862968445, 0.8839967370033264, 0.8757524609565734, 0.8825209140777588, 0.8952448964118958, 0.8879376173019409, 0.894842004776001, 0.8821961045265198, 0.8834858536720276, 0.8808918476104737, 0.8841630339622497, 0.8921479463577271, 0.8819234251976014, 0.8924110770225525, 0.8999855756759644, 0.9012735247611999, 0.8976959824562073, 0.9016206741333008, 0.9147605538368225, 0.8996430277824402, 0.9076033711433411, 0.8960775375366211, 0.8987436175346375, 0.8940637111663818, 0.901721203327179, 0.9082812666893005, 0.9003024458885193, 0.9050020337104797, 0.8655640006065368, 0.8614805936813354, 0.8631169438362122, 0.8672720432281494, 0.8737727284431458, 0.8649129986763, 0.8761376023292542, 0.7923196792602539, 0.7915350914001464, 0.7919237017631531, 0.7917740106582641, 0.8039986848831177, 0.7969159483909607, 0.8048314213752746, 0.7585591435432434, 0.7606862664222718, 0.7534333229064941, 0.7556298494338989, 0.7720638036727905, 0.7608120560646057, 0.7714516639709472, 0.758358108997345, 0.7580260992050171, 0.7456000566482544, 0.7553372979164124, 0.7666499972343445, 0.7606536507606506, 0.7662281274795533, 0.7542139768600464, 0.7475263118743897, 0.743454885482788, 0.752536940574646, 0.7530483722686767, 0.7540015339851379, 0.7529562473297119, 0.7597040653228759, 0.7574909687042236, 0.7573439121246338, 0.7596695303916932, 0.772217082977295, 0.7609141230583191, 0.7625783920288086, 0.7839914679527282, 0.7898658514022827, 0.7870563507080078, 0.7911776423454284, 0.7991540551185607, 0.7908477544784546, 0.7906830191612244, 0.7603384494781494, 0.7523511528968811, 0.7556865811347961, 0.7658920764923096, 0.7608572721481324, 0.7654007792472839, 0.7629059672355651, 0.8330840587615966, 0.8355538487434387, 0.8412968277931213, 0.8365283012390137, 0.8602987408638001, 0.8221303343772888, 0.8426010251045227, 0.8734997749328614, 0.8827306509017945, 0.8711414575576782, 0.8905982613563538, 0.8932598829269409, 0.8897738933563233, 0.88341783285141, 0.9088074922561645, 0.8915145754814148, 0.9059438228607177, 0.912453043460846, 0.9101584672927856, 0.8919782519340516, 0.9087852835655212, 0.9283751964569091, 0.9286310911178589, 0.9411866784095764, 0.9340290665626526, 0.9522815465927124, 0.9179457426071167, 0.935364055633545, 0.9117223620414734, 0.9040021896362305, 0.9072774052619934, 0.9128182411193848, 0.9154255747795105, 0.9087425351142884, 0.9094557642936707, 0.8894669532775878, 0.8910366773605347, 0.8952359080314636, 0.8912055492401123, 0.9066247463226318, 0.889570152759552, 0.9036363244056702, 0.8855886936187745, 0.898770534992218, 0.888173234462738, 0.8918946504592895, 0.90755136013031, 0.8983125567436219, 0.9027499437332154, 0.8485068321228028, 0.8475811839103699, 0.8438967585563659, 0.8554167866706848, 0.8572350859642028, 0.8591592073440552, 0.8648492932319641, 0.8270835995674133, 0.8269593715667725, 0.8291425943374634, 0.8237969040870666, 0.8375134110450745, 0.8252414584159851, 0.8349863290786743, 0.8058722853660584, 0.7985683083534241, 0.7917225003242493, 0.7981480479240417, 0.8157937049865722, 0.8014270901679993, 0.8105971813201904, 0.8332737684249878, 0.8423141956329345, 0.8348867535591126, 0.836742901802063, 0.8459230542182923, 0.8394757747650147, 0.8451227426528931, 0.8632870554924011, 0.8509251832962036, 0.8466007471084595, 0.8599017858505249, 0.8544145107269288, 0.8557517886161804, 0.8491165637969971, 0.8483101010322571, 0.8469385385513306, 0.847972321510315, 0.8515880823135376, 0.8614970803260803, 0.8450265407562256, 0.8526084780693054, 0.840705955028534, 0.843068265914917, 0.8396783947944642, 0.8482043981552124, 0.8573617696762085, 0.8488678455352783, 0.8550611853599548, 0.8555418610572815, 0.8561977505683899, 0.8565398097038269, 0.8605575680732727, 0.8669672846794129, 0.8565835595130921, 0.8649392366409302]\n",
            "X train:  (3697, 30)\n",
            "y train:  (3697, 14)\n",
            "X test:  (33, 30)\n",
            "y test:  (33, 14)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 2ms/step - loss: 0.0115\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0046\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0034\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0028\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0025\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0024\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 00012: early stopping\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "Model: \"sequential_333\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_155 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_84 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_155 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_503 (Dense)            (None, 14)                11662     \n",
            "=================================================================\n",
            "Total params: 12,046\n",
            "Trainable params: 12,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0032\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0064\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0032\n",
            "Epoch 00004: early stopping\n",
            "Model: \"sequential_334\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_168 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_328 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_169 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_329 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_504 (Dense)            (None, 14)                1806      \n",
            "=================================================================\n",
            "Total params: 463,118\n",
            "Trainable params: 463,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 26s 192ms/step - loss: 0.0126\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0088\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0083\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0079\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0070\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0058\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0058\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0043\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 22s 191ms/step - loss: 0.0046\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0041\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0037\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0039\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0033\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 22s 189ms/step - loss: 0.0030\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0032\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0031\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 22s 190ms/step - loss: 0.0035\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 20s 148ms/step - loss: 0.0113\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0201\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0088\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0068\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0067\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0058\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0050\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0049\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0047\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0043\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0037\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0035\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0034\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0035\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0032\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0036\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0034\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0036\n",
            "Epoch 00018: early stopping\n",
            "X train:  (3697, 30)\n",
            "y train:  (3697, 14)\n",
            "X test:  (33, 30)\n",
            "y test:  (33, 14)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 16s 133ms/step - loss: 0.0175\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0037\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0028\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 00023: early stopping\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "Model: \"sequential_337\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_156 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_85 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_156 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_509 (Dense)            (None, 14)                11662     \n",
            "=================================================================\n",
            "Total params: 12,046\n",
            "Trainable params: 12,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.0032\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0066\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0049\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0035\n",
            "Epoch 00004: early stopping\n",
            "Model: \"sequential_338\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_170 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_332 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_171 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_333 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_510 (Dense)            (None, 14)                1806      \n",
            "=================================================================\n",
            "Total params: 463,118\n",
            "Trainable params: 463,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 26s 197ms/step - loss: 0.0137\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0092\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0077\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0064\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 23s 199ms/step - loss: 0.0055\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0056\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0058\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0053\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0047\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0042\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0038\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0038\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0037\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0034\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0033\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0034\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0028\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0031\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0030\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0032\n",
            "Epoch 00020: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 20s 148ms/step - loss: 0.0107\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0155\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0079\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0079\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0056\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 17s 144ms/step - loss: 0.0045\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0046\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0040\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0037\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0039\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0039\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0040\n",
            "Epoch 00012: early stopping\n",
            "X train:  (3697, 30)\n",
            "y train:  (3697, 14)\n",
            "X test:  (33, 30)\n",
            "y test:  (33, 14)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 2ms/step - loss: 0.1781\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0743\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0157\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0083\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0067\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0049\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0033\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0025\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 36/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 37/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 38/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 39/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 00039: early stopping\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "Model: \"sequential_341\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_157 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_86 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_157 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_515 (Dense)            (None, 14)                11662     \n",
            "=================================================================\n",
            "Total params: 12,046\n",
            "Trainable params: 12,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0033\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0057\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0046\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0032\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0029\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0028\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0028\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0027\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0026\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0026\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 0.0023\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 1s 7ms/step - loss: 0.0022\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0022\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0021\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0021\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0021\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0019\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0019\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0019\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0019\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0019\n",
            "Epoch 00030: early stopping\n",
            "Model: \"sequential_342\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_172 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_336 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_173 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_337 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_516 (Dense)            (None, 14)                1806      \n",
            "=================================================================\n",
            "Total params: 463,118\n",
            "Trainable params: 463,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 26s 196ms/step - loss: 0.0118\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0097\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0072\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0068\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0058\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0055\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0048\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 23s 199ms/step - loss: 0.0046\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0045\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0040\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0039\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0035\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0035\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0033\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0031\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0034\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0033\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0029\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0030\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0028\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0026\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0027\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0026\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0027\n",
            "Epoch 00024: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 21s 148ms/step - loss: 0.0117\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0155\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0098\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0083\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0066\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0053\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0051\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0042\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0041\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0048\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 17s 146ms/step - loss: 0.0046\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0035\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0036\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0033\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0033\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0030\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 17s 145ms/step - loss: 0.0033\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0037\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0034\n",
            "Epoch 00019: early stopping\n",
            "X train:  (3697, 30)\n",
            "y train:  (3697, 14)\n",
            "X test:  (33, 30)\n",
            "y test:  (33, 14)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 2ms/step - loss: 0.0069\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0035\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0027\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0025\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0024\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 00019: early stopping\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "Model: \"sequential_345\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_158 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_87 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_158 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_521 (Dense)            (None, 14)                11662     \n",
            "=================================================================\n",
            "Total params: 12,046\n",
            "Trainable params: 12,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 4ms/step - loss: 0.0032\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0067\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0046\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0033\n",
            "Epoch 00004: early stopping\n",
            "Model: \"sequential_346\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_174 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_340 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_175 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_341 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_522 (Dense)            (None, 14)                1806      \n",
            "=================================================================\n",
            "Total params: 463,118\n",
            "Trainable params: 463,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 25s 194ms/step - loss: 0.0117\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0105\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0068\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0065\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0065\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 22s 194ms/step - loss: 0.0056\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0051\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0052\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0042\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0039\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0039\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0035\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 23s 194ms/step - loss: 0.0033\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0035\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0036\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0035\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 20s 151ms/step - loss: 0.0120\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0170\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0082\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0081\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0062\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 17s 147ms/step - loss: 0.0057\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0065\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 18s 153ms/step - loss: 0.0046\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 18s 152ms/step - loss: 0.0035\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 17s 151ms/step - loss: 0.0039\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0035\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 17s 151ms/step - loss: 0.0037\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0038\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0037\n",
            "Epoch 00014: early stopping\n",
            "X train:  (3697, 30)\n",
            "y train:  (3697, 14)\n",
            "X test:  (33, 30)\n",
            "y test:  (33, 14)\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 2ms/step - loss: 0.0440\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0065\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0037\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0025\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 00015: early stopping\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "X train:  (3697, 30, 1)\n",
            "y train:  (3697, 14)\n",
            "Model: \"sequential_349\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_159 (Conv1D)          (None, 26, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_88 (MaxPooling (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_159 (Flatten)        (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense_527 (Dense)            (None, 14)                11662     \n",
            "=================================================================\n",
            "Total params: 12,046\n",
            "Trainable params: 12,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.0035\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0069\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0045\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0033\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0032\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0031\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0030\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0029\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0028\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0026\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0025\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 34/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 35/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 36/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 37/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 38/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 39/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 40/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 41/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 42/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 43/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 44/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 45/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 46/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 47/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 48/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 49/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 50/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 51/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 52/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 53/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 54/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 55/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 56/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 57/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 58/200\n",
            "116/116 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 59/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 60/200\n",
            "116/116 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 00060: early stopping\n",
            "Model: \"sequential_350\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_176 (LSTM)              (None, 30, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_344 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_177 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_345 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_528 (Dense)            (None, 14)                1806      \n",
            "=================================================================\n",
            "Total params: 463,118\n",
            "Trainable params: 463,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 26s 196ms/step - loss: 0.0134\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0086\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0073\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0066\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0059\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0060\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 23s 201ms/step - loss: 0.0052\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0046\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0042\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0043\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0042\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0038\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0034\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0033\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 22s 194ms/step - loss: 0.0034\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0031\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0030\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0034\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0029\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0029\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0028\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 23s 198ms/step - loss: 0.0028\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0026\n",
            "Epoch 24/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0025\n",
            "Epoch 25/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0030\n",
            "Epoch 26/200\n",
            "116/116 [==============================] - 22s 192ms/step - loss: 0.0027\n",
            "Epoch 27/200\n",
            "116/116 [==============================] - 22s 193ms/step - loss: 0.0025\n",
            "Epoch 28/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0027\n",
            "Epoch 29/200\n",
            "116/116 [==============================] - 23s 195ms/step - loss: 0.0025\n",
            "Epoch 30/200\n",
            "116/116 [==============================] - 23s 197ms/step - loss: 0.0023\n",
            "Epoch 31/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0027\n",
            "Epoch 32/200\n",
            "116/116 [==============================] - 23s 196ms/step - loss: 0.0025\n",
            "Epoch 33/200\n",
            "116/116 [==============================] - 23s 199ms/step - loss: 0.0025\n",
            "Epoch 00033: early stopping\n",
            "Epoch 1/200\n",
            "116/116 [==============================] - 21s 151ms/step - loss: 0.0109\n",
            "Epoch 2/200\n",
            "116/116 [==============================] - 17s 148ms/step - loss: 0.0127\n",
            "Epoch 3/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0081\n",
            "Epoch 4/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0070\n",
            "Epoch 5/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0063\n",
            "Epoch 6/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0054\n",
            "Epoch 7/200\n",
            "116/116 [==============================] - 17s 151ms/step - loss: 0.0055\n",
            "Epoch 8/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0047\n",
            "Epoch 9/200\n",
            "116/116 [==============================] - 18s 152ms/step - loss: 0.0045\n",
            "Epoch 10/200\n",
            "116/116 [==============================] - 18s 151ms/step - loss: 0.0044\n",
            "Epoch 11/200\n",
            "116/116 [==============================] - 18s 152ms/step - loss: 0.0038\n",
            "Epoch 12/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0038\n",
            "Epoch 13/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0038\n",
            "Epoch 14/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0037\n",
            "Epoch 15/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0032\n",
            "Epoch 16/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0033\n",
            "Epoch 17/200\n",
            "116/116 [==============================] - 18s 152ms/step - loss: 0.0030\n",
            "Epoch 18/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0032\n",
            "Epoch 19/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0034\n",
            "Epoch 20/200\n",
            "116/116 [==============================] - 17s 149ms/step - loss: 0.0025\n",
            "Epoch 21/200\n",
            "116/116 [==============================] - 18s 151ms/step - loss: 0.0027\n",
            "Epoch 22/200\n",
            "116/116 [==============================] - 18s 151ms/step - loss: 0.0029\n",
            "Epoch 23/200\n",
            "116/116 [==============================] - 17s 150ms/step - loss: 0.0028\n",
            "Epoch 00023: early stopping\n",
            "[[0.81817348 0.80431857 0.81224003 0.81826523 0.81517617 0.8193357\n",
            "  0.80719354 0.80138243 0.7887815  0.78511133 0.7835515  0.78287864\n",
            "  0.77422315 0.77407022]\n",
            " [0.77033888 0.77682285 0.77926964 0.77807683 0.78749694 0.79055542\n",
            "  0.79153413 0.78511133 0.78339858 0.78605946 0.76975777 0.7785356\n",
            "  0.77590531 0.7761194 ]\n",
            " [0.78859799 0.79235992 0.78966846 0.80624541 0.81597137 0.82101786\n",
            "  0.83297651 0.8197333  0.82321997 0.83306827 0.83591265 0.83566797\n",
            "  0.84120382 0.83487277]\n",
            " [0.84618914 0.84600563 0.83646318 0.90469782 0.90488133 0.90139467\n",
            "  0.922437   0.91665647 0.89616467 0.90564595 0.91512723 0.93720944\n",
            "  0.96846709 0.96231955]\n",
            " [0.95568265 0.95504037 0.94925985 0.95051382 0.97972229 0.95794593\n",
            "  0.94347932 0.9465378  0.91683998 0.91723758 0.88998654 0.91246636\n",
            "  0.92020431 0.91534133]\n",
            " [0.92191705 0.92307928 0.93595547 0.92671886 0.92837044 0.90469782\n",
            "  0.90784805 0.91206875 0.91188525 0.90561537 0.91008074 0.89913139\n",
            "  0.90781747 0.9240274 ]\n",
            " [0.92586249 0.93262173 0.93571079 0.93161243 0.92286518 0.88729508\n",
            "  0.88821263 0.88815146 0.88087228 0.89283093 0.88857964 0.89702104\n",
            "  0.90754221 0.90613531]\n",
            " [0.9176046  0.93149009 0.9652251  0.96375703 0.99528994 0.99057989\n",
            "  0.9979814  0.98275018 0.96892586 0.9668461  0.97678615 0.97755077\n",
            "  0.96546978 0.98115977]\n",
            " [0.98067042 0.98189381 0.98467702 1.00568877 1.02923905 1.03092121\n",
            "  1.033368   1.03018718 1.03468314 1.00850257 0.99862368 1.0134573\n",
            "  1.02960607 1.01058233]\n",
            " [1.01926841 1.01822853 1.01620993 1.0239173  1.01143871 1.0323587\n",
            "  1.02367262 1.02960607 1.022908   1.03379618 1.00507707 1.02578297\n",
            "  1.02709812 1.01465011]\n",
            " [1.01740274 1.02125642 1.05410448 1.04951676 1.05018963 1.03541718\n",
            "  1.03856741 1.03327624 1.01422192 0.99204796 0.95442868 0.92038782\n",
            "  0.92005138 0.89414607]\n",
            " [0.9284622  0.93522143 0.9292574  0.93164301 0.96167727 0.98580866\n",
            "  0.97880475 0.98241375 0.97103621 0.98669562 1.00443479 1.01645461\n",
            "  1.01816736 1.01281502]\n",
            " [1.00143748 1.01113286 1.00911426 1.02348911 1.01201982 1.01244801\n",
            "  1.03471373 1.02856619 1.03703817 1.02238806 1.02593589 1.02501835\n",
            "  1.01663812 1.01529239]\n",
            " [0.99865427 0.99480059 0.99629924 0.98791901 1.00492415 1.0200942\n",
            "  1.00015292 0.96589797 0.9648275  0.97519574 0.96907879 0.96017862\n",
            "  0.95748715 0.95011622]\n",
            " [0.95088084 0.94195009 0.94730242 0.95794593 0.96048446 0.95552973\n",
            "  0.96369586 0.99030462 0.98164913 0.9678554  0.96525569 0.95436751\n",
            "  0.95944458 0.95965867]\n",
            " [0.98011989 0.97822364 0.98534989 0.97482873 0.9873379  0.98348422\n",
            "  0.99134451 0.99730854 0.98076217 0.98801077 1.00721801 1.02358087\n",
            "  1.02884145 1.03804747]\n",
            " [1.03012601 1.03287864 1.02403964 1.02578297 1.04110595 1.05349278\n",
            "  1.04752875 1.04661121 1.0408001  1.0393932  1.01672988 0.9845241\n",
            "  0.97773428 0.98525814]\n",
            " [0.97877416 0.97091387 0.98421825 0.94922926 0.92558723 0.91200759\n",
            "  0.89270859 0.95745657 0.9376988  0.93194886 0.91858331 0.91344507\n",
            "  0.93136775 0.9210301 ]\n",
            " [0.92509787 0.92809518 0.92020431 0.93188769 0.93775997 0.92047957\n",
            "  0.91451554 0.92109126 0.90417788 0.89754098 0.8852459  0.86674211\n",
            "  0.8587289  0.87588696]\n",
            " [0.88533766 0.9077563  0.90234279 0.88081111 0.87772205 0.87276731\n",
            "  0.87496942 0.86946415 0.8567103  0.8595241  0.85392709 0.84383411\n",
            "  0.86184854 0.87276731]\n",
            " [0.85759726 0.87126866 0.87181918 0.86450942 0.86319427 0.85976878\n",
            "  0.8545082  0.8615427  0.88604111 0.89243333 0.88420602 0.88289087\n",
            "  0.87695743 0.87919011]\n",
            " [0.87717152 0.8806276  0.86701737 0.87570345 0.89255566 0.8742048\n",
            "  0.86236849 0.85622094 0.85362124 0.85065451 0.84514925 0.83548446\n",
            "  0.81878517 0.80939564]\n",
            " [0.78520308 0.78468314 0.77838268 0.76238684 0.74388304 0.73238317\n",
            "  0.72531808 0.73697088 0.73088451 0.73067042 0.72302422 0.72265721\n",
            "  0.75030585 0.73323954]\n",
            " [0.72183142 0.70776242 0.72666381 0.72696966 0.72614387 0.72926352\n",
            "  0.72651089 0.73583925 0.72131148 0.71819183 0.71715195 0.70745657\n",
            "  0.70173722 0.69858698]\n",
            " [0.7136347  0.72641913 0.75214093 0.72229019 0.7116161  0.74131392\n",
            "  0.72923293 0.73700147 0.74801199 0.77177636 0.76198923 0.76327379\n",
            "  0.76033766 0.75394544]\n",
            " [0.74749205 0.73993761 0.69662956 0.70978101 0.71183019 0.70130903\n",
            "  0.7126254  0.72351358 0.82425985 0.82068143 0.85313188 0.86065574\n",
            "  0.84157083 0.85744434]\n",
            " [0.85842305 0.86438708 0.85065451 0.85392709 0.86288843 0.86145094\n",
            "  0.88252386 0.8669562  0.85316247 0.87811965 0.87536702 0.89671519\n",
            "  0.89998777 0.92476144]\n",
            " [0.92197822 0.92540372 0.93228529 0.91488255 0.90867384 0.91512723\n",
            "  0.92411916 0.93840225 0.8932897  0.86873012 0.87448006 0.88325789\n",
            "  0.85667972 0.85111329]\n",
            " [0.87252263 0.90179227 0.89231099 0.88221801 0.8782114  0.86346954\n",
            "  0.85603744 0.87827257 0.88949719 0.87671275 0.87126866 0.88426719\n",
            "  0.84517984 0.8563127 ]\n",
            " [0.8261561  0.82373991 0.81835699 0.81701126 0.79936384 0.84120382\n",
            "  0.85340714 0.87191094 0.86353071 0.7930022  0.79162589 0.76645461\n",
            "  0.76724982 0.75825789]\n",
            " [0.74727795 0.74773673 0.7443724  0.7626621  0.78156349 0.80957915\n",
            "  0.8235564  0.80710179 0.81618547 0.81725593 0.80174945 0.81306582\n",
            "  0.82328114 0.84753487]\n",
            " [0.84010276 0.84025569 0.82086494 0.83747247 0.81263763 0.80199413\n",
            "  0.80569489 0.80067898 0.81710301 0.8303768  0.84952288 0.84472107\n",
            "  0.82159897 0.79263518]\n",
            " [0.80441033 0.78529484 0.79817103 0.8301933  0.83976633 0.83780891\n",
            "  0.84046978 0.84001101 0.86609983 0.86203205 0.83316002 0.80722413\n",
            "  0.82664546 0.81428921]]\n",
            "[0.8520993590354919, 0.8361783862113953, 0.8446847438812256, 0.830044960975647, 0.8292667984962463, 0.8538230538368226, 0.8406580209732055, 0.8323784589767456, 0.8371436595916748, 0.8051584005355835, 0.820971405506134, 0.829833722114563, 0.8254167675971985, 0.8148316860198974, 0.831177294254303, 0.8173547506332397, 0.827463686466217, 0.8199903845787049, 0.8124163389205933, 0.82804434299469, 0.8207679390907288, 0.8174267649650574, 0.8238544344902039, 0.8034894227981567, 0.8160196661949157, 0.8127399325370789, 0.8163970112800598, 0.801377785205841, 0.813770079612732, 0.7992911338806152, 0.8105617642402649, 0.8099911570549011, 0.8017197370529174, 0.814176595211029, 0.806200110912323, 0.8059824109077454, 0.8091645121574402, 0.7875824451446534, 0.8029000520706177, 0.7978317618370057, 0.800793194770813, 0.7825689315795898, 0.8663051843643188, 0.8512205123901367, 0.8591852784156799, 0.8466959595680237, 0.8412082195281982, 0.8646530389785767, 0.856786572933197, 0.8457485318183899, 0.8526290774345398, 0.8215427041053772, 0.8413844466209411, 0.8422703146934509, 0.8412262797355652, 0.8229180216789246, 0.9604038715362548, 0.949190866947174, 0.9534066677093506, 0.9247081875801086, 0.9219292044639588, 0.9583744406700134, 0.9522130131721497, 0.9258652567863465, 0.9319853782653809, 0.8965305209159851, 0.922408378124237, 0.9277832746505738, 0.9246164083480835, 0.9091185569763184, 0.9557699799537659, 0.9504518270492553, 0.9573554515838623, 0.9389464020729065, 0.9310310006141662, 0.9503430247306823, 0.9541741251945496, 0.9372129678726197, 0.9329498410224915, 0.9161602020263672, 0.9386149168014526, 0.9314337611198426, 0.936810839176178, 0.9231905102729797, 0.9386824488639831, 0.9264291763305664, 0.9355482459068298, 0.9303156971931458, 0.9209803462028503, 0.9326444149017334, 0.9323960423469544, 0.9227154016494751, 0.9273443698883057, 0.9039215564727783, 0.9196120619773864, 0.9114346027374267, 0.9201377153396606, 0.8966179728507996, 0.9312432527542114, 0.9177540898323059, 0.9285887598991394, 0.9178418040275573, 0.9094575643539429, 0.9242785811424256, 0.9222769379615784, 0.9127955198287964, 0.9208969593048095, 0.8963552594184876, 0.9088624477386474, 0.9033393502235413, 0.9088599443435669, 0.8906163930892944, 1.0032474875450135, 0.9883557438850403, 0.9939610242843628, 0.9740955710411072, 0.9749092698097229, 0.9925583124160766, 0.9904419541358948, 0.9741637349128723, 0.981939697265625, 0.9435250878334045, 0.9660818576812744, 0.9730204701423645, 0.9756671905517578, 0.9480399847030639, 1.04391930103302, 1.036079478263855, 1.0423492908477783, 1.0198281288146973, 1.0142667531967162, 1.0365049362182617, 1.0376075029373169, 1.017413318157196, 1.0164498209953308, 0.9898109555244445, 1.0162397861480712, 1.0097695589065552, 1.0171738982200622, 0.9954638838768005, 1.0476032018661499, 1.0399773359298705, 1.0479222774505614, 1.0324301719665527, 1.0226035118103027, 1.0387080192565918, 1.0438172340393066, 1.0245638132095336, 1.025886106491089, 0.9999194025993348, 1.0230059266090392, 1.013955819606781, 1.0259946823120116, 1.0010469675064086, 0.9887732982635498, 0.9815879583358764, 0.9892005801200867, 0.9837068676948547, 0.9778943657875061, 0.9796079516410827, 0.9805064678192139, 0.9792657136917114, 0.9809772133827209, 0.9587868928909302, 0.9762032270431519, 0.9697534561157226, 0.9789839267730713, 0.9529157996177673, 1.0169614911079408, 1.0048094987869263, 1.015457558631897, 1.0082989931106567, 0.9973193287849427, 1.011538279056549, 1.0120691299438476, 0.9940061330795288, 1.0021108269691468, 0.9708384037017822, 0.9921357035636902, 0.979788863658905, 0.993295419216156, 0.9639451146125794, 1.0505311727523803, 1.0351526498794557, 1.0477847814559937, 1.024442195892334, 1.0197089076042176, 1.0405938386917115, 1.0388468742370605, 1.023396074771881, 1.025066351890564, 0.9963200449943542, 1.0181686997413635, 1.0132344245910645, 1.024096667766571, 1.0016450762748719, 0.9960435032844543, 0.9860721468925476, 0.9979747772216797, 0.9894225239753723, 0.9827302455902099, 0.9874670147895813, 0.9895248651504517, 0.9810226678848266, 0.9840251326560974, 0.9639876484870911, 0.9788168549537659, 0.9684483766555786, 0.9823567271232605, 0.9585572004318237, 0.9883243680000305, 0.9732666850090027, 0.9863969922065735, 0.9789937496185303, 0.9704951047897339, 0.9811508178710937, 0.9782070279121399, 0.970156466960907, 0.9753398180007935, 0.9491840243339539, 0.9666723251342774, 0.9600831747055054, 0.9734678506851197, 0.9428935170173645, 1.0333586931228638, 1.019946813583374, 1.031699275970459, 1.0101134061813355, 1.0043426513671876, 1.0265594005584717, 1.0244728922843933, 1.0047471523284912, 1.0129713892936707, 0.9791173934936523, 0.9984420895576477, 0.9977420926094055, 1.0024213671684266, 0.9833380341529846, 1.0403809309005738, 1.0268437147140503, 1.037908172607422, 1.0201584458351136, 1.014894151687622, 1.0283185720443726, 1.0303073406219483, 1.019142985343933, 1.0214271664619445, 0.9935175657272339, 1.0143860936164857, 1.0103344202041626, 1.0197004079818726, 0.9920575499534607, 0.94918133020401, 0.9407094240188598, 0.9560311913490296, 0.9562456130981445, 0.9378857612609863, 0.9448657631874084, 0.9435193300247192, 0.9422165751457214, 0.9455244660377502, 0.9327793955802918, 0.9404549241065979, 0.9258665323257447, 0.9365064263343811, 0.9209899544715882, 0.9166212677955627, 0.9007273316383362, 0.9134907364845276, 0.9116621017456055, 0.9048721790313721, 0.9100390434265136, 0.9053214073181153, 0.9062792062759399, 0.9184833765029907, 0.8882178068161011, 0.8996993660926819, 0.8986399054527283, 0.9029747724533081, 0.8773508310317993, 0.8931200981140137, 0.8807841300964355, 0.8921780467033387, 0.8885322451591492, 0.8759682178497314, 0.8879831194877624, 0.8858942270278931, 0.8818405628204345, 0.8861896991729736, 0.8669129371643066, 0.8792532205581665, 0.870271372795105, 0.8741791248321533, 0.8578693389892578, 0.9087400436401367, 0.8932342886924743, 0.9056026935577393, 0.90013507604599, 0.8883531212806701, 0.9029386878013611, 0.9012452840805054, 0.8930267453193664, 0.9005907416343689, 0.8739583611488342, 0.8885022401809692, 0.8818819522857666, 0.8891457200050354, 0.8661493539810181, 0.8751322984695434, 0.861117959022522, 0.8718563914299011, 0.8661845326423645, 0.8609237670898438, 0.8698040962219238, 0.8640933394432068, 0.8634236454963684, 0.8704479694366455, 0.8470359086990357, 0.8595344424247742, 0.8584619641304017, 0.8629042387008667, 0.8419679284095765, 0.7714026808738709, 0.7593184590339661, 0.7727608799934387, 0.7793354988098145, 0.7668146133422852, 0.7711159229278565, 0.7644139409065247, 0.7699732661247254, 0.772676694393158, 0.7675517797470093, 0.7734011292457581, 0.75708087682724, 0.7665049076080322, 0.7519261837005615, 0.7522411108016968, 0.7352117896080017, 0.7457044839859008, 0.7491607546806336, 0.7452979326248169, 0.75349200963974, 0.7405219912528992, 0.745117461681366, 0.7563861846923828, 0.7306798100471497, 0.7415291428565979, 0.7428407073020935, 0.7443552136421203, 0.7222695112228393, 0.7880305647850037, 0.7709692120552063, 0.783433985710144, 0.7773848176002502, 0.7708205223083496, 0.7915930390357971, 0.7779489994049072, 0.7769076466560364, 0.7814308404922485, 0.7548425197601318, 0.7686795473098755, 0.7693879723548889, 0.7654363870620727, 0.7567105412483215, 0.8422495007514954, 0.8156205654144287, 0.8444595456123352, 0.8338316082954407, 0.8173420190811157, 0.8458870053291321, 0.8358598351478577, 0.8271747469902039, 0.8334869384765625, 0.8086544513702393, 0.81863853931427, 0.8115884065628052, 0.8192102313041687, 0.807061779499054, 0.9190835952758789, 0.9009594202041626, 0.913935124874115, 0.8816831946372986, 0.8841580510139465, 0.9150169014930725, 0.9032850384712219, 0.8892173528671264, 0.897011935710907, 0.8626053690910339, 0.8782237410545349, 0.8975682616233825, 0.8876373529434204, 0.8799039006233216, 0.9194700360298157, 0.9094362497329712, 0.9160961747169495, 0.9016184091567994, 0.8963096737861633, 0.9117108821868897, 0.9086545586585999, 0.9014232516288757, 0.9056648254394531, 0.8810619831085205, 0.8984422564506531, 0.9010691523551941, 0.9029903531074523, 0.8828272461891175, 0.894447124004364, 0.8816868662834167, 0.8937501668930053, 0.8946072101593018, 0.8810193657875061, 0.8906922221183777, 0.888830304145813, 0.8882901906967163, 0.8929769635200501, 0.86943039894104, 0.8808791279792786, 0.8738487839698792, 0.8795346975326538, 0.8607690572738648, 0.8316777944564819, 0.8191851615905762, 0.8299123167991638, 0.8336572527885437, 0.8247116684913636, 0.8292829871177674, 0.8208153367042541, 0.829660165309906, 0.8336248397827148, 0.8169056296348571, 0.8287531018257142, 0.8236969947814942, 0.8281584262847901, 0.8052320718765259, 0.8429614663124084, 0.8339118957519531, 0.8422357559204101, 0.8423724412918091, 0.828551423549652, 0.8474656701087951, 0.8427707314491272, 0.8321860074996948, 0.8413073420524597, 0.8126659393310547, 0.8316262125968933, 0.8248660445213318, 0.8251728296279908, 0.8060417294502258, 0.8593842387199402, 0.8462694644927978, 0.8569425702095032, 0.8450180172920227, 0.8355893135070801, 0.8591566801071167, 0.8519192814826966, 0.8422582149505615, 0.8468457221984863, 0.8239595174789429, 0.8398764252662658, 0.8346174120903015, 0.8386435985565186, 0.8244061708450318]\n",
            "X train:  (3674, 60)\n",
            "y train:  (3674, 7)\n",
            "X test:  (63, 60)\n",
            "y test:  (63, 7)\n",
            "Epoch 1/200\n",
            "115/115 [==============================] - 1s 2ms/step - loss: 0.0039\n",
            "Epoch 2/200\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.0044\n",
            "Epoch 3/200\n",
            "115/115 [==============================] - 0s 3ms/step - loss: 0.0052\n",
            "Epoch 00003: early stopping\n",
            "X train:  (3674, 60, 1)\n",
            "y train:  (3674, 7)\n",
            "X train:  (3674, 60, 1)\n",
            "y train:  (3674, 7)\n",
            "Model: \"sequential_353\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_160 (Conv1D)          (None, 56, 64)            384       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_89 (MaxPooling (None, 28, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_160 (Flatten)        (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_533 (Dense)            (None, 7)                 12551     \n",
            "=================================================================\n",
            "Total params: 12,935\n",
            "Trainable params: 12,935\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0038\n",
            "Epoch 2/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0084\n",
            "Epoch 3/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0046\n",
            "Epoch 4/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0038\n",
            "Epoch 5/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0029\n",
            "Epoch 6/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0029\n",
            "Epoch 7/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0025\n",
            "Epoch 8/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0024\n",
            "Epoch 9/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0021\n",
            "Epoch 10/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0022\n",
            "Epoch 11/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0019\n",
            "Epoch 12/200\n",
            "115/115 [==============================] - 1s 7ms/step - loss: 0.0020\n",
            "Epoch 13/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0019\n",
            "Epoch 14/200\n",
            "115/115 [==============================] - 1s 7ms/step - loss: 0.0019\n",
            "Epoch 15/200\n",
            "115/115 [==============================] - 1s 7ms/step - loss: 0.0019\n",
            "Epoch 16/200\n",
            "115/115 [==============================] - 1s 7ms/step - loss: 0.0020\n",
            "Epoch 17/200\n",
            "115/115 [==============================] - 1s 6ms/step - loss: 0.0020\n",
            "Epoch 00017: early stopping\n",
            "Model: \"sequential_354\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_178 (LSTM)              (None, 60, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_348 (Dropout)        (None, 60, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_179 (LSTM)              (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_349 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_534 (Dense)            (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 462,215\n",
            "Trainable params: 462,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "115/115 [==============================] - 45s 369ms/step - loss: 0.0113\n",
            "Epoch 2/200\n",
            "115/115 [==============================] - 43s 371ms/step - loss: 0.0077\n",
            "Epoch 3/200\n",
            "115/115 [==============================] - 43s 378ms/step - loss: 0.0075\n",
            "Epoch 4/200\n",
            "115/115 [==============================] - 43s 373ms/step - loss: 0.0053\n",
            "Epoch 5/200\n",
            "115/115 [==============================] - 43s 375ms/step - loss: 0.0051\n",
            "Epoch 6/200\n",
            "115/115 [==============================] - 43s 375ms/step - loss: 0.0049\n",
            "Epoch 7/200\n",
            "115/115 [==============================] - 42s 369ms/step - loss: 0.0045\n",
            "Epoch 8/200\n",
            "115/115 [==============================] - 42s 367ms/step - loss: 0.0048\n",
            "Epoch 9/200\n",
            "115/115 [==============================] - 43s 371ms/step - loss: 0.0040\n",
            "Epoch 10/200\n",
            " 86/115 [=====================>........] - ETA: 10s - loss: 0.0043"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OiTP8uUyT_X"
      },
      "source": [
        "def sb_window_transform(time_series, window_size):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(time_series) - window_size):\n",
        "        X.append(time_series[i:i + window_size])\n",
        "        y.append(time_series[i + window_size])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def preprocess(result):\n",
        "  values = []\n",
        "  for arr in result:\n",
        "    values.append(arr[0])\n",
        "  \n",
        "  return values\n",
        "\n",
        "def _test_structural_break(train_sc, test_sc, win_sz = 9):\n",
        "  ann_result = []\n",
        "  gru_result = []\n",
        "  lstm_result = []\n",
        "  cnn_result = []\n",
        "  pred_ANN = []\n",
        "  pred_LSTM = []\n",
        "  pred_GRU = []\n",
        "  pred_CNN = []\n",
        "  ann = []\n",
        "  gru = []\n",
        "  lstm = []\n",
        "  cnn = []\n",
        "  \n",
        "  for i in range(5):\n",
        "      # ''''''''ANN'''''''''''''''''''\n",
        "      X_train, y_train = sb_window_transform(train_sc, win_sz)\n",
        "      X_test, y_test = sb_window_transform(test_sc, win_sz)\n",
        "\n",
        "      model = make_ann_model(win_sz)\n",
        "      early_stop = EarlyStopping(monitor='loss', patience=2, verbose=1)\n",
        "      history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, callbacks=[early_stop],\n",
        "                          shuffle=False)\n",
        "\n",
        "      train_acc, test_acc = test_model(model, X_train, X_test, y_train, y_test)\n",
        "      y_pred_test_ANN = model.predict(X_test)\n",
        "\n",
        "      ann_result.append(test_acc)\n",
        "      # ''''''''ANN''''''''''''''''''''\n",
        "\n",
        "      # ''''''''CNN''''''''''''''''''''\n",
        "      model = make_cnn_model(win_sz)\n",
        "      early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
        "      history_model_cnn = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, shuffle=False,\n",
        "                                    callbacks=[early_stop])\n",
        "\n",
        "      train_acc, test_acc = test_model(model, X_train, X_test, y_train, y_test)\n",
        "      y_pred_test_CNN = model.predict(X_test)\n",
        "      cnn_result.append(test_acc)\n",
        "      # ''''''''CNN''''''''''''''''''''\n",
        "\n",
        "      X_tr_t = X_train.reshape(X_train.shape[0], win_sz, 1)\n",
        "      X_tst_t = X_test.reshape(X_test.shape[0], win_sz, 1)\n",
        "\n",
        "      # ''''''''''LSTM''''''''''''''''''\n",
        "      model = make_lstm_model(win_sz)\n",
        "      early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
        "      history_model_lstm = model.fit(X_tr_t, y_train, epochs=200, batch_size=32, verbose=1, shuffle=False,\n",
        "                                      callbacks=[early_stop])\n",
        "\n",
        "      train_acc, test_acc = test_model(model, X_tr_t, X_tst_t, y_train, y_test)\n",
        "      y_pred_test_LSTM = model.predict(X_tst_t)\n",
        "      lstm_result.append(test_acc)\n",
        "      # \"''''''''LSTM'''''''''''''''''''\n",
        "\n",
        "      # ''''''''GRU'''''''''''''''''''''\n",
        "      model = make_gru_model(win_sz)\n",
        "      early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
        "      history_model_gru = model.fit(X_tr_t, y_train, epochs=200, batch_size=32, verbose=1, shuffle=False,\n",
        "                                    callbacks=[early_stop])\n",
        "\n",
        "      train_acc, test_acc = test_model(model, X_tr_t, X_tst_t, y_train, y_test)\n",
        "      y_pred_test_GRU = model.predict(X_tst_t)\n",
        "      gru_result.append(test_acc)\n",
        "      # ''''''''GRU'''''''''''''''''''''\n",
        "\n",
        "      pred_ANN.append(y_pred_test_ANN)\n",
        "      pred_CNN.append(y_pred_test_CNN)\n",
        "      pred_LSTM.append(y_pred_test_LSTM)\n",
        "      pred_GRU.append(y_pred_test_GRU)\n",
        "  # update optimal window size param\n",
        "  ann.append([win_sz, min(ann_result), np.mean(ann_result), np.std(ann_result)])\n",
        "  gru.append([win_sz, min(gru_result), np.mean(gru_result), np.std(gru_result)])\n",
        "  lstm.append([win_sz, min(lstm_result), np.mean(lstm_result), np.std(lstm_result)])\n",
        "  cnn.append([win_sz, min(cnn_result), np.mean(cnn_result), np.std(cnn_result)])\n",
        "\n",
        "  plot_ann = [0] * len(pred_ANN[0])\n",
        "  for pred in pred_ANN:\n",
        "      plot_ann = list(map(add, plot_ann, pred))\n",
        "\n",
        "  for i in range(len(plot_ann)):\n",
        "      plot_ann[i] = plot_ann[i] / 5\n",
        "\n",
        "  plot_lstm = [0] * len(pred_LSTM[0])\n",
        "  for pred in pred_LSTM:\n",
        "      plot_lstm = list(map(add, plot_lstm, pred))\n",
        "\n",
        "  for i in range(len(plot_lstm)):\n",
        "      plot_lstm[i] = plot_lstm[i] / 5\n",
        "\n",
        "  plot_gru = [0] * len(pred_GRU[0])\n",
        "  for pred in pred_GRU:\n",
        "      plot_gru = list(map(add, plot_gru, pred))\n",
        "\n",
        "  for i in range(len(plot_gru)):\n",
        "      plot_gru[i] = plot_gru[i] / 5\n",
        "\n",
        "  plot_cnn = [0] * len(pred_CNN[0])\n",
        "  for pred in pred_CNN:\n",
        "      plot_cnn = list(map(add, plot_cnn, pred))\n",
        "\n",
        "  for i in range(len(plot_cnn)):\n",
        "      plot_cnn[i] = plot_cnn[i] / 5\n",
        "\n",
        "  # save prediction plots\n",
        "  plt.plot(y_test, '-', label='True Values', color='#1b9e77')\n",
        "  plt.plot(plot_ann, label='ANN Prediction', color='#d95f02')\n",
        "  plt.plot(plot_cnn, ':', label='CNN Prediction', color='#7570b3')\n",
        "  plt.plot(plot_lstm, label='LSTM Prediction', color='#e7298a')\n",
        "  plt.plot(plot_gru, label='GRU Prediction', color='#66a61e')\n",
        "  plt.title(\"Prediction\")\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Normalized Stock Prices')\n",
        "  plt.legend()\n",
        "\n",
        "  return preprocess(y_test), preprocess(plot_ann), preprocess(plot_cnn), preprocess(plot_lstm), preprocess(plot_gru)"
      ],
      "id": "2OiTP8uUyT_X",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsrZpF6z-7Kn"
      },
      "source": [
        "def dm_test(actual_lst, pred1_lst, pred2_lst, h = 1, crit=\"MSE\", power = 2):\n",
        "    # Routine for checking errors\n",
        "    def error_check():\n",
        "        rt = 0\n",
        "        msg = \"\"\n",
        "        # Check if h is an integer\n",
        "        if (not isinstance(h, int)):\n",
        "            rt = -1\n",
        "            msg = \"The type of the number of steps ahead (h) is not an integer.\"\n",
        "            return (rt,msg)\n",
        "        # Check the range of h\n",
        "        if (h < 1):\n",
        "            rt = -1\n",
        "            msg = \"The number of steps ahead (h) is not large enough.\"\n",
        "            return (rt,msg)\n",
        "        len_act = len(actual_lst)\n",
        "        len_p1  = len(pred1_lst)\n",
        "        len_p2  = len(pred2_lst)\n",
        "        # Check if lengths of actual values and predicted values are equal\n",
        "        if (len_act != len_p1 or len_p1 != len_p2 or len_act != len_p2):\n",
        "            rt = -1\n",
        "            msg = \"Lengths of actual_lst, pred1_lst and pred2_lst do not match.\"\n",
        "            return (rt,msg)\n",
        "        # Check range of h\n",
        "        if (h >= len_act):\n",
        "            rt = -1\n",
        "            msg = \"The number of steps ahead is too large.\"\n",
        "            return (rt,msg)\n",
        "        # Check if criterion supported\n",
        "        if (crit != \"MSE\" and crit != \"MAPE\" and crit != \"MAD\" and crit != \"poly\"):\n",
        "            rt = -1\n",
        "            msg = \"The criterion is not supported.\"\n",
        "            return (rt,msg)  \n",
        "        # Check if every value of the input lists are numerical values\n",
        "        from re import compile as re_compile\n",
        "        comp = re_compile(\"^\\d+?\\.\\d+?$\")  \n",
        "        def compiled_regex(s):\n",
        "            \"\"\" Returns True is string is a number. \"\"\"\n",
        "            if comp.match(s) is None:\n",
        "                return s.isdigit()\n",
        "            return True\n",
        "        for actual, pred1, pred2 in zip(actual_lst, pred1_lst, pred2_lst):\n",
        "            is_actual_ok = compiled_regex(str(abs(actual)))\n",
        "            is_pred1_ok = compiled_regex(str(abs(pred1)))\n",
        "            is_pred2_ok = compiled_regex(str(abs(pred2)))\n",
        "            if (not (is_actual_ok and is_pred1_ok and is_pred2_ok)):  \n",
        "                msg = \"An element in the actual_lst, pred1_lst or pred2_lst is not numeric.\"\n",
        "                rt = -1\n",
        "                return (rt,msg)\n",
        "        return (rt,msg)\n",
        "    \n",
        "    # Error check\n",
        "    error_code = error_check()\n",
        "    # Raise error if cannot pass error check\n",
        "    if (error_code[0] == -1):\n",
        "        raise SyntaxError(error_code[1])\n",
        "        return\n",
        "    # Import libraries\n",
        "    from scipy.stats import t\n",
        "    import collections\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    \n",
        "    # Initialise lists\n",
        "    e1_lst = []\n",
        "    e2_lst = []\n",
        "    d_lst  = []\n",
        "    \n",
        "    # convert every value of the lists into real values\n",
        "    actual_lst = pd.Series(actual_lst).apply(lambda x: float(x)).tolist()\n",
        "    pred1_lst = pd.Series(pred1_lst).apply(lambda x: float(x)).tolist()\n",
        "    pred2_lst = pd.Series(pred2_lst).apply(lambda x: float(x)).tolist()\n",
        "    \n",
        "    # Length of lists (as real numbers)\n",
        "    T = float(len(actual_lst))\n",
        "    \n",
        "    # construct d according to crit\n",
        "    if (crit == \"MSE\"):\n",
        "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
        "            e1_lst.append((actual - p1)**2)\n",
        "            e2_lst.append((actual - p2)**2)\n",
        "        for e1, e2 in zip(e1_lst, e2_lst):\n",
        "            d_lst.append(e1 - e2)\n",
        "    elif (crit == \"MAD\"):\n",
        "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
        "            e1_lst.append(abs(actual - p1))\n",
        "            e2_lst.append(abs(actual - p2))\n",
        "        for e1, e2 in zip(e1_lst, e2_lst):\n",
        "            d_lst.append(e1 - e2)\n",
        "    elif (crit == \"MAPE\"):\n",
        "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
        "            e1_lst.append(abs((actual - p1)/actual))\n",
        "            e2_lst.append(abs((actual - p2)/actual))\n",
        "        for e1, e2 in zip(e1_lst, e2_lst):\n",
        "            d_lst.append(e1 - e2)\n",
        "    elif (crit == \"poly\"):\n",
        "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
        "            e1_lst.append(((actual - p1))**(power))\n",
        "            e2_lst.append(((actual - p2))**(power))\n",
        "        for e1, e2 in zip(e1_lst, e2_lst):\n",
        "            d_lst.append(e1 - e2)    \n",
        "    \n",
        "    # Mean of d        \n",
        "    mean_d = pd.Series(d_lst).mean()\n",
        "    \n",
        "    # Find autocovariance and construct DM test statistics\n",
        "    def autocovariance(Xi, N, k, Xs):\n",
        "        autoCov = 0\n",
        "        T = float(N)\n",
        "        for i in np.arange(0, N-k):\n",
        "              autoCov += ((Xi[i+k])-Xs)*(Xi[i]-Xs)\n",
        "        return (1/(T))*autoCov\n",
        "    gamma = []\n",
        "    for lag in range(0,h):\n",
        "        gamma.append(autocovariance(d_lst,len(d_lst),lag,mean_d)) # 0, 1, 2\n",
        "    V_d = (gamma[0] + 2*sum(gamma[1:]))/T\n",
        "    DM_stat=V_d**(-0.5)*mean_d\n",
        "    harvey_adj=((T+1-2*h+h*(h-1)/T)/T)**(0.5)\n",
        "    DM_stat = harvey_adj*DM_stat\n",
        "    # Find p-value\n",
        "    p_value = 2*t.cdf(-abs(DM_stat), df = T - 1)\n",
        "    \n",
        "    # Construct named tuple for return\n",
        "    dm_return = collections.namedtuple('dm_return', 'DM p_value')\n",
        "    \n",
        "    rt = dm_return(DM = DM_stat, p_value = p_value)\n",
        "    \n",
        "    return rt"
      ],
      "id": "EsrZpF6z-7Kn",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAFZRDW7Gl7F"
      },
      "source": [
        "def test_structural_break(train_start, train_end, test_start, test_end):\n",
        "  stock_name = 'ACC'\n",
        "\n",
        "  data = pd.read_csv('drive/MyDrive/Findan/Sb_1/data/{}.csv'.format(stock_name), index_col=0)\n",
        "  print('data loaded for {}!!'.format(stock_name))\n",
        "\n",
        "  data.index = pd.to_datetime(data.index)\n",
        "  data_frame = data.copy()\n",
        "  df = data_frame[[\"Close\"]]\n",
        "\n",
        "  split_date = pd.Timestamp('01-01-2017')\n",
        "\n",
        "  train = df.loc[train_start:train_end]\n",
        "  test = df.loc[test_start:test_end]\n",
        "\n",
        "  sc = MinMaxScaler()\n",
        "  train_sc = sc.fit_transform(train)\n",
        "  test_sc = sc.transform(test)\n",
        "\n",
        "  actual, m1, m2, m3, m4 = _test_structural_break(train_sc, test_sc)\n",
        "  matrix = []\n",
        "  actual = actual\n",
        "  preds = [m1, m2, m3, m4]\n",
        "  model_names = ['mlp', 'cnn', 'lstm', 'gru']\n",
        "  for first in preds:\n",
        "    lst = []\n",
        "    for second in preds:\n",
        "      lst.append(dm_test(actual, first, second).p_value if first != second else 0)\n",
        "\n",
        "    matrix.append(lst)\n",
        "\n",
        "  df = pd.DataFrame(matrix, index = pd.Index(model_names), columns = pd.Index(model_names))\n",
        "  print(df)"
      ],
      "id": "xAFZRDW7Gl7F",
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hMNZxNkPV2hO",
        "outputId": "1185cd68-71c6-4a63-db94-378365cf72f5"
      },
      "source": [
        "test_structural_break(pd.Timestamp('01-01-2006'), pd.Timestamp('2006-05-01'), pd.Timestamp('2006-05-02'), pd.Timestamp('2006-07-02'))"
      ],
      "id": "hMNZxNkPV2hO",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data loaded for ACC!!\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1303\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.1081\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0875\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0685\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0515\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.0371\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0257\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0176\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0129\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0112\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0117\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0132\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 1s 4ms/step - loss: 0.1847\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1463\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1123\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0817\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0558\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0354\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0211\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0133\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0110\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0124\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0149\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0164\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0160\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0142\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 44ms/step - loss: 0.1991\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1731\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0799\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0168\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0236\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0296\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0197\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0136\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0080\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0057\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0079\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0099\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0093\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0075\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0085\n",
            "Epoch 00015: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 33ms/step - loss: 0.0927\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0624\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0356\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0273\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0199\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0249\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0332\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0177\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0167\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0260\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0161\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0218\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0198\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0141\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0132\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0145\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0126\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0127\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0116\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0135\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0166\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0159\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0090\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0115\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0094\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0161\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0058\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0070\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0085\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0088\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0074\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0074\n",
            "Epoch 00032: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2076\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1796\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1557\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1337\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1122\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0921\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0739\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0577\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0327\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0244\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0191\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0165\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0160\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0168\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0179\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1170\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0851\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0570\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0345\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0187\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0095\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0072\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0094\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0120\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0121\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0102\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0080\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 42ms/step - loss: 0.0969\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0929\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0748\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0235\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0323\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0284\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0165\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0213\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0214\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0097\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0087\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0118\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0081\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0073\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0126\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0092\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0137\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0089\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0084\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 33ms/step - loss: 0.0889\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0815\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0286\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0601\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0222\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0289\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0330\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0407\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0237\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0187\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0145\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0132\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0128\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0112\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0078\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0150\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0108\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0166\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0113\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0083\n",
            "Epoch 00020: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1314\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.1117\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0935\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0766\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0611\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0474\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0354\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0255\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0179\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0126\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0096\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0084\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0086\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0094\n",
            "Epoch 00014: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1264\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0916\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0630\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0399\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0233\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0130\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0083\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0079\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0097\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0118\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0125\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0116\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0100\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 39ms/step - loss: 0.2566\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.4959\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.2584\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0421\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0213\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0209\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0136\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0085\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0128\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0113\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0128\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0088\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0111\n",
            "Epoch 00013: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 31ms/step - loss: 0.0915\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0845\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0798\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0143\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0449\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0495\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0148\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0304\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0273\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1565\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1291\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1032\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0794\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0584\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0411\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0277\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0185\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0134\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0123\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0137\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0158\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1384\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1006\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0681\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0419\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0232\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0119\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0079\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0093\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0124\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0138\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0127\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0102\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 40ms/step - loss: 0.3325\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.5749\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.1597\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0208\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0310\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0210\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0105\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0124\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0098\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0136\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0091\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0080\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0118\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0098\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0089\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0126\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0098\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 3s 32ms/step - loss: 0.0523\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0376\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0868\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1058\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0269\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0787\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0414\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0254\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0269\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0146\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0160\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0088\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0154\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0165\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0101\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0103\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0114\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1699\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1517\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1338\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1160\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0985\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0818\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0661\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0519\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0394\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0293\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0218\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0170\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0147\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0145\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0156\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0171\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2867\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2463\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.2103\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1782\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1494\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1203\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0940\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0715\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0520\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0366\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0259\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0200\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0184\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0196\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0213\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0221\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0212\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0189\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 40ms/step - loss: 0.2990\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.7594\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0678\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1097\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0370\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0097\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0189\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0285\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0186\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0154\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0089\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0108\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0079\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0107\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0088\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0132\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0096\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0116\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 36ms/step - loss: 0.3562\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4549\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0710\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0995\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1648\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0497\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0271\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0216\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0332\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0200\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0221\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0181\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0215\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0228\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0181\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0143\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0113\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0146\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0106\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0178\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0137\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0089\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0107\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0120\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0115\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0115\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0111\n",
            "Epoch 00027: early stopping\n",
            "               mlp           cnn          lstm       gru\n",
            "mlp   0.000000e+00  7.172174e-03  1.400113e-08  0.000001\n",
            "cnn   7.172174e-03  0.000000e+00  9.290826e-07  0.000010\n",
            "lstm  1.400113e-08  9.290826e-07  0.000000e+00  0.002190\n",
            "gru   1.133184e-06  9.922261e-06  2.190074e-03  0.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b1SEsNwiWEi8",
        "outputId": "7808034a-378e-42be-a1fe-07d31f4fb7d3"
      },
      "source": [
        "test_structural_break(pd.Timestamp('01-11-2005'), pd.Timestamp('2006-01-01'), pd.Timestamp('2005-10-02'), pd.Timestamp('2006-02-02'))"
      ],
      "id": "b1SEsNwiWEi8",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data loaded for ACC!!\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1278\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0669\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0269\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0087\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0082\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0096\n",
            "Epoch 00007: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2374\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1139\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0534\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0185\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0089\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0120\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0119\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0093\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0071\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0056\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0047\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0039\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0031\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0025\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 48ms/step - loss: 0.0341\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0128\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0124\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0238\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0592\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0269\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0211\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0081\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0132\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0102\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0067\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0095\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0079\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0058\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0054\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0046\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0053\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0058\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0053\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0059\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0038\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0041\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0048\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0057\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0047\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0048\n",
            "Epoch 00026: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 37ms/step - loss: 0.0296\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0170\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0125\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0161\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0065\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0056\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0046\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0062\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0053\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0079\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.0179\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0349\n",
            "Epoch 00012: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 2ms/step - loss: 0.4215\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3044\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2172\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1507\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0984\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0576\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0295\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0152\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0120\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0133\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0139\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1744\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0906\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0388\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0127\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0088\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0114\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0090\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0072\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0060\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0047\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0042\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0038\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0034\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0031\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0027\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0026\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0025\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0025\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0025\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0025\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0025\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0025\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0024\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0022\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 00128: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 43ms/step - loss: 0.0770\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0903\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.1226\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0536\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0213\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0337\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0300\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0198\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0084\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0103\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0076\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0064\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0085\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0080\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0075\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0079\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0064\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0063\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0060\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0064\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0052\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0068\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0056\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0054\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0059\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0059\n",
            "Epoch 00026: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 35ms/step - loss: 0.0449\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0214\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0103\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0077\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0127\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0149\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0257\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0452\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0227\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3190\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2399\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1823\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1333\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0862\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0451\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0197\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0133\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0163\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0165\n",
            "Epoch 00010: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1364\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0555\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0156\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0100\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0081\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0053\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0033\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0026\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 00130: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 3s 49ms/step - loss: 0.0514\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0324\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0216\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0640\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0478\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0089\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0117\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0158\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0067\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0087\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0052\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0064\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0073\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0063\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0060\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0051\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0054\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0048\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0051\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0046\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0050\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0048\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0047\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0040\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0055\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0059\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0092\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0174\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0062\n",
            "Epoch 00029: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 38ms/step - loss: 0.0583\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0234\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0178\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0132\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0233\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0346\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0623\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0104\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0064\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0064\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0073\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0048\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0068\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0052\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0050\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0047\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0050\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0050\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0048\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0039\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0050\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0040\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0056\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0038\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0038\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0038\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0045\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0042\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0039\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0083\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0213\n",
            "Epoch 00031: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2172\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1629\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1188\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0788\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0444\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0208\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0117\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0131\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0151\n",
            "Epoch 00009: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2687\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1139\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0325\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0099\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0159\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0155\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0107\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0073\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0052\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0043\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0035\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0029\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0026\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0014\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.9626e-04\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 52ms/step - loss: 0.0592\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0938\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.1478\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0706\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0457\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0120\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0098\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0079\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0089\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0069\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0077\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0062\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0059\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0044\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0067\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0062\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0047\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0051\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0063\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 3s 42ms/step - loss: 0.0309\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0436\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0200\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0185\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0442\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0437\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0069\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0128\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0088\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0057\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0079\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0065\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0041\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0064\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0063\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0044\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0043\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0049\n",
            "Epoch 00018: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1743\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0778\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0237\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0094\n",
            "Epoch 00006: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1748\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0871\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0273\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0083\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0150\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0143\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0099\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0074\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0047\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0040\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0034\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0029\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0020\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0019\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0015\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0010\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.9911e-04\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0010\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 54ms/step - loss: 0.0304\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0628\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.1908\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0193\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0115\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0081\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0103\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0073\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0067\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0052\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0051\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0060\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0056\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0046\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0052\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0053\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0051\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0069\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0066\n",
            "Epoch 00019: early stopping\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 40ms/step - loss: 0.0422\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0135\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0119\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0165\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0076\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0127\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0304\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0535\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0134\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0074\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0069\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0049\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0061\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0060\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0049\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0040\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0060\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0059\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0053\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0077\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0098\n",
            "Epoch 00021: early stopping\n",
            "               mlp           cnn          lstm           gru\n",
            "mlp   0.000000e+00  1.940805e-10  6.636806e-09  1.061080e-12\n",
            "cnn   1.940805e-10  0.000000e+00  4.832938e-08  4.785318e-18\n",
            "lstm  6.636806e-09  4.832938e-08  0.000000e+00  7.839806e-17\n",
            "gru   1.061080e-12  4.785318e-18  7.839806e-17  0.000000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hVxdaH3zknvRfSOzUkIQkhFOm9qCBIk+uVJiqfiooXL2AFe1cEr1joKlVAQKT3TgIBAiGEkpBAEtJ7PWe+P05ySEilBAT2+zznIXv2zOy1k8Nee9as+Y2QUqKgoKCg8PCiutcGKCgoKCjcWxRHoKCgoPCQozgCBQUFhYccxREoKCgoPOQojkBBQUHhIUdxBAoKCgoPOYojUFC4SYQQC4UQH5b93EUIEX2L/cwVQrxzZ61TULh5FEeg8MAihIgVQhQIIXKFEMllD3CLO3kNKeVeKWWLetgyVgix74a2E6WUH9xJexQUbgXFESg86AyUUloAIUAo8HbFk0IIg3tilYLCPwjFESg8FEgprwB/AwFCCCmEeEkIEQPEAAghHhdCRAghMoUQB4QQgeVthRCthRDHhBA5QojlgEmFc92FEAkVjj2EEKuFEClCiDQhxBwhREtgLvBI2egks6yuPsRUdvycEOK8ECJdCLFOCOFa4ZwUQkwUQsSU2fi9EEI03G9M4WFCcQQKDwVCCA/gUeB4WdFgoD3gJ4RoDcwHXgDsgR+BdUIIYyGEEbAWWALYASuBoTVcQw1sAOIAb8ANWCaljAImAgellBZSSptq2vYEPgFGAC5lfSy7odrjQFsgsKxev5v+RSgoVIPiCBQedNaWvYHvA3YDH5eVfyKlTJdSFgDPAz9KKQ9LKTVSykVAEdCh7GMIfCulLJFSrgKO1nCtdoAr8IaUMk9KWSil3FdD3Rt5GpgvpTwmpSwCpqMbQXhXqPOplDJTSnkZ2AkE17NvBYVaUeKjCg86g6WU2yoWlEVU4isUeQFjhBCTKpQZoXuoS+CKrKzOGFfDtTyAOCll6S3Y6QocKz+QUuYKIdLQjSpiy4qTKtTPB+7oxLfCw4syIlB4WKn4YI8HPpJS2lT4mEkplwKJgNsN8XjPGvqMBzxrmICuS+b3KjqHBIAQwhxdmOpKXTeioHC7KI5AQQF+BiYKIdoLHeZCiMeEEJbAQaAUeEUIYSiEeBJdCKg6jqBzHJ+W9WEihOhUdi4ZcC+bc6iOpcA4IUSwEMIYXQjrsJQy9g7do4JCjSiOQOGhR0oZBjwHzAEygPPA2LJzxcCTZcfpwEhgdQ39aICBQFPgMpBQVh9gB3AaSBJCpFbTdhvwDvAHOmfSBHjqDtyegkKdCGVjGgUFBYWHG2VEoKCgoPCQozgCBQUFhYccxREoKCgoPOQojkBBQUHhIee+W1DWqFEj6e3tfa/NUFBQULivCA8PT5VSOlR37r5zBN7e3oSFhd1rMxQUFBTuK4QQNa2IV0JDCgoKCg87iiNQUFBQeMhRHIGCgoLCQ859N0dQHSUlJSQkJFBYWHivTVG4DUxMTHB3d8fQ0PBem6Kg8FDxQDiChIQELC0t8fb2RiibNt2XSClJS0sjISEBHx+fe22OgsJDxQMRGiosLMTe3l5xAvcxQgjs7e2VUZ2Cwj3ggXAEgOIEHgCUv6GCwr3hgXEECgoKCg8y30RsY+/VmAbpW3EEd4C0tDSCg4MJDg7G2dkZNzc3/XFxcfFt9z9z5kymT59eqSwiIoKWLVvW2GbGjBl8+eWXt31tBQWFe09uSRFfH9/O0eQa14TdFg/EZPG9xt7enoiICED3ALawsGDKlCn686WlpRgY3PqvetSoUfTv359PPvlEX7Zs2TJGjRp160YrKCjcN0SmXUEiCWrk3iD9KyOCBmLs2LFMnDiR9u3b89///rfKG3pAQACxsbEA/Prrr7Rr147g4GBeeOEFNBpNpb6aN2+Ora0thw8f1petWLGCUaNG8fPPP9O2bVuCgoIYOnQo+fn5VWzp3r27XpYjNTWVcq0mjUbDG2+8Qdu2bQkMDOTHH38EIDExka5duxIcHExAQAB79+69k78aBQWFm+REagJAgzmCB25E8N7h9ZxOv3pH+/S3c2Vm+4E33S4hIYEDBw6gVquZMWNGtXWioqJYvnw5+/fvx9DQkBdffJHffvuN0aNHV6o3atQoli1bRvv27Tl06BB2dnY0a9YMOzs7nnvuOQDefvtt5s2bx6RJk+pl37x587C2tubo0aMUFRXRqVMn+vbty+rVq+nXrx9vvfUWGo2mWueioKBw9ziRmoCbuQ2NTC0apP8HzhH8kxg+fDhqtbrWOtu3byc8PJy2bdsCUFBQgKOjY5V6I0eOpGPHjnz11VeVwkKRkZG8/fbbZGZmkpubS79+/ept35YtWzh58iSrVq0CICsri5iYGNq2bcv48eMpKSlh8ODBBAcH17tPBQWFO8+J1CsNNhqAB9AR3Mqbe0Nhbm6u/9nAwACtVqs/Ls+Xl1IyZsyYSvH/6vDw8MDHx4fdu3fzxx9/cPDgQUAXglq7di1BQUEsXLiQXbt2VWlb8doV8/SllMyePbta57Fnzx7++usvxo4dy+uvv15lhKKgoHB3yCjKJy4njVHN2zbYNRpsjkAIMV8IcU0IEVnDeV8hxEEhRJEQYkp1dR4kvL29OXbsGADHjh3j0qVLAPTq1YtVq1Zx7do1ANLT04mLqz4zYNSoUUyePJnGjRvj7q57O8jJycHFxYWSkhJ+++23Gq8dHh4OoH/7B+jXrx8//PADJSUlAJw7d468vDzi4uJwcnLiueeeY8KECXq7FRQU7j6nUq8AENyAI4KGnCxeCPSv5Xw68ArwUOQ4Dh06lPT0dPz9/ZkzZw7NmzcHwM/Pjw8//JC+ffsSGBhInz59SExMrLaP4cOHc/r06UrZQh988AHt27enU6dO+Pr6VttuypQp/PDDD7Ru3ZrU1FR9+YQJE/Dz8yMkJISAgABeeOEFSktL2bVrF0FBQbRu3Zrly5fz6quv3sHfhIKCws1QPlHcyt6twa4hpJQN17kQ3sAGKWVALXVmALlSyno5hNDQUHnjxjRRUVG15tQr3D8of0sFhco8u30x5zKvsXfo7QVOhBDhUsrQ6s4p6aMKCgoK/2BONvBEMdwnjkAI8bwQIkwIEZaSknKvzVFQUFC4K1zLzyExP4ugRg0XFoL7xBFIKX+SUoZKKUMdHKrde1lBQUHhgeNkWvlCMo8Gvc594QgUFBQUHkYiUhNQCUGAnWuDXqfB1hEIIZYC3YFGQogE4D3AEEBKOVcI4QyEAVaAVgjxGuAnpcxuKJsUFBQU7idOpCTQzNoRM0OjBr1OgzkCKWWtimhSyiSgYWdAFBQUFO5TpJScTEugt0f1aeF3EiU0dAdZu3YtQgjOnj2rL4uNjUUIwezZs/VlL7/8MgsXLgR0K4Pd3NwoKioCKovC3YhardYLwQ0fPvy2NIDGjh2rX1w2YcIEzpw5U2PdXbt2ceDAAf3x3LlzWbx48S1fW0FBoW6u5GWSVphHoH3Dvy8rjuAOsnTpUjp37szSpUsrlTs6OjJr1qwa9yZQq9XMnz+/zv5NTU2JiIggMjISIyMj5s6dW+l8aWnpLdn9yy+/4OfnV+P5Gx3BxIkTFckJBYUGpqEVRyuiOII7RG5uLvv27WPevHksW7as0jkHBwd69erFokWLqm372muv8c0339zUg7xLly6cP3+eXbt20aVLFwYNGoSfn1+N0tJSSl5++WVatGhB79699ZIWUFmmetOmTYSEhBAUFESvXr2IjY1l7ty5fPPNNwQHB7N3795KktoRERF06NCBwMBAhgwZQkZGhr7PqVOn0q5dO5o3b65IWSso3CQnUhMwVKlpaefS4Nd64ETnrv02maLLJ+5on8aeQTg+/U2tdf7880/69+9P8+bNsbe3Jzw8nDZt2ujPT506lQEDBjB+/PgqbT09PencuTNLlixh4MC6RfNKS0v5+++/6d9fp+Bx7NgxIiMj8fHx4aeffqpWWvr48eNER0dz5swZkpOT8fPzq2JLSkoKzz33HHv27MHHx4f09HTs7OyYOHFipc12tm/frm8zevRoZs+eTbdu3Xj33XeZOXMm3377rd7OI0eOsHHjRmbOnMm2bdvqvDcFBQUdJ1ITaGnrjLG64R/TyojgDrF06VKeeuopAJ566qkq4aHGjRvTvn17fv/992rbT58+nS+++KKSQumNFBQUEBwcTGhoKJ6enjz77LMAtGvXDh8fH0AnLb148WKCg4Np3749aWlpxMTEsGfPHkaNGoVarcbV1ZWePXtW6f/QoUN07dpV35ednV2t95yVlUVmZibdunUDYMyYMezZs0d//sknnwSgTZs2+k14FBQU4HJOOqO3LuCX0/tIL8yrcv585jVOpTX8iuJyHrgRQV1v7g1Beno6O3bs4NSpUwgh0Gg0CCH44osvKtV78803GTZsmP7BWZFmzZoRHBzMihUrarxO+RzBjVSUu65JWnrjxo03e1u3jbGxMaCbA7nV+QsFhQeR388dYUdCNDsSovko7G/6evrxmFcAp9KusiX+DBeyUhAI+nn53xV7lBHBHWDVqlU888wzxMXFERsbS3x8PD4+PlXi4r6+vvj5+bF+/fpq+3nrrbdue8P5mqSlu3btyvLly9FoNCQmJrJz584qbTt06MCePXv0Etnp6ekAWFpakpOTU6W+tbU1tra2+vtcsmRJtU5OQUHhOlJKNsZG0sW1KVueeJUxvh04kHiBF3cv5efTe3Ezt+GjDk9weMQ0urs1vys2PXAjgnvB0qVLmTp1aqWyoUOHVlv+1ltv0bp162r78ff3JyQk5Lb0/ydMmEBsbCwhISFIKXFwcGDt2rUMGTKEHTt24Ofnh6enJ4888kiVtg4ODvz00088+eSTaLVaHB0d2bp1KwMHDmTYsGH8+eefldJgARYtWsTEiRPJz8+ncePGLFiw4JZtV1B4GIjOTOZidirP+XfGz86FGe0HMj10ACdTE2hu44S1seldt6lBZagbAkWG+sFG+VsqPOh8fXwb30RsJ3zkmziaWd616yoy1AoKCgr/EP6KPUU7J6+76gTqQnEECgoKCneJi1kpRGcmM8Crxr267gmKI1BQUFC4S2yM023h/qjiCBQUFBQeTjbGRtLawQNXC5t7bUolFEegoKCgcBeIz0nnZNqVf9xoABRHoKCgoHBX0IeFvBVH8MCSlJTEU089RZMmTWjTpg2PPvoo586dU2SoFRQUAF1YyN/OBS9L+3ttShUUR3AHkFIyZMgQunfvzoULFwgPD+eTTz4hOTkZUGSoFRQedhLzsghPufyPDAuB4gjuCDt37sTQ0JCJEyfqy4KCgujSpQugyFArMtQKDztbLutG3I96t7rlPrTahlv8+0A6grlzDhB2JB4AjUbL3DkHOBam2+ShuFjD3DkHiDh+FYCCghLmzjnAqZOJAOTlFjN3zgHOROre5nOyC+u8XmRkZCXJ6eqYOnUqX375JRqNpsq5ijLU9aFchrpVK92X6tixY8yaNYtz584xb948vQz10aNH+fnnn7l06RJr1qzRy1AvXry40ht+OeUy1H/88QcnTpxg5cqVeHt7M3HiRCZPnkxERITeuZUzevRoPvvsM06ePEmrVq2YOXNmJTuPHDnCt99+W6lcQeFhY3vCWbwt7Wlm43hL7YuKSvl1YTjFRQ0j3thgjkAIMV8IcU0IEVnDeSGE+E4IcV4IcVIIEdJQtvwTUGSoY2vtS0HhQaWgtIT9iRfo6d7ilvswNjagT//mNNSYoCFF5xYCc4CaZhUHAM3KPu2BH8r+vW0mvtxR/7Narap0bGSkrnRsampY6djcwqjSsaWVSZ3X8/f310+81oYiQ62g8PBxMOkiRZpSet7kJvRSSjZtjMbW1pQOHb1wcbVqIAsbcEQgpdwDpNdS5QlgsdRxCLARQjT8nmwNQM+ePSkqKuKnn37Sl508eVKRoVZoUApLS9h7NeZem6FQBzsTojFRG9LByeem2mm1ksQr2SRezW4gy65zL+cI3ID4CscJZWVVEEI8L4QIE0KEpaSk3BXjbgYhBGvWrGHbtm00adIEf39/pk+fjrOzc5W6b731FgkJCdX2Uy5DfTtMmDABPz8/QkJCCAgI4IUXXqC0tJQhQ4bQrFkz/Pz8GD16dJ0y1EFBQYwcORKAgQMHsmbNGv1kcUUWLVrEG2+8QWBgIBEREbz77ru3Zb9C/fkwbCOjNs8jOiP5XpuiUANSSnYknKWzaxNMDAzr3Uaj0aJWqxg9vg2DhzZ8plGDylALIbyBDVLKKncihNgAfCql3Fd2vB2YKqUMu7FuRRQZ6gcb5W9ZPyJS4hm44X9IJN92Gc6wprUnKyjcGy5mpdB19Vd8/MhgRvt2qFebXdvPcy46lbET2mJkpL5jtvxTZaivAB4Vjt3LyhQUFGqhVKth2oE1OJpaYKI25HR64r02SaEGdiREA9DjJnYas7A0xsrKGAODyo9nbXYhDfXifi8dwTpgdFn2UAcgS0qpfKMVFOpgYdRBItOvMrP9QHxtnTmddvVem3RHSS/Mo0jzYCQX7EiIppm1Ix6WtWfgAZSU6FLLQ9t5MPLpYFQqoT+nScklbfgS8v5XNe37TlCnIxBCNBFCGJf93F0I8YoQok7pPCHEUuAg0EIIkSCEeFYIMVEIUb7qaiNwETgP/Ay8eMt3oaDwkHA1L4svjm2hu1tzHvNuhb+dC6fTExvsTfFucj7zGq/vXUnIso/495b5lGirrrm5n8grKeJQ0sV6pY2mpebx+Uc7uRynW5ApxHUnoM0sIGPCSrSpeRh1vrkJ5/pSn/TRP4BQIURT4CfgT+B34NHaGkkpR9VxXgIv1dNOBYX7nmv5OVgamWBaz0nD6njv8DpKpZaPHnkCIQT+9q78du4IV/OycPuHSRvXl8i0K3x3Yid/x53GWG1ALw9fNl8+w0dHNzKj/cB7bd4tsz/xAsVaTb0cQUmJFmdXS6ysK6era/OKyXjhD0pjM7CdOxSjINcGsbU+jkArpSwVQgwBZkspZwshjjeINQoKDzCPb5hDd7cWfN7pyVtqv/vKOf6OO820Nv30wmX+drqM69PpV+87R1Cq1fBNxHZmn9yJhaExkwK7M96vE41MLXj30Dp+ObOfwEbuPNmk9b029ZbYkRCNuYERbZ2866zr7GLJs89XXkYli0rJfHkNJWeSsPn2CYwf8WogS+s3R1AihBgFjAE2lJXd+iuNgsJDSHZxIVfzslhz8Ti5JUW31MfW+CjMDYx43v+6zIevrTMCwen0+2ueICE3g2F//8SsEzsY1iSEQ8On8d82/WhkagHAO+0eo72TD//dv/q+nAMpTxvt4toMI3Xt79vnzqZQUFBSuX2JhszX11N8+DLWHw3ApFezhjS3Xo5gHPAI8JGU8pIQwgeonyjOQ4SFhUWVsujoaLp3705wcDAtW7bk+eefZ/PmzQQHBxMcHIyFhQUtWrQgODiY0aNHs2vXLoQQ/PLLL/o+IiIiEEJUu9BsxowZuLm56aWp161bd8v2x8bGEhCgy/INCwvjlVdeqbX+xx9/XOm4Y8eONdRUAN2DD3RyAxsunbylPs5mJNHC1rnSg8Xc0BgfK3tOp90/eRYbYk/R989ZRGckMafbU3zdZThWRpVDIoYqNXN7/AsbY1Mm7FhCRmHePbL21ojOTOZqXhY9PWoPCxUUlLBoQRgb10fpy6SUZM/YQtHO81i+3QvTQf4NbW7djkBKeQaYChwrO74kpfysoQ17EHjllVf0Ym1RUVFMmjSJfv36ERERQUREBKGhofz2229ERETo9f0DAgIqyUwsXbqUoKCgGq9R3v/KlSsZP358Fa2iW5F2CA0N5bvvvqu1zo2OoDoRO4XrxOfoVmmbGhiyPKbWpTLVIqXkbEYyvrZVFyn627ly5j5JIQ1LjmPizt9oau3I5ideZXDj4BrrOpha8nPPZ0jOz+a9IxtqrPdPZGVMOAA93Gp3BKamhrz0Skd69G6qL8v9di8FayIxf7Ej5v+6OxJs9ckaGghEAJvKjoOFELf+6vkQkZiYiLu7u/64XC20Nry8vCgsLCQ5OVmnNbJpEwMGDKizXcuWLTEwMCA1NZXu3bvz2muvERoayqxZswgPD6dbt260adOGfv36kZioe2iEh4cTFBREUFAQ33//vb6vXbt28fjjjwOQm5vLuHHjaNWqFYGBgfzxxx9MmzZNL4D39NNPA9dHRFJK3njjDQICAmjVqhXLly/X99m9e3eGDRuGr68vTz/99AOR6VJf4stGBGN8H+HotTguZN3cCvlrBTlkFuXja+tU5Zy/vQuXc9PJKiq4I7Y2FFJKPjj6F06mlizrNwHPeqRUtnbwYEiTYHYmRKOVNQsy/pP4NfowP57ey/CmIbiYW9dZ39XNGjs7MwDyloST9/NhTIcHYvHS3Rtl12eyeAbQDtgFIKWMEEI0bkCbbovsT3ZQcvZa3RVvAkNfR6ymV1XrrIvJkyfTs2dPOnbsSN++fRk3bhw2NnVP6A0bNoyVK1fSunVrQkJC9OJttXH48GFUKhUODg4AFBcXExYWRklJCd26dePPP//EwcGB5cuX89ZbbzF//nzGjRvHnDlz6Nq1K2+88Ua1/X7wwQdYW1tz6tQpADIyMhg6dChz5sypVgBv9erVREREcOLECVJTU2nbti1du3YF4Pjx45w+fRpXV1c6derE/v376dy5c5339iCQkJuBmYERz/l35ufT+1gRE8700P71bn82IwmAFtWMCPzsdJkkURmJdHD+x/7XZGNcJOEpl/m805OYGRrVu117Jx+Wx4QTk5lCi2oc4T+JDZdOMv3AWnq5+/J5p6G11t298wLZ2UU8NrAlKpWgYGMUOZ/uwLh3M6ze7VMphbShqddksZQy64ay+8M132PGjRtHVFQUw4cPZ9euXXTo0EG/JWVtjBgxgpUrV7J06VJGjao1C1e/YcyUKVNYvny5/stTrhMUHR1NZGQkffr0ITg4mA8//JCEhAQyMzPJzMzUP6SfeeaZavvftm0bL710PcvX1ta2Vnv27dunl7t2cnKiW7duHD16FNDJZbu7u6NSqQgODn6opKnjczPwsLDFycyKnu4tWHU+nNKbyJMvdwQtqw0NlWcOVQ4PlWg1fHdiB9fyqwoG3m1KtBo+CdtECxsnRtykHEZ7Z13u/OHkS7d07YyifL6N2E5haUndlW+D3VfOMWnPcto6eTG3x78wVNUuD5GVWUh6Wh4qlaA4PIGsaRsxDHHH5ovHEeq7u9a3PiOC00KIfwFqIUQz4BXgHxsQvpU394bE1dWV8ePHM378eAICAuq1iY2zszOGhoZs3bqVWbNm1Rp/nzx5MlOmTKlSXi5NLaXE39+fgwcPVjqfmZl5C3dze1Qc2Txs0tTxuRm4W+ic6IhmbdgaH8XuKzH0qqc08dmMJBxNLbEzMa9yztHUkkYmFpy5IXNo7YXjfH5sC3klxTc1+mgIfj17mNicNBb1HotBHQ/IG/G0sMPJzIrDSZcY7duBrZvOceliOs+Ma4Opad0JjH+cP8aXx7dibWTKOL+GCbccS7nMhB1LaGbjyIJeYzA1qHvEM2iIP1qtRJOUQ+Zrf6J2s8Z2zhCEcUPuDlA99XE7kwB/oAjdQrIs4LWGNOpBYdOmTXo56KSkJNLS0nBzq1ZgtQrvv/8+n332GWr17YlOtWjRgpSUFL0jKCkp4fTp09jY2GBjY8O+ffsA+O2336pt36dPn0rzB+VbURoaGurvrSJdunTRy12npKSwZ88e2rVrd1v38CCQkJuBh6XOEfRy98XexJxlMUfr3b6miWLQrUL1t3OplDlUWFDC1uXncc22ZUPsyXs6H5NdXMg3Edvp6Nz4ljZnyc4qpEt6C8KuxCGlxN3TGhNTA0xMdA/Ma8m5tW7jeChJN5L4IXI3xfWUrtgef1Y/CquLgtISJu1ehoOJJb/2GY+1sWmt9VNT8ki5lguAKNGQ+eqfyIISbGcPRmVd9/4nDUF9sobypZRvSSnbln3ellLWvX/jQ0Z+fj7u7u76z9dff82WLVsICAggKCiIfv368cUXX1QrTV0dHTt2ZPDgwbdtl5GREatWrWLq1KkEBQURHBysH2EsWLCAl156ieDg4BofFG+//TYZGRn6+yjfx+D5558nMDBQP1lczpAhQwgMDCQoKIiePXvy+eef1/ueH1SyigrILi7Eo2xEYKQ2YGiT1myLP0taYW6d7TVaLecyk6udKC7Hz86Vc5nJ+gfdwWsXKS3Q4m/mSlx2Oqu3naSw8N6MwP53ahfpRXm83fbRW4p7X72SjclFY0hRcTk3nZZ+ToweF4oQgqKiUv733X4W/Hyk2rZaqeVQ8iW8Le25mpfF6gt1r4WNz0lnzLaF9P1zFm8dXEt6Hamrc07uJC4nnS86D8XRzLLO/tf/eYa5cw5SUlJK9gfbKDmViPWnj2LQtFGdbRsMKWWtH2ArYFPh2BbYXFe7hvq0adNG3siZM2eqlCncnzyIf8vI1CvSbf5UueHSSX1ZVHqidJs/Vf4cubfO9hcyr0m3+VPl8nNHa6yz5sJx6TZ/qtx54pwsKSmV/9o8T7b+/UOZlJclA//3gXxj8nq5e+eFO3I/N0NyXrZsvOgt+dKupTfdVqvV6n+OTL5S7e9Ao9HKUyeuytycomr7OJOm+z2vOBcm+62dJTuv+kKWajS1Xvfb49uk2/yp8vW9K6XngunS79f35C+n98liTWmVuuczr0nvhW/KSbuX1fu+srMK5LnoFJn3+zGZ2PJzmT2r7u/AnQAIkzU8V+sTGmokpdQHlKWUGcCt7cCsoPAQUp46Wj4iAN2K4EB7N9ZePFFn+6haMobK8bdzxbTYiL8XRbNifQS7r5xjrN8jOJlZEdjEjWMBF+jUxRvQhSbKlS4bmgNJFyjSlPJChdXQ9aGwsIQfZh/gzGndpjstHZyxMTarMmGsUgkCAl0wt9DF5DWaynksh5IuAtDB2YeXg3pwKTuVv2JP1XhdKSWrLhyno3Njvuo8jC1PvEpgI3feO7yeoRt/JDk/u1LdNw+uxczAkHfa1iq9Vsk2SysTPNHL17gAACAASURBVFNzyf5kB8bdGmPxcqd6/EYalvo4Aq0QwrP8QAjhBQ22h7KCwgNHfK5uMVlFRwDQ19OPE6kJpBTUntVzNiMJgaC5TdX3r5ISDRfOp9HYqhHSVGLYFsJtLmJqYMgzLXTaNYN8AjkrEjmRnoBGo+XLT3exY+t5fR8NGTI6lXoFY7UBvnY3Fx7UlEqkRC/FrBIq2jt5czgpttr6Wq1k4byjrFtzulL5oeRLuJnb4GFpx6Ne/jS1dmD2yZ01hkLDr13mUnYqw5rqFnK1sHXi977P8n23UURlJPLo+jkcT9FtrLjmYgT7Ey8wrU1/HEzrDgmtXnmKXxeFU3QojoyX1mDQxB7rzx5DqO5emmhN1McRvAXsE0IsEUL8CuwBpjesWQoKDw7xORlYGBpjY2xWqbyPR0skUr95SU2czUjC28q+2kyUjeujmPfTYQrySvC1deagcQyrL0cwomkotmUZRn09/TBSqVl/STdpPGJUEK2CdA/mLZui+ebz3ZSWNswI4VTaFXxtnetMpSynPFRhbmHE/03qiG/L686vvZMPsTlpJOVX3cNXpRI4O1vSyMG8Ul+Hky7RoSz9VCVUvBzYnaiMJLbFR1XpA2DVhWOYGhjyqPf1xZ9CCJ5oHMSfj72IkUrNsL9/ZFHUQT44+hfBjTx4ukXdyRBSShwczPHJLSLzpTUYeNhgN28EKqt7Mzl8I/WZLN4EhADLgWVAGynl5oY2TEHhQSGhLHX0xolSPzsXXMys2Xq5+odSObqMoeonirv1aML459phYWmMv50L0ZnJlGq1TPC/Hm6wNjalm1tzNlw6hfZKFoGO5riUPTAbN7EnJNQdrebOD/KllESmXyXQvn6ZcgC7d15kxdITlJZqK23MAtfXExxJvIisJrTV/zFfunS7vqDufFYKqYW5PFJhkd0TjYPxsLDlu2pGBYWlJay/dIIBXgFYGFZdxOln58JfA18mxMGTtw79SVphHp92HIxKVP8Y1Wole3ZdJOxIPEIIOtqZ0nT+EVQultjOH4HKzqzadveCGhNWhRC+UsqzQohysYvyJGVPIYSnlPJYw5unoHD/U76Y7EaEEPT28OWPC8cp0pRiXI1KZUFpMbHZaQxuXFlvKj09H0tLY2xsTbGx1aUr+tvrVhj39/LDx+p6Boos1jDusiP5S6+QPnOevlxlb4atqxVdx7bFqAFy12Nz0sguLiTgJhyBplRLaakWtbpquMTfzoVOV0xp/H+7SU7YirA1Re1gjsrBAgMfO0yfbIWhryPnzqagUgsOacrnB647AkOVmhdbdWP6wbWsuRhRSeJ6a3wUWcWFDG9as76PnYk5v/d7lm8jtmNvYl7tveXkFGFpaYxKJTgTmYS1tQkB6flkvbMJlZMFdgtGom5UdT3IvaS2v/7rwPPAV9Wck8A/a+WWgsI/ECkl8bkZNUo/9PZoyZLowxxMukj3G/a1PXQgjsMRcaiMRaU1BFJKflt0DJVK8NKr19/8Ozr50DXJgv+Y+pC/8gQyrxhNci6FG87QPC2fBBsVB0Y40D+wDdrEbDRJOZREXCVr6l+kADnuNvi3unOpvpFl8tE3MyLo1bcZWq2sMnrSXMki98vdzNpsRopNMeYvdECbWYD2Wh7a1FzyV5wg/9djGAS5EGluQlawK0cDYnE2s8LrBk2jkc1C2RFxjGm7V+FmbqMfaaw6fwxnMys6Ojep1UZZCq8H9UatVpGfV0xKSh4uLpYYGRuwdfM5du+8wLsz+2BkbMC/W7tS9N0+Mk8lYtDCAdu5Q1E7VFUqvtfU6AiklM8LIVTA21LK/XfRpvuS5ORkJk+ezKFDh7C1tcXIyIj//ve/DBkyhF27dvHEE0/g4+NDYWEhjz/+uF5WesaMGVhYWFRaHezt7U1YWBiNGlXOK/b29sbS0hIhBM7OzixevPiWc/QrXvfdd9+la9eu9O7du9q6ERERXL16lUcf1WVGrFu3jjNnzjBt2rRbuvbDRGZxAbklRXhaVi/N0dGlCSZqQ7bFR1VxBG7u1iSvz8HQR13JEQghGPC4L8XFlcMjTguj+XqJMXAQfRRdJTDu1hizp1rzTuFejqXF88Tg0ahVunCGNrOAtJFL0Lyzmb0D/fELcLpjGjcnU69gqFLXqQ9UWqpl5bITdOvRBFc3qyohobwl4eR8sweAyGEuvOAeSdiYNthWmHPRZhZQsO40+StO0PFEIuLkFQyaFNC0qytoJBgItFmFFPx1hoLVkXxyJg+NyobEeStIaOmJYRN7MksvMrT/I/rfDUBubhEnIxJpFeiMpZUJZ04ns/CXo7zyemfcPWy4eCGNxQvCeW1KV1zdrPBt6YipkZri8ATyloRTtPsiKmdLrD7sj+kT/nddOqK+1DoelFJqhRBzgPtzi6C7hJSSwYMHM2bMGH7//XcA4uLiKu0P0KVLFzZs2EBBQQGtW7dmyJAhdOp082ljO3fupFGjRrz55pt8/PHHleSi9TnBqpv7sr3//vu1no+IiCAsLEzvCAYNGsSgQYNu2vaHkYQcXeqoezWhIdDJUnd1bcq2+Cg+aD+IvbsvcS05l2EjA/HwtMH4CYk8J/Eu25GsnKbNKr8k5K88oVOtHNoK87FtEeZGuo+Zof7h8/jFbP5OOMPRa7H6EYrKxhSb2UPQPPUrw6KSoEQLRre3mr2cyHTdRHFdG7NkZhRw8XwaLf2dcHWzqnxfyyLI+WQHxt2bYPV2byxUqRT9HcnR5Fj6evrp66lsTDEfHYrZM20oCUvg2vKjPLItBosTKVz77X8YBbhQdCgOijXku1gRGehCSBsnLh4Op/R8Au5Hr/BjiSWavXFEP7IFq2GtcPZzIic2g/0LwrDp7EVjNyscsgoZ6WyO6f5YCm1NcTcx4LkBzbFRSYpPJmL9dxTNN0WTm5yLsDTG4j9dMX86BGFy+3t5afIyUBlbIG5jq9OaqE9gcLsQYiiwWtaUc1UDQoj+wCxADfwipfz0hvNewHzAAUgH/i2lTLiZa/wT2LFjB0ZGRkycOFFf5uXlxaRJk6rUNTU1JTg4mCtXrtzWNbt27cp3331HbGws/fr1o3379oSHh7Nx40ZWrFjBihUrKCoqYsiQIcycOROAjz76iEWLFuHo6IiHh4de82js2LE8/vjjDBs2jKNHj/Lqq6+Sl5eHsbExW7du5d1336WgoIB9+/Yxffp0CgoKCAsLY86cOcTGxjJ+/HhSU1NxcHBgwYIFeHp6MnbsWKysrAgLCyMpKYnPP/+cYcOG3dY9349Ut4bgRnq6+7IlPoqzGckUFJSQn19MaakWAwMV0VnJNLdyYs3KSHwa26FWC9LS8uneswnqsgd80f5LZL+/FaPO3li91xdhUP2LQG8PXwxVanYmnKscN2/ugPVHA8j6z3qyP96OxTu99X3fKlJKTqZe4THvuqXXGzmY88b07lXmKQo3R5P9wVaMuzfB5rvBCAMVwaWmGKnUHE66VMkRlCOEwKitB7utElnQKJYRJ515zMII1YU0zIYFYvpkK9QO5lhHJuPWvTEtUn354euDZBpmE6DKZWKMFeqVJ5CrTpAsBEIreQbg4CXKF1O5ASWgP7aE6yMwQzXGXXwwecMX425NUJnXX2W1NvKjdpL081isOo+l0ZMz70ifFamPI3gB3XxBqRCiEBDo9p63qq2REEINfA/0ARKAo0KIdVK30U05XwKLpZSLhBA9gU+A6mUw68ny8JkkZJ6pu+JN4G7jx8g279V4/vTp04SE1G8DiYyMDGJiYvSqn7fKhg0b9PsbxMTEsGjRIjp06MCWLVuIiYnhyJEjSCkZNGgQe/bswdzcnGXLlhEREUFpaSkhISFVxO+Ki4sZOXIky5cvp23btmRnZ2NmZsb777+vf/ADLFy4UN9m0qRJjBkzhjFjxjB//nxeeeUV1q5dC+j2Y9i3bx9nz55l0KBBD6kj0K0hqGlEcC05lytr8nCwtGJ7QhQv9uuOEOjDM2czkujm0oz00/lYWRuTl1tMQnwWPcs2Mik5l0Lma+swaNoIm68H1egEQLebWQsbJyLTqr6EmA7wpfBUIgULw4jPKsTvvT6obGrXzKn9vjPIKi6glX3Nm60XFpZwMiKR0HYeVZxA0aE4Mv/7F4at3bD5aqD+vkwMDGnt4MHOK9G8qR1QKYxTkUNJF0n3KqDXsL64NW3E2ahrXI7LoK+fEw5Atx66OH2AnRvtO3ry88V9DB7QjUbN25Jy7AomB2JBK3WT0Y3MUdmbIcyNQKVCqAWoVMiiErTpBWgz8tGmF6CyNMK4R9M7mhKqLSkibfW7ZGz6CkOnZli0HnjH+q5InY5ASln3SonqaQecl1JeBBBCLAOeACo+pf3QORmAncDaW7zWP4qXXnqJffv2YWRkpJdg3rt3L0FBQcTExPDaa6/pY/s1xWNrKu/RowdqtZrAwEA+/PBDMjMz8fLyokOHDgBs2bKFLVu20Lq1LpqXm5tLTEwMOTk5DBkyBDMzXVy1utBOdHQ0Li4utG3bFgArq1p9PQAHDx5k9erVgE7K+r///a/+3ODBg1GpVPj5+ZGcnFxnX3eTVefDUQlVg2+MHp+bgaWhMdZG1T9UbWxNsbU2pam5A1svR/FyYA/9ufTCPK4V5OBr78yzL7TTv6UXF5UihECTnEPGxD8Q5kbY/jAUlUXd+1YE2Luy5XIUUladkLX5TzciD13GYXM013acx6RPM0yHBmLU3vOmFz2dKnM2rWqZKA47ksD6tafx8LTBxfX6d63kTDKZk9Zi4GWL7fdPIm5QGH3GtwMv717GwrMHedavanhVSsmhpEt0cPGhSZl+T3TUNS5dTKd7z6YYVQh9qdUqxg3swPCS1vqUUYcQNwip/wR3Q1F05QxJPz5D0eUIrLs/j8OoL1EZN0y2UW3po83QvbE3AU4Cb0gpbyae4QbEVzhOANrfUOcE8CS68NEQwFIIYS+lTLvBlufRZTDh6elJbdT25t5Q+Pv788cff+iPv//+e1JTUwkNDdWXlc8RXLp0iQ4dOjBixAiCg4Oxt7fX7xhWTk5OTo0b2JTPEZSTmZmpl5wG3X+C6dOn88ILL1Rq9+23397WPd4KFWWnbzKq2KD8cnofM45swNHUkiGNgxt0AxCd6qhdlWsUFZWiVguMjNQ8/+Ij5B7P45uI7aQV5mJvontbLVe/9LV1rhSqMTI2QJOaR/qzK5DZhdgtHoXauX7va63s3VgWE0ZiXhauFpW/Y0KtIvHbthRcLsB3dyYF609TuPEsBi0csP7sMQybO9T7vk+lXcFAqGpUTAXo1MUbT6+qTiD9uZUIKxNsfx5WrRrnEz5BrDp/jM/CN9Pf0x+3G+7jcm46iflZlcJfjz/hh0YjKzmBilS3buBeknN0FUk/j0VlbI7rq2uwaN2wc3K1BQLnAxuAocBxYHYDXH8K0E0IcRzoBlwBqqwUkVL+JKUMlVKGlu/A9U+iZ8+eFBYW8sMPP+jL8vPzq63r4+PDtGnT+Owz3bbPXbt2Zd26deTk6GQGVq9eTVBQ0C3LT/fr14/58+eTm6tTtbxy5QrXrl2ja9eurF27loKCAnJycli/fn2Vti1atCAxMVE/isnJyaG0tBRLS0u9fTfSsWNHli1bBuikrLt0uTlNmbvNr2cPM+PIBpxMLblWkMPlstBNQxGfU/0aggN7Y/ng3W3k5xcDuvi9RLIjXrfKOL+kWC+ffKPGkDYjn4xnV6BNzMF27jAM/eq/a1d53vupasJDUkqmH1jD5KQdXBjgy/FpvbD+eADa1DzShi8hb/4RpKZ+e1KdSrtKc1snTKqZ2CwuKiU/rxghBJ5e1383xccSSB+7DGFiiN28EaidqnduQgg+eWQwEsn0g2sqvWRIKVkcdQhAv6IYdG/+NTmBfxJSStLWfUTi9yMx9gzG64OIBncCUHtoyFJK+XPZz18IIW52AdkVwKPCsXtZmR4p5VV0IwKEEBbA0IoCd/cLQgjWrl3L5MmT+fzzz3FwcMDc3Fz/sL+RiRMn8uWXXxIbG0tgYCAvv/wynTt3RgiBo6Mjv/zyyy3b0rdvX6KionjkkUcA3V7Cv/76KyEhIYwcOZKgoCAcHR314Z+KGBkZsXz5ciZNmkRBQQGmpqZs27aNHj168OmnnxIcHMz06ZXVRWbPns24ceP44osv9JPF/1RWxoQz7eAaern78nrr3jy2fg5Hk+PwuiEj504hpSQhN4POrk2rnPNpYodGq8XMTDeZ2MreDSczKz44upGPw/8mpUDnyB1NLXGqoGOjzSokfcJKSuMysP1hKEah7lX6rg0/O2dUQnAq/Sr9vPwrnYvNSSO5TPfo+NkEClJK6f1SBxp1bUzWe5vJ+XI3hbsvYvPxANRuNe/FK6XkVOoV+ni2rPb833+d5eSJRN6Y3h2Tsmyaov2XyHzlT92Cq3kjULvUHpb0sLRjakg/ZhzZwLpLJ3micRAFpSW8sf8P1l6MYGiT1jSzvr+0MbXFhSTPn0DOoaVYPvIvnMb9jMroLklQ1CRLCpxFlzYaUvaJqnhcU7sK7Q2Ai4APYIQuDOR/Q51GgKrs54+A9+vqV5GhfrBpqL/l+osnpMeCaXLUpl9kQUmxLNVopO+Sd+W0/asb5HpSSplWkFtvqWkppVx45oAcvvFH+Z+9K+V3ETvk2gsRMi47TUoppbawRBafTZapI5bIxFZfysLdty4p3XP113LM1gVVypedOyrd5k+VbvOnyg8O/iVLS6/LNWu1Wpm3+pRMCv1WJoV8I3PnHZba4qqyzFJKeSUnQ7rNnyoXnDlQ/fmETLln13X7C7ZGy8TAr2TK4AWyNDW33vdRqtHIR9fNlkG/fyDPpifJx9bNkW7zp8rZJ3ZUkrC+H8iPOSjj3u8oo8eoZOq6jxvEfmqRoa5tRJAIfF3hOKnCcZ0ri6WUpUKIl4HN6NJH50spTwsh3i8zaB3QHfhECCHRidm9VGOHCgq3wWfHtuBv58q8Xs/owxUhDp4cvRbXYNcsTx29MWMo9mJ6JWmIcp5Kd+bJqBJkcSmyqASKrqLNOE/KxXQ0V7JAK8FAhc03gzDueuub1AfYu7Iv8UKV8iPJl7AxNiPI3o2/4k/xVvsBFBeVsmXzOfz8nWg8JACjdh7kfLiNnC93U7D2NEbTuxHpLenocn017sk6Jopd3axxdbNGaiV5Px0id/Y+DINcdRPeN7FDl1ql4otOTzJg3Rz6/PktJmpDfun5DP1vGOnUB6nVIG5yC83bRWo15IavIWPztxSeP4jKzAaXl5Zj2fbuZ9fVtrK4R03n6ouUciOw8Yaydyv8vApYdbvXUVCojRKthss56bwc2L2SgmeokxdfH99OVlFBndsL3khGoW5yd0iT1rR28Ki2TrkjqLiqWErJ8qUR2Nqa8fyLukwvbU4ROZ/soGBtJBioECYGun1rjQxQWRlj6O+EyeMtMWhij2GAMwaeNa9JqA8B9q78ceE41/JzKu2odTgplnaOXvTz8uc/+1ZxIjUBi0xTIk8k0biJLnwmHSywmDUY032XyP54O/nP/kGMbxFxY9swatAAQDf/oBICvxukp69dyyX8SDzdejbBpFRL1rSNFO26gMnjLbGa0ReV2c3n3PvZufJGSB9WXzjOnG5P4WdXc7pqRaRWQ+HFo+RHbiEvciuFFw9j0rg9Nr1fxDJ0KKIeew7fDrnH15Py+2RKUi5h6NAYh6dnYd1lLCqTmuUnMvOTMTe2xlB958NFd3+X5AZCVpMOp3B/IRsosyghNwON1FZZndvW0RuJ5HhqfBV5h7r436k9zI86wPyoAwxpHMy0Nv2rZK+Uryp2M7/+4BZCMP75dhQX6XIiivZfIuudzWhTcjF/oQMW/9cR0cCTmuUTxpHXYglNPIXa0oFcn/bE5qTx7xbt6efpxzSVmvWxp3in7aO88WZ3/f+tgwfiOHwwjlde70LR0iEsmTaXUWEmmE6LJHpRPJ7PduG0KoFm1o5VZLMvxKSyf18sHV0tyZu+EU1iDpZv98JsVOvb+r/7cmCPSmm3tSGlJHvPfFJXvYkmJxWEwNg7FJteL5J38m+S5v6bFKv/YN39OWx6v4SB1Z2dZ9DkZZLy+2Sy9y/GyL0VLi+vxCLkiTpHI8fiN/Lrkel0bDycYa3fvqM2wQPiCExMTEhLS8Pe3l5xBvcpUkrS0tIwMbnzbzux2bpsZG+ryo4g2MEDlRAcTY69KUeQXVzIr9GH6OvREl9bZ348vZeNcZG84N+FlwN7YGaoewDG56ZjbWRSZbThUCY6lvPNHvJ+Poy6sR12vz2NUaDL7dxmvfGzcaZX8hnsvu5PUrYuRbXIsRl9bJvSrtEEbIzN6OrajA2XTvJ26IBKqauNGpkT0MoZlUrwfcx+VnQt4ukPJrB2zhra7Eona8oGplhKwgbZIwdqKy1w6xDiRovDcRQ8uxKVjQl2i5/CKPju5euXpCeQvOB58k9txrR5F2z+/X+Y+fdGbVE22hn1NfmRW8jc/j3p6z8ic8ss7Aa+iU2fV+7IpG1e5BaS5z9HaWYidgPfwv6Jt+sceRSW5LI8fAYHLq3Eyy6QLk3+ddt2VMcD4Qjc3d1JSEggJSXlXpuicBuYmJjg7n5zWTD1oSZHYGFojJ+tC2E3OU/wa/RhckqKeC24F4GN3Hm6RXs+Dd/Edyd3su7SSb7tMoJQJy/iy/YhKEerlWxcH0Wbtu7YXUjTaQMNCcDqnd53RIvmRoqTYsjetwiQqMxsUZlZI1RqMrbO5q34k1yz9aDpa3+iyUklevUMpkf/jfrzk2Q9OZOBPoFsTzjL8dR4Qhyur93xC3DCL8CJq3lZrIgJY2SzULxcXXlm5gT+9fcvmIddY/RBY/r/lk7qwQVYTu6Kcc+m5K4/Q8G3e9Em5WDyWEssp/VAbd/wUsyytBhNTip5pzaRsnQKUlOCw9OzsOn1IuKGVclCpcI8sD/mgf0pvnqWlJXTSF05ncwdc3EY8QkW7Ubc0otmacZVUlZOJ+fArxi5tsTz7VWYNK6atXcjF1LDmX/wNdLyEhjg/zIDA15Drbrz3xOohyMQQrxfMa5fJh2xWEr5dINYdAsYGhri4+NTd0WFh5LYnDTMDIxoVE38NdTJixUx4ZRqNRjUY7KwSFPKvNP76OzSlMBGOqflZmHD7G5PMap5W17ft5In/57LC/5duZSdRgub6zn+KSm5HDwQh4e9Ger3NqNubI/Vu3108wF3kMK4CDL++oyco6so06sAzfXtKA0dGrOxy4ussHTlQPDjALyTlkm79FieSzxG8rwJtO82AVNs2XDpZCVHUM73e3YTGteEiYN1UinmhsYs7DeOcamL+T+PeNbZPYrz/LNkTloLjcwhNY8SL1ucFo+66ZTX2pBaDbnH15F/ejvavHQ0eRlo8zPR5KWjyU5BW5Clr2vavAtOE+Zh5Fi7zDSAkasvbq+uJf/MDlKWTiHxh38hfh6H2soBtaUDastGGDo2xbRJe0yadMDQqWkVJ6EtKSJzyyzS1n8EpcXYPT4Nu0Fvo6phlXlFIhI28+O+F7E1c2ZKrxU0dajbcdwO9fkGegghpkspPxFCGAMr0C0wU1C4L4jNTsPbqvqwYaijFwujDhKVnkSrRnWHKdZcOE5yQQ5fdxle5VxHlyZsGzyZ94/8xYLjByg0LKG3hy8ZGQWkpebh7WPHe+/3If/j7RRey8Xut3/dUSegyUkl6Zdx5J3YiMrEEtsBU7Dt+ypqaydkUZ7uIVmYjZFTMwzPHOBy+CYyivJRCxVnMpLp1/pxPMZ+Reqqt8jY+AX/c/LlE0MD3m77KCqhQltcSEH0blLPH8LoyEWaFw0g64dXSLTS4vDvWaikFS2jPGjbojF+Qx4hpX0AeatOYnk0npgOXvhO6YaR453R4tcWF5J9YAkZm76mJOkcKlNr1FaOqM11Ix9DB5+yB3bZQ7uRF2YB/aqMAurCzK8nnjOPknNkBUWXT6DJvoYmJ4XS7GsUHFhC1g7dIlKVhT3Gri0Rxuaoyj4F5w9Sknwe89YDcRj1Vb0cEMCpK9v5af9LeNm14tXuizE1qlvq5Xapz7dwPPCbEGI60APYKKW8+3oFCgq3SFxOGs1tql9929bRG4B95y5QfEnSpq3ubfXUyUQ0Gklw6+tZKFqp5YfIPQTYudLVtVmlfrRa3US3haExIwzbQpQRp9vH0sW1GadPJrJu7RlmfNgX9alECleexGxsKEZB9ctwqQ9SU8rV/42iMGY/9k9+gE2vF1GbX5+8FiYWlTJSylM7T6ddpVirQSJp7+SNUKlxGPEpxu4BaOc9x3v7/kekicA+/gT5UTuQxQUADFYZYmB9AItCW7IvnqXwcgTuUzYx9tm2+PjYoVap2H8gjpPX8pn2y3A6md5+SENqtRReOkre8XVk7VmAJjsZY+82uLy4DIvQJxss/VOo1Fh1GAUdRt1gj4biq1EUXjhEwflDlKRcQpObTmlaPNqiPNSWjXD7z0bMW/Wr97VOJ+5m7r6JuNu05JXui+6KE4DatYYqymnOAn4E9gN7hBAhUtmqUuE+QKPVcjknvVrJYtCFdVzMrInZk062plTvCPbvjUWtEnpHsG/3ReLV6VzISuH7bpUfCFevZPPLj4cZ9XQwzVo40LiJPY8ObMm77fpgYWFMtmUhLm5WGElJxjubUXvZYvlK5zt6n6l/vE1B1A6cnp2HdZexddYPKFMFPZV2hcyiAgyEihDH6yEgq47/psTem4yvHsNkw8dk23lg0H4UBv69eeJMOD2btmFW15FoNFq+/GATnVLeR37UBe8pf2NkrMu0GTw0gEc6eWF6m06g4Nw+svYtJi9iA5rsZFCpMQvog13//2Dassc9SxARKjXG7gEYuwdg3W3CbfcXlbSPH/Y+h4tVU17tvgQzo5pXb99pahsR3LhFZQY6tdCvULaqVLhPSMzPolirqTJRXJFQRy8OaM+yptuL+rKxz4bqaFhcgwAAIABJREFUN3TXaiW7dl4kziIFTy87HvMO4MMZ2+jbvzntH/HCwcGcps3sMSl74NnZm9G9ZxOkVqJJycXkajauV7PJmbMfzdUs7BaPuqOTwzlH/yBj4xdY93ihXk4AdHvvupnbEJl2lat5mbRq5FYl3dO+RWd+H/YVh86HkWhirZtriDqOEGpeCdL99790MR1jCwtcHp2D/H0w8R93w23yBkybdkCtVuFaixRFXWhy00hZ9gbZ+xahMrXCvFV/zFsPxDxwAGrz21tL8U/jatY5/rdnAg4W3vw/e2cdX2X5/vH3fWrdneQ2GmWjG0RCJFQUbERFFAUUu7/+LBALE1AxCEFESlq6Gd25Zt3b2U7dvz/OiLHgrMjn/XqdF5wn7nMd2J7rea74XON7zcLJrnzRybqiThvKFBSuNecrhirSEzKbLUT6hrIk5gDS9RJBNQ1EZ8YSG59JbF4mZzunsS7mBO+0uAsVKiKjgjGZrMdrdWoefMT6AG0pNGDYfJai1Scp3nAamW8o9XlOT3dAF1l7ydLipKMk//QE9g3b4/PgF1U6t4VXINFpsaQW5jGyHDlngM96P87pqAGk6fNJLyogXZ9HoJM7jdys4o+Nw7wZP9GaMDY22ETC5L4kTLoDzwGv4NHvxUobpCpCSkne1j9ImzsRc2F2lZKsNyJSSubsfhuNWsf4nn/gbOd55ZNqGVuqhj4CJskSMTghhAfwkpSy9rsaFBRqmfOOoEEFjmDj+jOk7SpG461md2osg5zdWRt/jHd2LCY2z6pMqlOpCXb24O6IljwQFolKJRhwd2lBNePhZPKn76B44xkoMiE8HLC/MwJtcz9Uga6oA6wvlUvtyR2b8zNJ+vpeVDpHAsbOQ1VFKeWWXkGsjLOOB2nvV7/cY+zUGpu7dbU+DQh5cxOpvz9Pxj/vk73uR7yGvotb1ycQVxhXCdYLYuHBlWQu+xT98Y3YN+5I8GPfYxdy5SlnNzI7YhZyInU7D7X9GDeHayOUZ0uyuL+U8o3zb6SUWUKIAYDiCBSue2LyMrBTa/B3Kj/p5u3jRFhDb7TFKv6NPcTiswdYEXeYxm4+zOj1CK1KVEErmoRlOp1B3tTNFK86gXCzx/Geltj1CUcXGVzptLCaIKUkf/ffpP7xAub8dIInrkTrWfWnjEu1gNr61qsV2zRufgSOnYf+1DbS5r5C6swxZK34AofGHdF41UPrFYLWux5qZ29UTp6onT0Rai252+eQteJzDAmHULsH4vvoN7j1GF3lKp8bjUJDDgv2fUR9r9vo0mj4NbPDFkegFkLYSSmLAYQQDsD1NcVBQaECYnIzqOfiiUqUf0Fp2SqAlq0CmLd8B0tjDuKg0fJ6ZD+eat6lwqHr5rR8jPuTKFp7iqIlRxD2Gpye7YTT41E2TQkrd019LmmzX0R/fCNCY4fQ6BAaO9SuPjiEd8Ehohv29dpgyksl9ffnKdizCLt6txM0YQn29W0bk3o55xPGEe5+eNjXbnOXQ+OOhLy5kfw9/5C96msKD6/BlJ0E5cmICAFSogtuif9Tv+DSfnida/1cLyw6MIW84gye7/5LhT+jVwNbHMEsrAPszwvNjwR+rTuTFBSqhpSSf2MP0dG/IZ6XXdBi8jLKaAwBZGYWcvpkBpFtg1GpBE8270I9Vy/Gt+5dRjNI6o0U/XeK4v9OYdiXhOVcyahyOw2Oj0Ti/FR7VJ6O1bZff2Ynyd8/hDEj1jqTVqiRpmKkyYAh+SQF+5YCIOycLjSHed//KR59x9sUcqkIP0dXGrv50DukSbXXqAwhBC6RQ3GJHApYu3xNWYkYM+Iw52dc0gCWg0N4Fxxb9r2lJGJiMw+y4dTvdG/8CKGe1zb8ZcvM4k+FEPuBO0o2fSClXFm3Ziko2M7PR7fy7o4ljGnRnTfb9r+wXUpJTG4GXcsZDBO9M4F1/50iPMIbN3cH7gxtVqrEVJotGLbHol9yhOI1J5GFRlS+zugig9E+Fom2VQDapn41agiTFgtZK6aQvuAtNO6BhLy+DoewsklbU04K+hOb0B/biFmfg9fgt9H5lf1O1WHFoBfQXKXwi9Do0Po0QOujqABYLGZm73oTFzsvBrd66VqbY7PW0F5Ai7VsVOkqVrhu2HLuNP/buQyAdYnHSzmCFH0eRWZjuU8Ed/QNo3lLf9zcS1eiWHKL0P99kMLZezEn5CBc7LC/qykOA5uhjQyu8hD3ijDlppE87VEKD63COeoe/EZOq7AkUuPmh0vb++pEp768UZIKdc+/R74hJnM/Izt8cVX7BSrClqqh+4HJwHpAAFOFEC+XzBJQULhmxOdl8sy6WTRy86Z/vRZ8tf8/kgpyCHSy/mLFliM2ZzZbMBrN2NtrCQy6mEA2p+RRMH0H+oWHkHoj2shgXF7sjl3PRrWuBaQ/uYVz343AnJeO76Pf4tZz9C0VEqkuBlMRx1O2cCBpLc52ngxsMa7ORNjqkl2xS1hy8HM61L+X9vWHXmtzANueCN4E2kopUwGEED7AGpSBMgrXEL3JwKj/fscsLczo9SjFZhNf7f+P9YnHeTC8HWDND0BpR7B541k2rjvDuJe64loyDctSYCBz1DzM8TnY39UEp4cjqzQQ3laklGSt+Jz0+a9bSy3f3op9vdtq/XNuNg4lrWPjqdkcTd6EwaxHp3bAYNYTl3WIpzt/h52m+vmZq82Z9D3M3P4SjX3a8nC7j6+bGwBbHIHqvBMoIQO4uWu6FK5rpJRM3LyAo5nJ/NrncRq6eSOlxN/RlXUJlziC3Aw0QkXQJZo7DRt5UZBvuOAEpJTkvr0Cc0wWHj/dj137skqb1cVSXIAh8QjFiYcxJB1Ff3IrRae24hx1L35PTEftWLshgZTcM8yNfpcWgT3p3PB+7LW1I/B2rZBS8u/hqSw+OAUPxwA6NRxG66A+hPm2Z9vZv5i9+y2++O9Bxnb/BWe767/TOKMgge82PoW7ox9juk5Dq75+ii9tcQQrhBArgTkl7x8AltedSQoKlTPz6DYWnd3Pa5F96RUcAVgrVHoGR7D07AGMFjNalZpzmwtoo2lQSl46JNSdkNCLjqHw92iKVhzH+cVuteIELIYiCvYvI2/7bAr2/4s0WTuLhUaHNqAJvg9Pxa33mFq/EzSY9Pyw+RlS8s5wJHkjSw5+QddGI+gZ/hhCqEjNO0tKXgyZhYncFnQn9b1a1+rn1zZGczG/73yVHTELaV9/KI+0+6TUiMZujR/Cxc6LGVtfYPKaexnX43c8na7ekJuqUmDI4dsNozBZDLzUbe416R6uDFuqhl4WQtwDnFfJmialXGjL4kKIflgF69TADCnlJ5ftD8VaiupecsxrJXOOFRTK5WB6Ih/sWsYdIU14rmWPUvt6BkWw9OBBtsadoXNwQwxZZvx8rHmAkyfSOXk8jT59w9GWjII0RCeQ99kG7Ho3xmlUuxrZZcpNI+Pvd8jb8ScWfQ5qN3/ceo3BMaIbuqBmaH0a1qjU80rM3v0253JO8EKP33DQurDm+E+sOT6DVcd+LHPsyiPfM7DFePo3ew7VVR7Ybgu5Ren8sOlpTqdHM6jlSwxo/ny5jvP2kH6M6/k73218kklr7uPVPn/j4Xh1przZSrGpkHUnZrLy6A8UGfN5vvtMAtzCrnziVcaWZPGnUspXgb/L2VbZeWrgW6APkADsEkIsllIeueSwt4B5UsrvhRDNsA66r1/1r6FwK5BnKGLM+tl42TvzRZdhZS4Onfwa0uNsc1bOO063lxuzvvFhhja8HYAivZED+8/Rp591JKU5LZ/sFxejDnTF7aMBNbpDLzi0iuTpI7EUZOLS/gFcOj6EY9OedXrhv5Qtp/9k29n53NViHM0CrLo/T3l/Q0ZBArtiF+OgdcHXpQG+LvWx1zgzJ/ptFh+cwpHkjYzs8AXeziFXxU5byC/OYvKa+8gqTOLpzt8RGXpXpceH+7bnxV5zmLL2Aaauf5yX75h/1aSbK8NgKmLz6TksP/ItuUVptAjoweBWE695v0BF2PKT2ge4/KLfv5xtl9MOOCWlPAMghJgLDAYudQQSOP+/5gYk2WCPwi2IlJLXti4kPj+L+f2fLrcT1t3BkfyWBSSSRlZxIbnGIhq4WRPF3j5OPDm6PVqtGmk0k/3SEix5xXhNu6/a+j8WYzEZf71J1sov0AU2I3jicuxCWtXoe1aVhKyjzIl+myZ+nRnYfFypfV5OwfRr9myZc57sNJWWgb2YvfttPljRn6c7f0vzgO5Xy+QKMZkN/Lj5GTILkhjf8w/CfG17Sgv1bMHoLj8wdcPjfL95NC90/xWN+up3JkspOZOxh21n/mJ33FL0xlzCfTswusv3dT5hrKZUNo9gDPAs0FAIceD8ZsAZ61yCKxEExF/yPgFof9kx7wGrhBDPA05cbFq73JangacBQkNrL5mncH2SlJ/Nz0e30tDNmxaegUR4+LPg9B4Wnd3Pq2360u4ygbTCAgOpKfnUb+hJh1b1+Th6BduSzwDQwNUbgIDAi3eJeZPXY9ydgNund6GNqJrIlzQZKY7bh/7kFnI2/4oh/gBuvZ/F54FJV10dU2/M48ctY3DUuTGq41dVCvO0rz+URt5RfLvxCX7b8TL/G7j+mlbfSCmZtesNTqRuZ1THr2x2AudpFtCVx9pP5pftE/h1x8s80fHLOqnIKTDkcCp1JyfTdpCjv1hDI5HEZR4iJe8MWrU9bUL606XRcMJ82l83lUGVUdkTwWysSeGPgdcu2Z4npcyspc8fAcyUUk4RQnQEfhdCtJBSWi49SEo5DZgGEBUVVY5YicLNxFf7/2PWiZ0X3mtKNFi6BYbxXKuyd65L/jnC4UPJvPJmT3oGR/Bx9ApmHt0GlB1Yr190iMI/9uD4WCQOd5c/rAYgc9kkslZ+YR076OiOytEdLGaKzu5GGgoB0PqFETh+Ec4lc3+vJhZpYeb2l0jPj2NCrzm4OvhUeQ1v5xAeavsRk9fcx8qjPzCo5Yt1YKltrDr6I1tLwlvt6g+p1hodGtxDZmESiw5Mxt3Bj6G3vVaufo/BVMS+hBVYpAWdxh6d2gF7rTOhHi3Qaco688yCRNaf/J3D59aTmH0MiUSjssPD0R/BxYu8u6M/fZs+Q5vQAThoXar1Ha4VlTkCI5AopRwBIISIAAYAsVySL6iERODS4GNwybZLGQX0A5BSbhNC2APeQCoKtyQ5xXr+PrOXB8IiGduqJ4czkjiUmcS5gpwLs3MvZ+DgZrTrGIqzsx1NpT/+jq5sSz6DQBDsfLGs0Hg4mZz3VqNrF4LLSz0qtCFz6aek//UGjs16o3bzx6LPwVKYg7SYcOs+CoewzjiEdUbjUXujJqvKv4ensi9hJfe3eZdw38sftG2nsU9bokLvZtXRH+nScDieTlf/O+2NX8HC/Z/QNnQQd7eYUKO1+jd7jqzCc6w69iMn03YyPPL9CxVSUkr2J65i3p7/kVGQUOZcO40TrYP60K7eIJr6dyU++whrj/1EdLy1cz3ctwN3t3yRMN/2NPBqXaqK6UanMkewAuuF+qQQojGwDasA3UAhRDsp5WuVnAuwCwgTQjTA6gCGAw9edkwc0BuYKYRoCtgDaVX/Ggo3C3+d3oPeZOTxJp1o4OpNA1dvBjYoG3ePj8smelc8g4a2wMlZRwNnazmeEIIeQeHMPbmbIGc37EoStpbMQrJeWITKwwH3zwdVKBGdufxz0v96A5cOI/B/+tc6m4N7OSazgcUHPyc59zStgnrTOqgPLvblz1DYn7D6Qmdqr/CRNf7se257jX0Jq1i4/1NGdfqqxutVhZTcM/yyfQL1vW7j0faTaxxGEUIwIuoDGnq34e99H/PxqkF0bng/nRs+wLLDX3P43AYC3cIZ1+MPfJxDMZj1GEx68osz2Ze4mj3x/7Iz9h/sNI4Umwqx17rQO2IUvcIfv67LU2uKkOXJwgJCiINSypYlf/8A8JRSPieE0AHR5/dVurh1bsGXWEtDf5ZSfiiE+B+wW0q5uKRSaDrWvIMEXpFSrqpszaioKLl79+4qfEWFGwUpJT0Wfo6rzp4lA5+r9NgN606zbXMsz43rhItr6TuzZTEH+XDBHIblB/GkcwtMZzMxHknBklmI16wH0Tb3L3fNrNVTSZs1Hud2wwgY/cdVq/rJLkzhxy3PcCZ9D+4OfmTrUxBCRZhPO1oH3UnroDvwcbHOCziXc5JPVg3Bz7UhE3vPR6epnbvSf/ZPYvmRb3mtzz808L69Vta8EmaLkUmr7yUtP5a3+6/Ew7H8/5fqojfm8e+hqaw98TNmixF7rQt3t5hAz/BHK5SmMJkNHEnexP7E1QS4htGl0QM3fGPeeYQQ0VLKqHL3VeIIDkgpW5X8fQswWUr5T8n7/VLKa9KRojiCm5ctSad4YOUMvuw6jPsaR5bZf/pUBlJKGodZO4mLikzlDkbP2niCvOf+QWcWoFWjCXVH3cATx2GtsetavvJl9vpppM4cg3PkEALGzEVcJTG2k6k7mbblWYpNBTzafjKRIXeRkH2EvfEr2JuwgqScEwD4uzaiZWBvDiSuodCQyxt9l9RqGKfImM/bS3vg5RTMq30WXpUE56IDn/Hv4ak2lYnWhJTcMxw6t56o0IHXbALY9UBljqCyW54DQojPsIZ1GgOrSha7ulOVFW4Zfj22HXc7RwbWLxsKslgki/4+hKOTjsZh3gghynUChn2JGCb8iwx1wzypL4ERoVecFJa3awGpvz6LU6v+BIyZc9WcwObTc5m16028nYIZ33MWQe7WLukQj+aEeDRnUKuXSMuP42DSWg4m/se6EzOxSAsv9ppT67F8e60zQ1q/wm87Xmb5kW+ICr0bb+fQOhuWciptF8uPfEvHBsPq1AkA+Lk2xM+1YZ1+xo1OZU8EDsA4IABrWGd/yfZOQCMp5e9XzcpLUJ4Ibk7OFeTQYf6nPNW8C2+1HVDuMelpBbi62aPTlR+3Nx5PJfOxuajcHfD8fQRqnys/0hceXU/ilP7Y1Y8k+OVVqOyuTgllVmEyby3pRiOfSJ7p8oNNUsRFxgIKDFl4OVV9LKUtWKSFz9YM43S69ffLXutCiHszbg/pR6/wkbX2lKA35vHB8n4IBG/1X37DVdjcqFTriUBKqQc+KWf7VmBr7ZmnoACzTuzEIiWPNCldAbNvbxKnTqQzeGhzvH0qHqdoiski68n5CEcdnj/db5MTKI7bT9LXQ9H6NiJo/OKr5gTAWvUjsfBou09t1qO31zphr63dkZKXohIqXuo9l8TsY8RlHSIu6zBn0/cyb8/7nM3Yy2PtJ9dKpczc3e+SWZjEy73nK07gOuHqZMMUFCrBaDEz+/hOegaHU++yITIZ6QWkpuShUld8N2pOyiXzyXlIi8RrxjDUQVe+sBpST5MwZQAqB1eCXlqO2vnqiYCl5cex+fRcujYajrfz9dUgqVZpCfVseUEKQUrJyqPfs3D/p2QUJDCmy7Rq9SycZ8PJP9ges4C7mr9AI59yb04VrgGKnLTCNWdZzEFS9Xk81qRjmX29+4Qx+rmOqNXl/6iaU/PJHPknMq8Yz+nD0DQsv+QSQJpN5O9bRtLU+4h5vTnSZCBo4gq0XldXa2fpwS9Qq9QMaP7CVf3c6iCEoF+zZxnd5Xvis47wyeohJGYfr9ZaR5M3Mzf6HVoE9GBgi/G1bKlCTVAcgcI1JSE/i7e3L6aJhz89gsIvbN+5PY5zSdYh8RU6gfQCMp/4E0tGAR7T7qtwmIwh5RRp817nzEv1SfpyEPoTm/G4Yyyh727HLrBp7X+pSkjKOcGOmIX0CHsMd8faH35TV7QJGcDE3vMwmov5dPUQNp+eQ0X5xfJIyT3DtM1j8HNpyJOdv7kuVU9vZSrTGlqCtba/XKSUg+rEIoVbhmKzidHrZmGymJnW8yHUJUPUDQYzq1eeoHFjbx54qPwJXpZsPVlPzsNyLg+PH+9D17p0FY3FWEzB3kXkrJ9B4ZG1oFLj1LIfbo88gVPrAQjN1RclA1hy8HPsNE70azbmmnx+Tajv1Zo3+i7ll+0T+H3naxxI/I9H2n1SYePbeQqKs/lm4xOoVBrGdv9ZyQtch1SWI/is5M97AH/gj5L3I4CUujRK4dbgvR1L2J+ewPReD9PQzQeDwYxaLdDp1Ix7sSvqCso+LTlFZD45H1NMFh7f34suqnQVjSHpGAmf34UpPQaNVz287vkfrl0fR+txbTtD4zIPsid+OXe1GHfdDSaxFQ9Hf8b3nMXa4z/xz/5J/G95X4a0ehmJJEefQrY+lQJDNvYaJxx1rjjq3Dh8bgOZBYlM6DX7usuJKFiprGpoA4AQYsplJUdLhBBK/aYCYE0m3rv8R/qENGVMS9uljP86Fc3vx3cwpkV3+tdrgV5v5JsvN9PqtkD69o/AuQJpaEu23uoETqbj8fUQ7DrWK7W/6OxuEj+/C4SKwPGLcWrV76rJRID13+Nc7klOpG7ndFo0BrMelVAhUJGQfQxHnRt9Ip68avbUBSqhok+Tp2jq14Wfto3jt52vXNjnpPPA2c6DIlM+hYZcjOYiVELDo+0nXfdSzLcytlQNOQkhGl4yV6ABVsloBQXS9PnsTIkhOjWODv4Nud2n8sSrlJIt507z6taFdPJvyKuRdwLg4KCleQt/GjWuOMxgySokc9R8TGcy8Jg6BLtupZuECo/8R+LXQ1E7eRH88kp0/ldvElRc5iFWHf2RYylbyCvOAMDNwRdnnScSCxZpBiT33fbmdTE4pTYI9mjKG32XkJh9DGc7T9wcfMqUlxrNxZgtpjote1WoObY4ggnAeiHEGazzCOoBo+vUKoUbhuPZyQCohWDcxj9ZOfgFHC6Lv1ukhd2pcSyLOcjy2EMkFeQQ4OjG1G7DWbviFO06huLh4cCAuytO3FoyC8l84k9Msdl4fDMUuy6lpSLyoheS/P2DaP3CCJq4vMphoP0Jq9kTv5xAt3CC3CMIcm+Cu4P/FZuo0vJiWXTgM3bFLcZR50arwDsI921PuG8HvJ1Dbwgt+pqgVdtVOv9Yq7a7roa0K5SPLTOLVwghwoAmJZuOSSmL69YshRuF41nWdNGULsN4fuNcPtq9gg86XKwjOJ2TxrPrZ3M48xx2ag3dA8N4pc2d3BnaHFOehS2bzuLgqKVbj4olACyZhWSO/BNTfDYe3w7FrlP9Uvuz//ue1N9fwL5hO4ImLKlyT0B6fhw/bRuHRZrZHrPgwnZ7jTNuDr7Wl70vLvZeaFQ61GotGpWOrMIktp75C7VKQ/9mz9G36TM3zd2+wq2FLTOLHYEXgXpSyqeEEGFCiAgp5dK6N0/heud4dgoedo4Madiafenx/HRkC31CmtItKIy/Tu3hjW3/YKfW8EWXYfSv3wJnrR2GYhM6nQa84KVXu+PmXvFkL0uBgczRf2GKy8bj+3uw63AxJyClJGPBW2Qu/QSn1gMIeHYuKruqhSAsFjO/bH8RIVS8P2AV9loXkrKPk5B9lNS8s+ToU8kpSiUmcz95xZmYLQZMFiNSWlAJDV0aDWdgixdwc7hxSkEVFC7HltDQL0A0cL7bJxGYDyiOQIETWSlEePghhOC1yH5sSDzBi5vn0yWgMX+d3kN7v/pM7T6CQCdrt69eb+S7r7fS845GtIkMrtQJyGIT2WMXYjqWivs3Q0s7AZOB5J+fIm/rH7h1fxLfR7+tlmz0qmPTOJW2i5Edvrig4RPm2+6KoxItFjMSiVqlNOcr3PjY0lDWSEo5CevEMqSUhcDNHfhUsAkpJcezU4hwt94NO2i0fNXtAdL1+Sw4vZdxrXvxZ7+nLjgBAJVK4OvrhKtr5Zo10mwh+5WlGHbE4fZhf+y7N7qwz6LPI/GLu8nb+gdeQ9/H9/EfquUE4rMOs/jgFNqEDKB9/aFVOlelUitOQOGmwZafZEOJEqkEEEI0ApQcgQJJBTnkG4uJ8Lg4UKS1dzC/3PEYzlo72l4yZF5KicUisbPT8MjIyjVmpJTk/m81xatP4vJqTxwGNb+wz5yfSeLnd1EUE43fqBm4da3ehC6juYift43H2c6Dh9p+dNMndRUUKsMWR/Ae1rGVIUKIWUBn4PE6tEnhBuF4tjVRfP6J4Dw9gyPKHLth3RlOHEvj8VFR6Owq/rGTJgu5H65BP/8ATk+1x+mxi07DlH2OhM/6YUw+QeDY+Ti3GVxt2xcdmEJSzgme7z4TZzuPK5+goHATY0vV0CohRDTQAWtIaJyUMr3OLVO47jmeZS0dDfe4cqLU2VmHq5sdGm3FzV1SbyR74hKK153G6cl2OI/vemGfMe0sCZPuxJSbQtCLS3Fs1rvadsdk7GfN8Rl0bfQgLQJ7VnsdBYWbBVuqhtYCU6SUyy7ZNk1K+bQN5/YDvsI6s3iGlPKTy/Z/AZz/TXQEfKWUygS0G4QT2Sn4ObjgUYmOv9lsQa1WEdUuhKh2FTebWTILyXr2b4wHz+HyVm+cHmxzYZ/+1DaSvrkfadQT/MpqHBq1r3CdK2G2GPltxyu42ftw722vV3sdBYWbCVuSxQ2AV4UQ716y7YpC4kIINfAt0B9oBowoGVZ/ASnlBCnlbVLK24CpwN82W65wzTmelVLp00Bqaj6ffbKemDOZla5jiskk48FZGI+n4f7VkAtOwGIsJm3+G8R/2A2h1hLy2roaOQGAlUd/IDHnGCOi/k+p+VdQKMEWR5AN9Ab8hBBLhBC2jVOCdsApKeUZKaUBmAtUFtQdAcyxcW2Fa4xFWjiRnVomP3ApWo0KNzd7XFwr7izVLz5Mxn2/YcktxvOX+7G/wyoLURy3n7j/dSBr2ae4dnmMev+3D7uQljWyOTn3FMsOfU1kyF3cFnxnjdZSULiZsCVZLKSUJuBZIcTjwGbAluxaEBB/yfsEoNzbOSFEPaxPHv/ZsK7CdUBcXhZFZmOpiqHznA8HeXg68szYTuWebykwkPvBaooWH0EbFYz7pIGo/V2QFgtZK6ZB1wTZAAAgAElEQVSQvuBt1E6eBI77B+fb766SbXpjHosOfIZKqIkKHUgDr9uRSH7f+To6tT0PRL5Xna+soHDTYosj+OH8X6SUM4UQB4HnatmO4cBfUkpzeTuFEE8DTwOEhioyttcDFxLF5TwRzPl9L24eDtw9uFmZfQDGoylkT1iMOSEH5+c64fRMR4RahSkrieTpj1N4ZC3OkUPxe/wH1C7eVbIrPT+ebzeOIjn3FCqhZu3xn/B0DCLEoxmn0nbyaLtJuDn4Vv0LKyjcxFQ2mMZVSpkLzBdCXCrechaYaMPaicCl2cHgkm3lMZxKnIuUchowDSAqKsr2sUgKdcaJ7FQAwt1LX1QtFombhwOuFYSDijeeIXvCYoSrHZ4zH0AXZf0Ryd+7mOSfnkQa9PiN/BHXbqOqXNt/Oj2a7zc+jcli4IUev1HfsxX7E9ewO24ph89toJl/Nzo1vL8a31ZB4eamsieC2cBArPISktLdxBKoWCXMyi4grES2OhHrxf7Byw8SQjTBGmraZrvZCteaY9nJBDm546Ir3SGsUokKnwQKFxwg971VqOs5o3ooj6zDH2NcfwZjWgzGlJPY1budgNF/oAtsUu75lbEzZhG/7ngZD0d/xnb/E3/XxgB0aHAPHRrcQ7GpELXQKI1jCgrlUNlgmoElfzao6JjKkFKahBBjgZVYy0d/llIeFkL8D9gtpVxccuhwYK6sygBUhWvOeY2hS8nKLESvNxIYVLqeQEpJ/tTNFPywHUtgOrkeb8NKAyonT7S+DbELbY1b91G493kBlbZqksUWi5lFB6ew4si3NPZpx5iuP5Y7/ctOU3GJq4LCrU5loaE2Fe0DkFLuudLiUsp/gX8v2/bOZe/fu9I6CtcXJouZ0zlp9Agq3UG8/r/T7NoZz9vv98HBQQuAtEgyxv2EaW0WBu/dmJrvwLvvB7h1fbzK8f/L0Rty+WnbOA4m/UeXRiMYHvm+on2voFANKgsNTalknwR61bItCjcIMbkZGCxmIjxK5wf63dWEps39LjoBKcl+ax6mtVmYwg7g9spAXNv/XiuD41Nyz/DtxidJy4/lwaj/o1vjh5Wwj4JCNaksNKT03iuUy7ELGkOlS0cdHLQ0aXrROeR9+R/F/8RhDN2L/29foHWrHc3+fQkrmbl9ImqVhgm9ZhPuW7MmMwWFWx2bdHSFEC2wdgdfyAxKKX+rK6MUrm+OZyUjEDR29wGgsNDAn7P307d/BIFB1m7d/F92UTh9DwafaLy/fK5WnIDJbODv/Z+w9vhP1PNsxegu31+YIaCgoFB9bNEaehfogdUR/ItVMmIzoDiCG4Ck/Gwyiwto4VW1Gb6VcSI7lXounhdmE6elFpAQn835yEzhggPkT16P0eMATq+0xbFJ10pWs430/Himbx1LTMY+eoWP5J7bXlfyAQoKtYQtEhP3YZWYSJZSjgRaA7bKTFw3mPMzyFj0f0hLuT1rNyVSSsasn809//5IcmFura17PCu5VMVQvfoevPFObwICXTHsSSD3vVWY3E6guq8QzwEv1vjzYjL28+HKu0jOPc3oLt/zQOR7ihNQUKhFbHEEeimlBTAJIVyBVEo3it0QFBxYQcbCd8le+921NuWqsTs1lui0OApNBj6NXlHuMduTz/DMullkFRcCkJ9fzPq1p4iLzQIgL7eIGT/s4MSxNACiU+M4m5tBhLsfR4+ksHrlCQDUahXmjAKyXvgLiy4TY/ut+D/9U40TuOn5cXyz4Qkcta681XcZbUIG1Gg9BQWFstjiCHYLIdyB6Viby/ZwAzZ/uXR8EMeWfUmf/wbGtLPX2pyrwg+HNuJu58hjTToy/9Qe9qXFl9qfWpjHM+tmszTmIGPXz8FssQDw35pTxMZYHYFGqyYtLR89BiZu/ovBS7/Dx8GZoY1u59iRVI4cSsFoMGMxmsl44kcsWYUY2m0g6LWFqJ1qpiheYMjhmw0jMVsMPN9jJj4u9a58koKCQpURVenjEkLUB1yllAfqyqArERUVJXfv3l2tc40ZccS82RKHRu0Jmrjypi43PJ2TRo+/P+eF1j15pkU3ui74jPquXiwc8AxCCCzSwsOrfmFHylkedujIwaPnaDsgmNej+lFcbMKuZIqYRVqYc2IXH0evJN9QxMOyM91Dw7ijVxgWi8RksqBTW0h56l3Y4Yml+3H8pkxB7Viz6KHJbOCr9Y9wOj2a8T3/INy3Q238sygo3LIIIaKllOWOELDliQAhRCshxCCgDdBYCHFPbRp4tdB6heIz7BMKD68ld9Mv19qcOuXHQ5vQqdWMbNoJF509r0Teye7UWBafPcDxY6m8O2klW+NP8377u+np1YTGwpcf921iaczBC07gTE4696+YzqtbFxLh7sfKwePo6teYI/usTwFqtQp1UQYJzz8EOzwRkQYCvv2xxk5ASsnvO1/lROp2Hms/WXECCgp1jC1VQz8DrYDDgKVks+QGHSLj1nM0eTvnkTZnIk4t+6HxCLzWJtU6afo8Fpzew7DGkXg7OAPwQOMofj26jQ93/8urAf1JzM2mf4sWPBTeDktjSYduoRxbkcCLm+bT0NWbDYkn+GzvauzUGiZ3vpfhYVEIIYgY4EeP3o3Q2WnQn9hJ2isfoz3VFlU9HT4zJiBUFY+itAW9MY9Zu95gV+xiBrV8ifb1h9bGP4mCgkIlXDE0JIQ4IqUsX0XsGlCT0NB5DMkniH37dhxb3EngC3/fdCGiSdErmXpgPRvueYmGbhdlHLaeO839y6ejUakIcHJjxaAXcLNzuLA/uTCXAYunklFUgFla6BvajA87DsHfsewkr6yZP1P4zVHUhb5oO/vi/tG9qH2ca2T32fS9zNj6PJmFSdzdcgL9m4296f5vFBSuFTUNDW27fMTkjY7OPxyvoe9RsHcx2aunXmtzapUCYzG/HttO39BmpZwAgOM5ex442xEHg45vuo8o5QQA/B1dmdbzYVp6BfFd9xHM6PVIGSdgzi8m5aEPKJ6UgUo44/pZb7ymP1YjJ2CRFlYc+Z5Ja+5DIpnYex4Dmj+vOAEFhauELZ3Fv2F1BslAMVY5aimlbFWnltUxHn0nUHR6O2mzJ6B2cse186PX2qRaYe7J3eQY9DzToluZfQ6OWlo2COS5ezrRsKQr+HKi/Oqx9O7yR0MYjqSQ+fTPyEwdon02fl+9icq1ZqqesZkHmbP7bc5m7CUy5C4ebvcxjrobrk1FQeGGxhZH8BPwCHCQizmCGx6h1uA/ehZJXw4i+acnUTm44dymspHKNwZ/n95La+9govzKllpGNPEloknVp3NJKdH/uY/cj1ZjEQWoHyrG941JNbpjLyjO5p8Dk9l0ahYu9t6M7PAF7esPVZ4CFBSuAbY4grRLZgfcVKh09gS+8DcJk+7k3HfDCXpxGY7NblxRVb3JwOGMJMa07F5mX3aWHicnHVpd1ZK5Um8k560VFC0/hsntBOr7TfiO+7lGF+wdMQv5M/p99MZceoaPZFDLCTjoyuYhFBQUrg62OIK9QojZwBKsoSEApJQ3ZNXQ5ajsnQl6cSnxH/cg8euhBE1YgmNE2bDKjcCB9ERM0kKkb9m5zgv/Okhmpp6XXi3rJCpCFhnJGrsQw/ZYikJWoO3rhP/zCxAqm6qOy2A0FzE3+j02n55DI+9IHmr7EUHuVZ9GpqCgULvY4ggcsDqAOy/ZdsOWj5aH2tmT4IkriP+0NwmT7sT/iWk3ZM4gOi0OgNt9yiqAdOvZkIJ8g81rXeoE9A0XoOnkQMDYPxEabbVsS8uL5cctY4jPOky/ps8yqNVLqFU2id8qKCjUMZX+Jgoh1ECGlNKWYfXXNbLIiH75cRyGNC83rKHxCCT0rS0kfXs/ydNHYkg+idfQ96t993st2JMaR30XL7zsy1bwNGps+zQwWWwi64V/MGyLpbjJckR4HoHjVqLSOVz55HLYn7iGX7ZNQAjBc91+plVQ72qto6CgUDdUepWTUpqBzlfJljpF/+8xct9cTvHakxUeo3b2JPil5bh2G0Xmko84991wLCVibNc7Ukr2pMXRppyw0L49iWRm2vY9pKHECWyOwdhmB0bffQSOW1jtbuEtZ+bx/aan8HGpx5t9lylOQEHhOsSW2919QojFQohHhBD3nH/ZsrgQop8Q4rgQ4pQQ4rUKjrlfCHFECHG4JBdRJzgMao6msTd5kzcgDRVLUQuNFr+RP+L9wGTyo/8m8fO7sBTl15VZtUZiQTap+jwifUo7Ar3eyNxZ+9ixNdamdfImb8Cw6SyWnrHoNYsIGDMbnX94tWxae/xnftvxMk38OjOx9zy8nW840VoFhVsCWxyBPZCBdUbx3SWvgVc6qSSs9C3WQTbNgBGXN6YJIcKA14HOUsrmwPgqWV8FhEaFyys9MMdnUzhnb+XHCoFn/xfxH/0H+pNbSJgyAIs+r65MqxWiU635gTaXOQIHBy2vvNGTTl0bXHGNorUnKZy1B1UXC/kF3+M97GOcWvWrsi1SSpYc/JJ5e97n9uB+PNftJ+w0Nes3UFBQqDuumK0rGUZTHdoBp6SUZwCEEHOBwcCRS455CvhWSplV8lmp1fwsm7Dr0gBdlwbkf78Vh8HNUblXHvN27TAcoVJz7seHSZjSn6AXl9VYUK2u2JMWh71aS1NP/zL7PL2ufBE2n8sl580ViBA12cVv4dJxBB79X6qWLf8cmMyKI9/SscEwHmn3iZIUVlC4zrniE4EQIlgIsVAIkVryWiCEsGVQbBBwqQB+Qsm2SwkHwoUQW4QQ24UQ5d5+CiGeFkLsFkLsTktLs+GjK8bl5R7IfAP532217fh2wwh4di5FZ3eR+Fk/zAXZNfr8uiI6NY7W3sFoLhF9y8stYv7c/aSlVR7akiYL2S8vRRbpyfP4BMdWvfEbOa1avQLxWUdYeeQ7OjUYxqPtJylOQEHhBsCW0NAvwGIgsOS1pGRbbaABwrDORB4BTC8ZglMKKeU0KWWUlDLKx6d8aQRb0YZ543BfKwrn7sN0NtOmc1wihxI4dj5FsXuJ/7gHxoz4K590FSkyGTmcmVSmf+BcUh779yVhNlUuLJg3dQPGPYkUBv+Jy4BhBI1fjMqueqGchfs/wUHnyn1t3kYlbpyKKwWFWxlbflN9pJS/SClNJa+ZgC1X40RKj7QMLtl2KQnAYimlUUp5FjiB1THUKc5jOyPsNOR9tsH2c24fRNCEJZgyYon7oBNFsfvq0MKqcSgjCaPFXCY/EN7Eh3c/uBP/AJcKzy1cs5eC6bsweO/G4/lH8H3kG4S6enfxR5M3c/jcBvo3ew4nRS9IQeGGwRZHkCGEeFgIoS55PYw1eXwldgFhQogGQggdMBzrk8Wl/IP1aQAhhDfWUNEZm62vJmpvJ5ye7kDxulMUb7J9bKVTiz6EvLERoVIT/3F3Cg4sr0MrbWdPWtlE8Xl5ca22YkmJgq3ryHlpMRaHdDw+GY5H3/HVlo6wSAt/7/sYT8cgeoY/Vq01FBQUrg22OIIngPuBZOAccB9wxQSylNIEjAVWAkeBeVLKw0KI/5VMO6NkX4YQ4giwDnhZSmmLk6kxTo9Gom7oRc67K7HkFV/5hBLsQloS+vZWdH5hJH45mMxlk7AYiurQ0isTnRZHiLMHvo4X7/y3bIrhh2+2YiinVFZKSebyb8gevxCkBo+vh+DSqWYDYHbHLiEu6xCDWr2EVm1fo7UUFBSuLld0BFLKWCnlICmlj5TSV0o5REoZZ8viUsp/pZThUspGUsoPS7a9c17ETlp5UUrZTErZUko5t2Zfx3aEnQa3j/pjSc0nb9K6Kp2r8Qgk5PX1ON02kPT5rxPzWhNyNv6MNJvqyNrKiU6NLdNIZmenwdnFDt1lInOW4kKSpz9O/ifrUOeH4PbhABw7d6rR5xvNxSw6MJlg96a0rzekRmspKChcfSoMBgsh3qnkPCml/KAO7Lmq6FoF4PREOwpm7MC+Tzh23RrafK7K3pmgF/6m4PAa0v96i5SfnyJr+RS87/8E59vvrhN7pZSMXPsrjd18eTWyL1qVmqSCHJILc8vkB9q2D6Ft+9INXIVH15Ey8xk47I5D2n04jmqL492319iujadmkV4Qzws9fkNVw1GVCgoKV5/KnggKynkBjAJerWO7rhrOYzuhaVQSIsqteojHqfkdhL6zjYDn/wKhIumrIaTMHIPFoK91W49np7Am/hg/HNrI/cunca4ghz2p1o7hSzuKc3OKsFguVgqZC7JI/vlpEj69A5HtiUP8MHQdQnEZV32V1ZTcM6w+Np3P/xvBX3s/pIlfZ5r535iqrQoKtzoVPhFIKaec/7sQwgUYhzU3MBeYUtF5NxpCZw0RZTw4i7xP1+H2Yf+qryEELpFDcW49kPS/3yHr30noT20lYMxs7IKa15qtW8+dBuDNqP58sW8t/RdPpYmHP3ZqDc08Ay4c9/P0nXh4OPDw8DDydswlY9EHmPPScO/3Cqp5EVg89Lh/djdCY1t5p9FcRHzWEWIy9nM2Yx9nMvaQnm+NDga6hXNHkye5I+IJZaiMgsINypXURz2BF4GHgF+BNue7gG8mtC1LQkTTd2DXoxH2faqnrSM0Wnzu/xjHpj1Inv44ce+3x2f4ZNx6PI2ohZDJ1nNnCHH2YEzL7vQOacLo/2ax+dwp2vrWQ1dS8mkxm2jfqADzqSWcGfct0lSMXYO2BE1YgmW7itxjq3Gbcjcqz/L7BCwWM0eSNxGfdZjEnGMkZh8nOfc0FmnNf7g7+FHf6zbuiHiSloG9FP0gBYWbAHG+zLDMDiEmA/cA07DKQFwXymtRUVFy9+7dtb6uNJjIfHQuxhNpeM4cjq5VwJVPqgRTdjLJ0x+l8PBadAFN8BryDs5th1Vb1toiLbSa83/0DW3KlC7DAOug+s/2rqa9XwPucPMkZ8NP5GyYgSkzHpWTJ64dRuDa9THs6rVB5hSR1n8G2ggfPH55oNy7d70hlxnbXuBQkjV57ukYRJB7E4Lcm1DPsyUNvG7Hw7GshIWCgsL1jxAiWkoZVe6+ShyBBetAGhPWQTQXdmFNFl+T2YLVdQT5+cVsXHeG1rcHEhRcfrOTOaOAzBGzkHojnnMeQhNcpsm5Skgpyd/zDxl/v4sh8TC6kFZ43DkOtaM7UlpASoTOAcemPa+o9X84I4m+i7/my673c1/jNtb1LWYKj/xHzvrp5O9dRJb0Jz7oUe4c2ArnNoNQae0unJ/z3ir0Cw7g9fdjaMPK9gOm5sXw3cZRpOTFMOz2t+jY4F5lfKSCwk1EZY6gshzBTaUPoFar2LolBk8vxwodgdrLCY8f7iXjwdlkPbMAr1kPoXKrfk38hdzB7YPI2zmPjIXvk/LTqDLHqZw8cO30CG49nsIuqFk5K8HWZGt+oFNAI4qTjpK75Xfyts3ClJmAyskTjz7jOK0ZypED+fRt2rWUEzAeTkY/fz+Oj0SW6wSOJm9m2pZnEagY3/N3IvxqVk6qoKBwY1HhE8H1Sk1CQ4ZiEzq7K8snGHbHkzlqPtrbAvGcfh9CVzvCadJswpB4GCmlNTQjBKbsc+Rumkle9EIwG7Fv3AmnFn2wb9gO+4btUDt7YtHn8dG893CJ3cMQYw7F8ftBpcapZV9cOz+C022DUOnskVKSl1uM6yXOS1okmQ/NwpyQg/e/T6JysStl0/qTv/Fn9Hv4uzbm2W4z8HEuO9hGQUHhxqdaoaHrlbrKEVyOfukRcl5Zhq5LfdynDCpzAa1tTLmp5G7+jdxtszAkHISS/xeNVz1MWQlgMWNWaXAO64Rzm8G4dBiBxs0Ps9nCv0uP0bV7A9zLkdUu/PsguW+twO2j/jgMaXFhu9liYv7eD1h3Yiatgu5gVMevsNeWHXGpoKBwc1Ct0NDNytxZe3Fw0DL4nhaVHucwsBmy2ETu+6vJfHAW7t/fU+OcQWVoXH3xHDARzwETMetzKT67m6IzOymK20eWy0BeS0vjybvGMTiiQ6nz0lIL2LktDj8/Z9p1KH03b07OI2/SOrRtgrAfdLGMVW/MY8aWsRw6t547Ip7k3tveUBrBFBRuYW45R+DoqMPewbav7XhvK9TB7mSPW0TGA3/g8fUQdJG2jGKoGWoHVxyb9cKxWS8AFh3cwN7dy+kYUrYnwT/AhZdf71EqHATWkFDOm8vBaMHtw/4IlbVKKKvwHF+vf4zk3FM81PZjujV+sM6/j4KCwvXNTZUQtoVBQ5tzZ78Im4+3ax+K19yHULnak/nEPAr/3MfVDqdtOXeaMDffUqJyADnZeqSUZZwAQOGcvRi2xeLySg809TwubJ+z+20yChJ4vvuvihNQUFAAbkFHcJ68KshJaOp74jXnIXRtg8l9fzVZT83HnJhTh9ZdxGgxszMlhk4BpXWQjEYzX362iaWLj5Y5x3Q2k7wpG9B1bYDD/a0vbI/NPMj+xNX0bfoMzQK61rntCgoKNwa3pCNYufw4kz5aj7EcieaKULk74DFtGK7v9MG4L4n0wb9QOHcf0lK3TwcH0hMoNBnoGNCozL47+0fQqnXpxjdpNJPz2jKruur/9SvVOLb00Jc46tzoFVHdMdQKCgo3I7dcjgCgWXM/nJ10F0I8RqOZJf8coV59DyLbVpwDECqB4/DbsOvagJx3VpL7v9UU/rkP+/5NsO8bUSoEA9bQjVs5lTxVYes565yeTv6lnwi0WjUdO9crtU1KSf7ULRgPJuP++SDUPhergGIzD3IgcQ2DW03EQVvxxDIFBYVbj1vSEYSEuhMSerECSK1WkZqSh7OLDoCU5Dw8vRwrnO6lDnLDY8Yw9P8cRj9vH/lfbiL/y01omvpi170h2hYBJLvYMe3PAzz4WCQtWvpjNltQq6v+ALY1+TRNPPzxtHe6sO1cUi5pqfk0b+l/YU1ptpD36ToK/9iDwz0tsb8sD7Lk4Bc46dzpGf54lW1QUFC4ubklHQGAyWRm7qx93D2kOW5u9jw1pgNqtQq93sj332yleQt/hg1vXea8A/uSaBTmjZOTDsehLXAc2gJzUi7JS/Zy5p9o6v+YikqCPTDGWYd9eh654T5EJ+djDnKj55NtUXs5lTWoHPQmI7tSYnkwvG2p7bt2xLNrRzzhTXxRq1XIIiPZry6jePVJHB+LxOXlnqWOj8k4wMGktQxu9bLyNKCgoFCGW9YRnEvK4+D+czRq7EXHzvVRq1XkG4txstcx5J4WhJaEeVYsO4ZWp6Z3nzBycoqY9dseevUJo2//CKSUFBebWFZwirec/sPnbldaJwQT63CMp3VN6JzjhvlEOvoFB2mqNwKQ9tsudJ3r4zC0Jfa9G1fatfzL0a0UmY0MqF+652Hg4Ga06xCCvb0GS7aerLELMe5NxOXVnjg9VrZfZOmh808DyixhBQWFstyyjiAk1J33P+qHvb2GE9kpfLlvLUvOHiTc3ZdRzTvTxM0XgPT0Auztrf9Mbm72jJ/YDeeSLuPDJ5L57YdolkTspkmIP8836s1RcxqEqXjm3F6iWtTj69cfIMTZA0tKPqazmRh2x5P/1wEMLy0h190Bh8HNcH6mUxlNo8yiAqbu/487QprQ4bL8gEol8A9wxZSYQ9bovzAn5OA+ZVCZcBBATMZ+Dib9x5BWryhPAwoKCuVSpxITQoh+wFeAGpghpfzksv2PA5OBxJJN30gpZ1S2Zm1KTJzMTuXLfWtZfPYAjhotw8Ii2ZUSw+HMc3jZO/FIkw480bRTqfj8eU5lp/L8gvlY0qFvtwheaN8TzSXduQtP7+ONbQtx1NqxY9irF/ZJKfl68kb8zuXSV0iK15xE5e2E28cDsGt/sTP47e2L+e3YdtYMGU+Yu9UpGQ1mfpq+ky7dGhChgqxnFiCNZjy+GYouqvy5AFM3PM7Z9L18NGiLIiGhoHALc00kJoQQauBboA+QAOwSQiyWUh657NA/pZRj68qOS8krysDF3guAn45s4f2dS7FXa3m2ZXdGt+iKp70TUkq2Jp9h+uFNfLlvLX8c28H/dRzMwPotL6yzKekko9fNQueoYfrjD9PWr36Zzxra6DY0KhVj1s9mT1o87UqOEULw6JNtQQg8PBwwHkom+5WlZD3xJ46Pt8VlXBfO6rP5/dh2RoS3veAEwCqlbTSYcDqcTObk9QgPB7xmDkfTyKvc73s6PZpDSesY2vo1xQkoKChUSF2GhtoBp6SUZwCEEHOBwcDljuCqsCt2MTO3T+TNvsv4/thRfjm6lb6hzZjU+R687C9eJIUQdA5oROeARhzOSGLilgU8s24W/es15/86DGZV3BHe2r6Yxm4+zLzjMUJcPCv8zG6BYaiFinUJxy84AgCPkulgUko2JuVx27Rh6H7aQeEvuzBsOcv6FsW0dtEx4Z6LSV9pMOGcXsBIVx35H65BHe6Dxw/3lioRvZwlBz7Hxc5LyQ0oKChUSl06giAg/pL3CUD7co67VwjRDTgBTJBSxl9+gBDiaeBpgNDQ6skkR/h2RK3S8M7a51mRexujm3fljaj+qCuZGNbcK5AlA5/lx0Ob+HzfGrosmIzeZKRnUATf9RiBi67yWQVudg5E+oayLuE4r0b2LbO/sMDIurWnAOj97p3YdW9E2oerGPB3PgNwQv75CxlNfbFkF2GKzUKUNK/pujTA/YtBqJx0FX72idQdHE3ZzH23v4WdpvyxlAoKCgpw7ZPFS4A5UspiIcRorHORe11+kJRyGtaRmURFRVUrqVFg0ZEsWuNh2MprLUcwNuoum87TqNQ816oH/eo1570dS4nw8OO1yL6l8gGV0TMogk/3rCS1MK+MVpCTs44JL3fD08t6obbr3pAxeRaKU4wsCBwM+1MwHk7GHOzGTiEI7NKA24Y0RxPuc0FErjyklCw+MAU3B1+6N37EJjsVFBRuXerSESQCl2Ywg7mYFAZASplxydsZwKS6MmZ/egKHixpwh/0xCrMWIeWj5c7trYhGbj78fmfVpRl6Bofz6Z6VbEg8wbCwyMTy5QkAAAzsSURBVDL7vbytieiCfAP7suLYlx7P5G734hreHAZcVBttfSaTgCBXtDYM1jmWsoWTaTsYHvk+Ok31J6wpKCjcGtSl1tAuIEwI0UAIoQOGA4svPUAIcalQziCgrILa/7d359FVlGccx7/PTWIgBAhJWLJQCIGwRCUQRaBgA25oW+pRbOFYa9W6VK3aalVOPa3iabXibtHWqlVb61oXpAqKkoieuoQlQIBIghISiQmILGHJcp/+MRO8hoQEkssdmOdzzj25d2Zy58cdkifzvjPv20mmDMjm/Wm/Y1rOjZRtXsLyigXh2tW3ZCem0qdrdxZVlrS6zc6de5l9xyIWvFVCtAS+1THd2BgEYOCgRGLbUQRUlbkr76FXXCoTMmd0/B9gjDnqha0QqGoDcDWwAOcX/AuqWiwis0RkqrvZNSJSLCJFwDXAz8OVB6BXl26MH3QeKT2G8HLRnTQG68O5O8DpfM5Ly6Kgch0NwZYHuYuPjyVvcibLu27ghL4D9vU9bNu2hztvf5fCj/frNmlV8aZ81m9eylnZvyImKryzqhljjg5hHX1UVd9Q1SxVzVTVP7rLfq+qc93nM1U1W1VHquokVV0bzjwAUYFozsmZSfWOz1hc9my4dwfApPShbKvbzfKaila3GT6uD0v3ljOh+xDKSp0Ws+7dY0lJ60Faes927Wf77hqeW/IHkrqlMz5jWqdkN8Yc/Xw5DPVxqZPJ6jOWeSvvp7Yu/PMKTEwdTEDkgM1D71WuIyoYoEtJLC89X4SqEggIF186hpTUHm3uo7ZuGw/kX8C23dVcMv5BoqNav6LIGGNC+bIQiAjTRt1Cbd027ln4Y7bu2hTW/SXExpHb27mMtDX5lZ+SFNeN8bkZXHH1+IPqyN5TX8tD+RdStb2MK09+jMzk/TuljTGmNb4sBAADEo/jmryn2LKrkjvf+hEbt4b3PrdJ6UNZsaWSmt079lvXGAxS8MU68tKzOD4nlZ4tTD3ZmvrGPTyy+FI2fLWCX4x/iOH9JnRmbGOMD/i2EAAM7zeBG099CZEAdy88j+JNBWHb16Q0Z0C4gspP91tXtKWCr/fuIi8t66Df98kPb2Dtlx/ws5NmM6r/lA7nNMb4j68LAUBawjBuOu1VkuO/w18KLuKRxZfxXukzbN7Z/it12iM7KYXeXeNZVLF/IVhUUUJAhImpgw/qPddUvU9h+ev88LjfMC7j3M6KaozxmUjfWewJveL68dtTX+SVortYUblw3z0GfbsPIqvPWDKTcxnUO5c+8QMPqu0+VEACTEobyoLy1exuqKdrdMy+dfmVn5KT3J9eLYxy2pqgBnl5+R0kxqVxxvDLDymTMcaAFYJ9usTEM+OEWUzPvY0vd5Sx6osC1lS9R2H5PBaX/RuA+NhEhvedwKj+U8hOyaNLTMu/uHfX72Bt1QcUbypg49er2Vu/kz0Nu6iv28EolOvzezDnlOsQEbbuqWV5TQW/zjnloPIWbphL+dZVXDT2PmKi7O5hY8yhs0LQjIjQr8dg+vUYzKnDLiGoQaq2l1JWs4TSmk8o3pTPJ+VziYmKZUS/75GWMJSGxjoags6jansZpTWFBLWBLtHxZCTlkBiXSmx0N2Kj43j/s9eorX6Eewr7cMOJ5/PeF6UoSl56+/sH6hv38uqK2fRPGMGYgWeH8dMwxviBFYI2BCRAas8sUntmMXHwDILBRko3f8KyjfNZVrGAFZVvEx11DNGBWKIDx5AQ15fTh11GdmoemcmjiQrEfOv98oZcwK3zz2blutt5uUdfFld/RUJsHCOT0tudKX/d02ypreCCSc8QEN938xhjOiisM5SFQ2fOUNYZVPWg+w3WbynmT2+dS70GWKlnMS4tlzl57RsXqLZuG7e8PpGMpByuyXv6UCIbY3zoQDOU2Z+THXQonceDkrK58ntPES31ZPMG4/skt/t75xfPYXfdds4ZOfOg92uMMS2xQhAho1NP4idjHqZroI7Pyh+krmFPm99TsO6fLCx5jLEZ00jvNfwwpDTG+IEVggg6PfM0rpw4h4qtK3nqoxtorZkuGGzkhaWz+HfhLWSn5DE997bDnNQYczSzQhBhOelncPbImygsf515q+7fb/2e+lr++v7lvFPyOJOzLubKiX9v9bJVY4w5FHbVkAecMfwKqraXMm/V/fTrkcmIfiezfstS1m9eyrKNb1K1Yz3Tc2fZJPTGmLCwQuABIsL5J/6Jmp3lPP6/a1ENussDpCcM5+qTn+DY1EkRTmmMOVpZIfCImKhYfjnxb7xaNJukbukMSh7NgMTjrRnIGBN2Vgg8JD42kZ+OuSPSMYwxPmOdxcYY43NhLQQiMkVESkSkVERuPsB254qIikiLd70ZY4wJn7AVAhGJAuYAZwIjgBkiMqKF7boD1wIfhSuLMcaY1oXzjGAMUKqq61W1DngO+FEL290O/Blo+9ZaY4wxnS6chSANCJ3mq8Jdto+IjAb6q+p/D/RGInKZiBSKSGFNTU3nJzXGGB+LWGexiASAe4Hr29pWVR9V1RNU9YTevXuHP5wxxvhIOAtBJdA/5HW6u6xJd+BYIF9EPgfGAnOtw9gYYw6vcBaCT4AhIpIhIscA04G5TStVdZuqJqvqQFUdCHwITFVV70w2YIwxPhC2G8pUtUFErgYWAFHAE6paLCKzgEJVnXvgd2jZkiVLNovIhkOMlQxsPsTvPZyOhJyWsXNYxs5hGds2oLUVR9wMZR0hIoWtzdDjJUdCTsvYOSxj57CMHWN3FhtjjM9ZITDGGJ/zWyF4NNIB2ulIyGkZO4dl7ByWsQN81UdgjDFmf347IzDGGNOMFQJjjPE53xSC9g6JfTiJyBMiUi0iq0KWJYrI2yKyzv3aK8IZ+4vIIhFZLSLFInKt13KKSBcR+VhEityMt7nLM0TkI/eYP+/e2BhRIhIlIstEZJ6HM34uIitFZLmIFLrLPHO83TwJIvKSiKwVkTUiMs5LGUVkqPv5NT22i8h1XsoYyheFoL1DYkfAk8CUZstuBt5R1SHAO+7rSGoArlfVETjDgFzlfnZeyrkXmKyqI4EcYIqIjMUZ1fY+VR0MbAUuiWDGJtcCa0JeezEjwCRVzQm57t1LxxvgAWC+qg4DRuJ8pp7JqKol7ueXA+QCu4BXvJTxW1T1qH8A44AFIa9nAjMjncvNMhBYFfK6BEhxn6cAJZHO2Czva8BpXs0JxAFLgZNw7uKMbun/QISypeP88E8G5gHitYxujs+B5GbLPHO8gZ7AZ7gXu3gxY7NcpwMfeDmjL84IaMeQ2B7SV1U3uc+rgL6RDBNKRAYCo3AmEfJUTrfJZTlQDbwNlAFfq2qDu4kXjvn9wI1A0H2dhPcyAijwlogsEZHL3GVeOt4ZQA3wD7eZ7TER6Ya3MoaaDjzrPvdkRr8UgiOSOn82eOL6XhGJB/4DXKeq20PXeSGnqjaqcxqejjMp0rBI5mlORH4AVKvqkkhnaYcJqjoapyn1KhE5OXSlB453NDAaeERVRwG1NGti8UBGANw+n6nAi83XeSUj+KcQtDUktpd8KSIpAO7X6gjnQURicIrAM6r6srvYczkBVPVrYBFOM0uCiDQNrBjpY/5dYKo75PpzOM1DD+CtjACoaqX7tRqnXXsM3jreFUCFqjZNb/sSTmHwUsYmZwJLVfVL97UXM/qmEBxwSGyPmQtc6D6/EKdNPmJERIDHgTWqem/IKs/kFJHeIpLgPu+K04exBqcgTHM3i2hGVZ2pqunqDLk+HXhXVc/HQxkBRKSbOPOI4za3nA6swkPHW1WrgI0iMtRddAqwGg9lDDGDb5qFwJsZ/dFZ7HbMnAV8itN2/LtI53EzPQtsAupx/sq5BKfd+B1gHbAQSIxwxgk4p68rgOXu4ywv5QSOB5a5GVcBv3eXDwI+BkpxTs1jI33M3Vx5wDwvZnTzFLmP4qafFS8dbzdPDlDoHvNXgV4ezNgN2AL0DFnmqYxNDxtiwhhjfM4vTUPGGGNaYYXAGGN8zgqBMcb4nBUCY4zxOSsExhjjc1YIjGmFiCSFjB5ZJSKV7vOdIvJwpPMZ01ns8lFj2kFEbgV2qurdkc5iTGezMwJjDpKI5IXMJ3CriDwlIotFZIOInCMid7nj+c93h+dARHJFpMAdyG1B0zADxniBFQJjOi4TZ+ygqcC/gEWqehywG/i+WwweAqapai7wBPDHSIU1prnotjcxxrThTVWtF5GVQBQw312+Eme+iaHAscDbztBNROEMLWKMJ1ghMKbj9gKoalBE6vWbjrcgzs+YAMWqOi5SAY05EGsaMib8SoDeIjIOnGG9RSQ7wpmM2ccKgTFhpqp1OENN/1lEinBGcB0f2VTGfMMuHzXGGJ+zMwJjjPE5KwTGGONzVgiMMcbnrBAYY4zPWSEwxhifs0JgjDE+Z4XAGGN87v+5xW3EubPL0gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "awXSgn1gX8zm",
        "outputId": "37ee54d3-25ab-4f27-fcc2-0a6ecc8ee705"
      },
      "source": [
        "stock_name = 'ACC'\n",
        "\n",
        "data = pd.read_csv('drive/MyDrive/Findan/Sb_1/data/{}.csv'.format(stock_name), index_col=0)\n",
        "print('data loaded for {}!!'.format(stock_name))\n",
        "\n",
        "data.index = pd.to_datetime(data.index)\n",
        "data_frame = data.copy()\n",
        "df = data_frame[[\"Close\"]]\n",
        "\n",
        "train = df.loc[pd.Timestamp('01-11-2005'):pd.Timestamp('2006-01-01')]\n",
        "test = df.loc[pd.Timestamp('2005-10-02'):pd.Timestamp('2006-02-02')]\n",
        "plt.plot(train) \n",
        "plt.plot(test)"
      ],
      "id": "awXSgn1gX8zm",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data loaded for ACC!!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f763ef96850>]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_09o4yjYy5j"
      },
      "source": [
        ""
      ],
      "id": "3_09o4yjYy5j",
      "execution_count": null,
      "outputs": []
    }
  ]
}